{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 23:22:00.232143: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:22:00.422421: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:22:00.424251: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:22:01.679275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import fmin, tpe, hp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seaborn import load_dataset\n",
    "pd.options.display.precision = 4\n",
    "pd.options.mode.chained_assignment = None  \n",
    "\n",
    "# Machine learning pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/spaceship/train.csv')\n",
    "test = pd.read_csv('./data/spaceship/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0005_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sandie Hinetthews</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0006_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/2/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Billex Jacostaffey</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0006_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>28.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Candra Jacostaffey</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0007_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Andona Beston</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0008_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>B/1/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Erraiam Flatic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0008_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>B/1/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Altardr Flatic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0008_03</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/1/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7295.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>Wezena Flatic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0009_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Berers Barne</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0010_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>48.0</td>\n",
       "      <td>False</td>\n",
       "      <td>719.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Reney Baketton</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0011_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/2/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>28.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>974.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Elle Bertsontry</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0012_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Justie Pooles</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0014_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>F/3/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flats Eccle</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0015_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>Carry Hughriend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0016_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>F/5/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alus Upead</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0017_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lyde Brighttt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId HomePlanet CryoSleep  Cabin    Destination   Age    VIP  \\\n",
       "0      0001_01     Europa     False  B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1      0002_01      Earth     False  F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2      0003_01     Europa     False  A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3      0003_02     Europa     False  A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4      0004_01      Earth     False  F/1/S    TRAPPIST-1e  16.0  False   \n",
       "5      0005_01      Earth     False  F/0/P  PSO J318.5-22  44.0  False   \n",
       "6      0006_01      Earth     False  F/2/S    TRAPPIST-1e  26.0  False   \n",
       "7      0006_02      Earth      True  G/0/S    TRAPPIST-1e  28.0  False   \n",
       "8      0007_01      Earth     False  F/3/S    TRAPPIST-1e  35.0  False   \n",
       "9      0008_01     Europa      True  B/1/P    55 Cancri e  14.0  False   \n",
       "10     0008_02     Europa      True  B/1/P    TRAPPIST-1e  34.0  False   \n",
       "11     0008_03     Europa     False  B/1/P    55 Cancri e  45.0  False   \n",
       "12     0009_01       Mars     False  F/1/P    TRAPPIST-1e  32.0  False   \n",
       "13     0010_01      Earth     False  G/1/S    TRAPPIST-1e  48.0  False   \n",
       "14     0011_01      Earth     False  F/2/P    TRAPPIST-1e  28.0  False   \n",
       "15     0012_01      Earth     False    NaN    TRAPPIST-1e  31.0  False   \n",
       "16     0014_01       Mars     False  F/3/P    55 Cancri e  27.0  False   \n",
       "17     0015_01      Earth     False  F/4/P    55 Cancri e  24.0  False   \n",
       "18     0016_01       Mars      True  F/5/P    TRAPPIST-1e  45.0  False   \n",
       "19     0017_01      Earth     False  G/0/P    TRAPPIST-1e   0.0  False   \n",
       "\n",
       "    RoomService  FoodCourt  ShoppingMall     Spa  VRDeck                Name  \\\n",
       "0           0.0        0.0           0.0     0.0     0.0     Maham Ofracculy   \n",
       "1         109.0        9.0          25.0   549.0    44.0        Juanna Vines   \n",
       "2          43.0     3576.0           0.0  6715.0    49.0       Altark Susent   \n",
       "3           0.0     1283.0         371.0  3329.0   193.0        Solam Susent   \n",
       "4         303.0       70.0         151.0   565.0     2.0   Willy Santantines   \n",
       "5           0.0      483.0           0.0   291.0     0.0   Sandie Hinetthews   \n",
       "6          42.0     1539.0           3.0     0.0     0.0  Billex Jacostaffey   \n",
       "7           0.0        0.0           0.0     0.0     NaN  Candra Jacostaffey   \n",
       "8           0.0      785.0          17.0   216.0     0.0       Andona Beston   \n",
       "9           0.0        0.0           0.0     0.0     0.0      Erraiam Flatic   \n",
       "10          0.0        0.0           NaN     0.0     0.0      Altardr Flatic   \n",
       "11         39.0     7295.0         589.0   110.0   124.0       Wezena Flatic   \n",
       "12         73.0        0.0        1123.0     0.0   113.0        Berers Barne   \n",
       "13        719.0        1.0          65.0     0.0    24.0      Reney Baketton   \n",
       "14          8.0      974.0          12.0     2.0     7.0     Elle Bertsontry   \n",
       "15         32.0        0.0         876.0     0.0     0.0       Justie Pooles   \n",
       "16       1286.0      122.0           NaN     0.0     0.0         Flats Eccle   \n",
       "17          0.0        1.0           0.0     0.0   637.0     Carry Hughriend   \n",
       "18          0.0        0.0           0.0     0.0     0.0          Alus Upead   \n",
       "19          0.0        0.0           0.0     0.0     0.0       Lyde Brighttt   \n",
       "\n",
       "    Transported  \n",
       "0         False  \n",
       "1          True  \n",
       "2         False  \n",
       "3         False  \n",
       "4          True  \n",
       "5          True  \n",
       "6          True  \n",
       "7          True  \n",
       "8          True  \n",
       "9          True  \n",
       "10         True  \n",
       "11         True  \n",
       "12         True  \n",
       "13        False  \n",
       "14         True  \n",
       "15        False  \n",
       "16        False  \n",
       "17        False  \n",
       "18         True  \n",
       "19         True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_deck</th>\n",
       "      <th>Cabin_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>23.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>339.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "      <td>932.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>D</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>D</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>46.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7708.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>40.0</td>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3144.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomePlanet CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "0       Earth      True  TRAPPIST-1e  27.0  False          0.0        0.0   \n",
       "1       Earth     False  TRAPPIST-1e  19.0  False          0.0        9.0   \n",
       "2      Europa      True  55 Cancri e  31.0  False          0.0        0.0   \n",
       "3      Europa     False  TRAPPIST-1e  38.0  False          0.0     6652.0   \n",
       "4       Earth     False  TRAPPIST-1e  20.0  False         10.0        0.0   \n",
       "5       Earth     False  TRAPPIST-1e  31.0  False          0.0     1615.0   \n",
       "6      Europa      True  55 Cancri e  21.0  False          0.0        NaN   \n",
       "7      Europa      True  TRAPPIST-1e  20.0  False          0.0        0.0   \n",
       "8      Europa      True  55 Cancri e  23.0  False          0.0        0.0   \n",
       "9       Earth     False  55 Cancri e  24.0  False          0.0      639.0   \n",
       "10      Earth     False  TRAPPIST-1e  19.0  False        339.0        3.0   \n",
       "11     Europa     False  TRAPPIST-1e  45.0  False        932.0       74.0   \n",
       "12     Europa     False  TRAPPIST-1e  44.0  False          0.0     1561.0   \n",
       "13       Mars      True  TRAPPIST-1e  46.0  False          0.0        0.0   \n",
       "14      Earth     False  TRAPPIST-1e  21.0  False          0.0        0.0   \n",
       "15      Earth     False  TRAPPIST-1e  27.0  False          0.0        0.0   \n",
       "16      Earth     False  TRAPPIST-1e  20.0  False          2.0       12.0   \n",
       "17     Europa      True  TRAPPIST-1e  44.0  False          0.0        0.0   \n",
       "18     Europa     False  TRAPPIST-1e  29.0  False          0.0     7708.0   \n",
       "19     Europa     False  TRAPPIST-1e  40.0  False         26.0     1925.0   \n",
       "\n",
       "    ShoppingMall     Spa  VRDeck Cabin_deck Cabin_side  \n",
       "0            0.0     0.0     0.0          G          S  \n",
       "1            0.0  2823.0     0.0          F          S  \n",
       "2            0.0     0.0     0.0          C          S  \n",
       "3            0.0   181.0   585.0          C          S  \n",
       "4          635.0     0.0     0.0          F          S  \n",
       "5          263.0   113.0    60.0          F          P  \n",
       "6            0.0     0.0     0.0          B          P  \n",
       "7            0.0     0.0     0.0          D          S  \n",
       "8            0.0     0.0     0.0          D          S  \n",
       "9            0.0     0.0     0.0          F          S  \n",
       "10         136.0   237.0     0.0          F          S  \n",
       "11           NaN     7.0  1010.0          D          P  \n",
       "12           0.0    14.0   224.0          D          P  \n",
       "13           0.0     0.0     0.0          E          P  \n",
       "14           0.0  1687.0    92.0          G          P  \n",
       "15           0.0   903.0     NaN          F          P  \n",
       "16         253.0   457.0   690.0          F          P  \n",
       "17           0.0     0.0     0.0          B          S  \n",
       "18         243.0   569.0   343.0        NaN        NaN  \n",
       "19           8.0  3144.0    63.0          B          S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].fillna('Z/9999/Z', inplace=True)\n",
    "test['Cabin'].fillna('Z/9999/Z', inplace=True)\n",
    "train['Cabin_deck'] = train['Cabin'].apply(lambda x: x.split('/')[0])\n",
    "train['Cabin_side'] = train['Cabin'].apply(lambda x: x.split('/')[2])\n",
    "test['Cabin_deck'] = test['Cabin'].apply(lambda x: x.split('/')[0])\n",
    "test['Cabin_side'] = test['Cabin'].apply(lambda x: x.split('/')[2])\n",
    "train.drop(['Cabin', 'PassengerId', 'Name'], axis=1, inplace=True)\n",
    "test.drop(['Cabin', 'PassengerId', 'Name'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Cabin_deck']=='Z', 'Cabin_deck']=np.nan\n",
    "train.loc[train['Cabin_side']=='Z', 'Cabin_side']=np.nan\n",
    "test.loc[test['Cabin_deck']=='Z', 'Cabin_deck']=np.nan\n",
    "test.loc[test['Cabin_side']=='Z', 'Cabin_side']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_missing</th>\n",
       "      <th>Percentage_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <td>201</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CryoSleep</th>\n",
       "      <td>217</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination</th>\n",
       "      <td>182</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>179</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIP</th>\n",
       "      <td>203</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoomService</th>\n",
       "      <td>181</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FoodCourt</th>\n",
       "      <td>183</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShoppingMall</th>\n",
       "      <td>208</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa</th>\n",
       "      <td>183</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRDeck</th>\n",
       "      <td>188</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_deck</th>\n",
       "      <td>199</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin_side</th>\n",
       "      <td>199</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Number_missing  Percentage_missing\n",
       "HomePlanet               201                2.31\n",
       "CryoSleep                217                2.50\n",
       "Destination              182                2.09\n",
       "Age                      179                2.06\n",
       "VIP                      203                2.34\n",
       "RoomService              181                2.08\n",
       "FoodCourt                183                2.11\n",
       "ShoppingMall             208                2.39\n",
       "Spa                      183                2.11\n",
       "VRDeck                   188                2.16\n",
       "Cabin_deck               199                2.29\n",
       "Cabin_side               199                2.29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_cols=train.columns[train.isna().any()].tolist()\n",
    "\n",
    "# Missing values summary\n",
    "mv=pd.DataFrame(train[na_cols].isna().sum(), columns=['Number_missing'])\n",
    "mv['Percentage_missing']=np.round(100*mv['Number_missing']/len(train),2)\n",
    "mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Heatmap of missing values')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(train[na_cols].isna().T, cmap='summer')\n",
    "plt.title('Heatmap of missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = train.copy()#.drop('Transported', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   HomePlanet    8492 non-null   object \n",
      " 1   CryoSleep     8476 non-null   object \n",
      " 2   Destination   8511 non-null   object \n",
      " 3   Age           8514 non-null   float64\n",
      " 4   VIP           8490 non-null   object \n",
      " 5   RoomService   8512 non-null   float64\n",
      " 6   FoodCourt     8510 non-null   float64\n",
      " 7   ShoppingMall  8485 non-null   float64\n",
      " 8   Spa           8510 non-null   float64\n",
      " 9   VRDeck        8505 non-null   float64\n",
      " 10  Transported   8693 non-null   bool   \n",
      " 11  Cabin_deck    8494 non-null   object \n",
      " 12  Cabin_side    8494 non-null   object \n",
      "dtypes: bool(1), float64(6), object(6)\n",
      "memory usage: 823.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
      "Categorical features: Cabin_deck, Cabin_side, CryoSleep, Destination, HomePlanet, VIP\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "TARGET = 'Transported'\n",
    "FEATURES = df.columns.drop(TARGET)\n",
    "\n",
    "NUMERICAL = df[FEATURES].select_dtypes('number').columns\n",
    "print(f\"Numerical features: {', '.join(NUMERICAL)}\")\n",
    "\n",
    "CATEGORICAL = pd.Index(np.setdiff1d(FEATURES, NUMERICAL))\n",
    "print(f\"Categorical features: {', '.join(CATEGORICAL)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_deck_A</th>\n",
       "      <th>Cabin_deck_B</th>\n",
       "      <th>Cabin_deck_C</th>\n",
       "      <th>Cabin_deck_D</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>Destination_missing</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>HomePlanet_missing</th>\n",
       "      <th>VIP_False</th>\n",
       "      <th>VIP_True</th>\n",
       "      <th>VIP_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>3.0188e-04</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>2.4500e-02</td>\n",
       "      <td>1.8232e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>1.1995e-01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.9967e-01</td>\n",
       "      <td>2.0304e-03</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.3035e-02</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>1.4856e-01</td>\n",
       "      <td>7.9973e-03</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>2.3480e-03</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>2.5214e-02</td>\n",
       "      <td>8.2874e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.6201e-02</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.2986e-02</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>5.1622e-02</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>1.2632e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.6331e-02</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>9.6394e-03</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4304</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>2.4469e-01</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>4.9090e-03</td>\n",
       "      <td>5.1382e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>4.6824e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.6076</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>3.3542e-05</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>9.9449e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>3.2670e-02</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>8.9254e-05</td>\n",
       "      <td>2.9006e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.3924</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.3418</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>4.0922e-03</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.3542e-05</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>2.6395e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>0.0000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  RoomService   FoodCourt  ShoppingMall         Spa      VRDeck  \\\n",
       "0   0.4937       0.0000  0.0000e+00        0.0000  0.0000e+00  0.0000e+00   \n",
       "1   0.3038       0.0076  3.0188e-04        0.0011  2.4500e-02  1.8232e-03   \n",
       "2   0.7342       0.0030  1.1995e-01        0.0000  2.9967e-01  2.0304e-03   \n",
       "3   0.4177       0.0000  4.3035e-02        0.0158  1.4856e-01  7.9973e-03   \n",
       "4   0.2025       0.0211  2.3480e-03        0.0064  2.5214e-02  8.2874e-05   \n",
       "5   0.5570       0.0000  1.6201e-02        0.0000  1.2986e-02  0.0000e+00   \n",
       "6   0.3291       0.0029  5.1622e-02        0.0001  0.0000e+00  0.0000e+00   \n",
       "7   0.3544       0.0000  0.0000e+00        0.0000  0.0000e+00  1.2632e-02   \n",
       "8   0.4430       0.0000  2.6331e-02        0.0007  9.6394e-03  0.0000e+00   \n",
       "9   0.1772       0.0000  0.0000e+00        0.0000  0.0000e+00  0.0000e+00   \n",
       "10  0.4304       0.0000  0.0000e+00        0.0074  0.0000e+00  0.0000e+00   \n",
       "11  0.5696       0.0027  2.4469e-01        0.0251  4.9090e-03  5.1382e-03   \n",
       "12  0.4051       0.0051  0.0000e+00        0.0478  0.0000e+00  4.6824e-03   \n",
       "13  0.6076       0.0502  3.3542e-05        0.0028  0.0000e+00  9.9449e-04   \n",
       "14  0.3544       0.0006  3.2670e-02        0.0005  8.9254e-05  2.9006e-04   \n",
       "15  0.3924       0.0022  0.0000e+00        0.0373  0.0000e+00  0.0000e+00   \n",
       "16  0.3418       0.0898  4.0922e-03        0.0074  0.0000e+00  0.0000e+00   \n",
       "17  0.3038       0.0000  3.3542e-05        0.0000  0.0000e+00  2.6395e-02   \n",
       "18  0.5696       0.0000  0.0000e+00        0.0000  0.0000e+00  0.0000e+00   \n",
       "19  0.0000       0.0000  0.0000e+00        0.0000  0.0000e+00  0.0000e+00   \n",
       "\n",
       "    Cabin_deck_A  Cabin_deck_B  Cabin_deck_C  Cabin_deck_D  ...  \\\n",
       "0          False          True         False         False  ...   \n",
       "1          False         False         False         False  ...   \n",
       "2           True         False         False         False  ...   \n",
       "3           True         False         False         False  ...   \n",
       "4          False         False         False         False  ...   \n",
       "5          False         False         False         False  ...   \n",
       "6          False         False         False         False  ...   \n",
       "7          False         False         False         False  ...   \n",
       "8          False         False         False         False  ...   \n",
       "9          False          True         False         False  ...   \n",
       "10         False          True         False         False  ...   \n",
       "11         False          True         False         False  ...   \n",
       "12         False         False         False         False  ...   \n",
       "13         False         False         False         False  ...   \n",
       "14         False         False         False         False  ...   \n",
       "15         False         False         False         False  ...   \n",
       "16         False         False         False         False  ...   \n",
       "17         False         False         False         False  ...   \n",
       "18         False         False         False         False  ...   \n",
       "19         False         False         False         False  ...   \n",
       "\n",
       "    Destination_PSO J318.5-22  Destination_TRAPPIST-1e  Destination_missing  \\\n",
       "0                       False                     True                False   \n",
       "1                       False                     True                False   \n",
       "2                       False                     True                False   \n",
       "3                       False                     True                False   \n",
       "4                       False                     True                False   \n",
       "5                        True                    False                False   \n",
       "6                       False                     True                False   \n",
       "7                       False                     True                False   \n",
       "8                       False                     True                False   \n",
       "9                       False                    False                False   \n",
       "10                      False                     True                False   \n",
       "11                      False                    False                False   \n",
       "12                      False                     True                False   \n",
       "13                      False                     True                False   \n",
       "14                      False                     True                False   \n",
       "15                      False                     True                False   \n",
       "16                      False                    False                False   \n",
       "17                      False                    False                False   \n",
       "18                      False                     True                False   \n",
       "19                      False                     True                False   \n",
       "\n",
       "    HomePlanet_Earth  HomePlanet_Europa  HomePlanet_Mars  HomePlanet_missing  \\\n",
       "0              False               True            False               False   \n",
       "1               True              False            False               False   \n",
       "2              False               True            False               False   \n",
       "3              False               True            False               False   \n",
       "4               True              False            False               False   \n",
       "5               True              False            False               False   \n",
       "6               True              False            False               False   \n",
       "7               True              False            False               False   \n",
       "8               True              False            False               False   \n",
       "9              False               True            False               False   \n",
       "10             False               True            False               False   \n",
       "11             False               True            False               False   \n",
       "12             False              False             True               False   \n",
       "13              True              False            False               False   \n",
       "14              True              False            False               False   \n",
       "15              True              False            False               False   \n",
       "16             False              False             True               False   \n",
       "17              True              False            False               False   \n",
       "18             False              False             True               False   \n",
       "19              True              False            False               False   \n",
       "\n",
       "    VIP_False  VIP_True  VIP_missing  \n",
       "0        True     False        False  \n",
       "1        True     False        False  \n",
       "2       False      True        False  \n",
       "3        True     False        False  \n",
       "4        True     False        False  \n",
       "5        True     False        False  \n",
       "6        True     False        False  \n",
       "7        True     False        False  \n",
       "8        True     False        False  \n",
       "9        True     False        False  \n",
       "10       True     False        False  \n",
       "11       True     False        False  \n",
       "12       True     False        False  \n",
       "13       True     False        False  \n",
       "14       True     False        False  \n",
       "15       True     False        False  \n",
       "16       True     False        False  \n",
       "17       True     False        False  \n",
       "18       True     False        False  \n",
       "19       True     False        False  \n",
       "\n",
       "[20 rows x 32 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute numerical variables with mean\n",
    "df_num_imputed = df[NUMERICAL].fillna(df[NUMERICAL].mean())\n",
    "# Normalise numerical variables\n",
    "df_num_scaled = df_num_imputed.subtract(df_num_imputed.min(), axis=1)\\\n",
    "                              .divide(df_num_imputed.max()-df_num_imputed.min(), axis=1)\n",
    "\n",
    "# Impute categorical variables with a constant\n",
    "df_cat_imputed = df[CATEGORICAL].fillna('missing')\n",
    "# One-hot-encode categorical variables\n",
    "df_cat_encoded = pd.get_dummies(df_cat_imputed, drop_first=False)\n",
    "\n",
    "# Merge data\n",
    "df_preprocessed = df_num_scaled.join(df_cat_encoded)\n",
    "df_preprocessed.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['bool', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:174\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    172\u001b[0m uniques_set, missing_values \u001b[39m=\u001b[39m _extract_missing(uniques_set)\n\u001b[0;32m--> 174\u001b[0m uniques \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(uniques_set)\n\u001b[1;32m    175\u001b[0m uniques\u001b[39m.\u001b[39mextend(missing_values\u001b[39m.\u001b[39mto_list())\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'bool'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m train_cat_imputed \u001b[39m=\u001b[39m cat_imputer\u001b[39m.\u001b[39mfit_transform(x_train[CATEGORICAL])\n\u001b[1;32m     19\u001b[0m encoder \u001b[39m=\u001b[39m OneHotEncoder(drop\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, handle_unknown\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m, sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m train_cat_encoded \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mfit_transform(train_cat_imputed)\n\u001b[1;32m     22\u001b[0m train_preprocessed \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((train_num_scaled, train_cat_encoded), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m columns \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(NUMERICAL, encoder\u001b[39m.\u001b[39mget_feature_names_out(CATEGORICAL))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:982\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    972\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    973\u001b[0m         (\n\u001b[1;32m    974\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`sparse` was renamed to `sparse_output` in version 1.2 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse\n\u001b[0;32m--> 982\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    983\u001b[0m     X,\n\u001b[1;32m    984\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[1;32m    985\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    986\u001b[0m )\n\u001b[1;32m    987\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_drop_idx()\n\u001b[1;32m    988\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features_outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:97\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     94\u001b[0m Xi \u001b[39m=\u001b[39m X_list[i]\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     result \u001b[39m=\u001b[39m _unique(Xi, return_counts\u001b[39m=\u001b[39;49mcompute_counts)\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m compute_counts:\n\u001b[1;32m     99\u001b[0m         cats, counts \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[39mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m _unique_python(\n\u001b[1;32m     43\u001b[0m         values, return_inverse\u001b[39m=\u001b[39;49mreturn_inverse, return_counts\u001b[39m=\u001b[39;49mreturn_counts\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[39m# numerical\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m _unique_np(\n\u001b[1;32m     47\u001b[0m     values, return_inverse\u001b[39m=\u001b[39mreturn_inverse, return_counts\u001b[39m=\u001b[39mreturn_counts\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     types \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(t\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mtype\u001b[39m(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values))\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEncoders require their input to be uniformly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstrings or numbers. Got \u001b[39m\u001b[39m{\u001b[39;00mtypes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m ret \u001b[39m=\u001b[39m (uniques,)\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['bool', 'str']"
     ]
    }
   ],
   "source": [
    "df = train.copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=TARGET), df[TARGET], \n",
    "                                                    test_size=.2, random_state=SEED, \n",
    "                                                    stratify=df[TARGET])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "train_num_imputed = num_imputer.fit_transform(x_train[NUMERICAL])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_num_scaled = scaler.fit_transform(train_num_imputed)\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "train_cat_imputed = cat_imputer.fit_transform(x_train[CATEGORICAL])\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False)\n",
    "train_cat_encoded = encoder.fit_transform(train_cat_imputed)\n",
    "\n",
    "train_preprocessed = np.concatenate((train_num_scaled, train_cat_encoded), axis=1)\n",
    "\n",
    "columns = np.append(NUMERICAL, encoder.get_feature_names_out(CATEGORICAL))\n",
    "pd.DataFrame(train_preprocessed, columns=columns, index=x_train.index).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_deck_B</th>\n",
       "      <th>Cabin_deck_C</th>\n",
       "      <th>Cabin_deck_D</th>\n",
       "      <th>Cabin_deck_E</th>\n",
       "      <th>Cabin_deck_F</th>\n",
       "      <th>Cabin_deck_G</th>\n",
       "      <th>Cabin_deck_T</th>\n",
       "      <th>Cabin_side_S</th>\n",
       "      <th>CryoSleep_True</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>VIP_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.3544</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7412</th>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>0.3924</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n",
       "5339  0.1899       0.0000     0.0000        0.0414  0.0013  0.0000   \n",
       "261   0.3544       0.0000     0.0197        0.0014  0.0003  0.0718   \n",
       "7412  0.4937       0.3054     0.0026        0.0000  0.0000  0.0000   \n",
       "1881  0.3924       0.0000     0.0000        0.0000  0.0000  0.0000   \n",
       "6464  0.1899       0.0000     0.0178        0.0012  0.0000  0.0080   \n",
       "\n",
       "      Cabin_deck_B  Cabin_deck_C  Cabin_deck_D  Cabin_deck_E  Cabin_deck_F  \\\n",
       "5339           0.0           0.0           0.0           0.0           1.0   \n",
       "261            1.0           0.0           0.0           0.0           0.0   \n",
       "7412           0.0           0.0           0.0           0.0           1.0   \n",
       "1881           1.0           0.0           0.0           0.0           0.0   \n",
       "6464           0.0           0.0           0.0           0.0           1.0   \n",
       "\n",
       "      Cabin_deck_G  Cabin_deck_T  Cabin_side_S  CryoSleep_True  \\\n",
       "5339           0.0           0.0           1.0             0.0   \n",
       "261            0.0           0.0           0.0             0.0   \n",
       "7412           0.0           0.0           1.0             0.0   \n",
       "1881           0.0           0.0           0.0             0.0   \n",
       "6464           0.0           0.0           1.0             0.0   \n",
       "\n",
       "      Destination_PSO J318.5-22  Destination_TRAPPIST-1e  HomePlanet_Europa  \\\n",
       "5339                        0.0                      1.0                0.0   \n",
       "261                         0.0                      1.0                1.0   \n",
       "7412                        0.0                      1.0                0.0   \n",
       "1881                        0.0                      1.0                1.0   \n",
       "6464                        0.0                      1.0                0.0   \n",
       "\n",
       "      HomePlanet_Mars  VIP_True  \n",
       "5339              0.0       0.0  \n",
       "261               0.0       0.0  \n",
       "7412              0.0       0.0  \n",
       "1881              0.0       0.0  \n",
       "6464              0.0       0.0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.copy()\n",
    "df = df.dropna()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=TARGET), df[TARGET], \n",
    "                                                    test_size=.2, random_state=SEED, \n",
    "                                                    stratify=df[TARGET])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "train_num_imputed = num_imputer.fit_transform(x_train[NUMERICAL])\n",
    "test_num_imputed = num_imputer.transform(x_test[NUMERICAL])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_num_scaled = scaler.fit_transform(train_num_imputed)\n",
    "test_num_scaled = scaler.transform(test_num_imputed)\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "train_cat_imputed = cat_imputer.fit_transform(x_train[CATEGORICAL])\n",
    "test_cat_imputed = cat_imputer.transform(x_test[CATEGORICAL])\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False)\n",
    "train_cat_encoded = encoder.fit_transform(train_cat_imputed)\n",
    "test_cat_encoded = encoder.transform(test_cat_imputed)\n",
    "\n",
    "train_preprocessed = np.concatenate((train_num_scaled, train_cat_encoded), axis=1)\n",
    "test_preprocessed = np.concatenate((test_num_scaled, test_cat_encoded), axis=1)\n",
    "\n",
    "columns = np.append(NUMERICAL, encoder.get_feature_names_out(CATEGORICAL))\n",
    "pd.DataFrame(train_preprocessed, columns=columns, index=x_train.index).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_auc(model_pipe, X, y):\n",
    "    \"\"\"Calculate roc auc score. \n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    model_pipe: sklearn model or pipeline\n",
    "    X: features\n",
    "    y: true target\n",
    "    \"\"\"\n",
    "    y_proba = model_pipe.predict_proba(X)[:,1]\n",
    "    return roc_auc_score(y, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.8592\n",
      "Test ROC-AUC: 0.8407\n"
     ]
    }
   ],
   "source": [
    "test_num_imputed = num_imputer.transform(x_test[NUMERICAL])\n",
    "test_num_scaled = scaler.transform(test_num_imputed)\n",
    "test_cat_imputed = cat_imputer.transform(x_test[CATEGORICAL])\n",
    "test_cat_encoded = encoder.transform(test_cat_imputed)\n",
    "test_preprocessed = np.concatenate((test_num_scaled, test_cat_encoded), axis=1)\n",
    "\n",
    "print(f\"Train ROC-AUC: {calculate_roc_auc(model, train_preprocessed, y_train):.4f}\")\n",
    "print(f\"Test ROC-AUC: {calculate_roc_auc(model, test_preprocessed, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessors&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessors&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessors: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessors',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))])),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessors = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipe, NUMERICAL),\n",
    "    ('cat', categorical_pipe, CATEGORICAL)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessors', preprocessors),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.8592\n",
      "Test ROC-AUC: 0.8407\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train ROC-AUC: {calculate_roc_auc(pipe, x_train, y_train):.4f}\")\n",
    "print(f\"Test ROC-AUC: {calculate_roc_auc(pipe, x_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessors&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=10,\n",
       "                                            random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessors&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=10,\n",
       "                                            random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessors: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, MinMaxScaler())]),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(learning_rate=0.01, n_estimators=10, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessors',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))])),\n",
       "                ('model',\n",
       "                 GradientBoostingClassifier(learning_rate=0.01, n_estimators=10,\n",
       "                                            random_state=42))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "numerical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessors = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipe, NUMERICAL),\n",
    "    ('cat', categorical_pipe, CATEGORICAL)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessors', preprocessors),\n",
    "    ('model', GradientBoostingClassifier(n_estimators=10, learning_rate=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.8469\n",
      "Test ROC-AUC: 0.8283\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train ROC-AUC: {calculate_roc_auc(pipe, x_train, y_train):.4f}\")\n",
    "print(f\"Test ROC-AUC: {calculate_roc_auc(pipe, x_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.8869\n",
      "Test ROC-AUC: 0.8667\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "numerical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessors = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipe, NUMERICAL),\n",
    "    ('cat', categorical_pipe, CATEGORICAL)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessors', preprocessors),\n",
    "    ('model', xgb.XGBClassifier(objective ='binary:logistic', learning_rate = 0.1, max_depth = 5, n_estimators = 5))\n",
    "])\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "print(f\"Train ROC-AUC: {calculate_roc_auc(pipe, x_train, y_train):.4f}\")\n",
    "print(f\"Test ROC-AUC: {calculate_roc_auc(pipe, x_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;num_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "                         method=&#x27;mean&#x27;,\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;cat_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;encoder&#x27;,\n",
       "                 Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" ><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;num_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "                         method=&#x27;mean&#x27;,\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;cat_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;encoder&#x27;,\n",
       "                 Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-104\" type=\"checkbox\" ><label for=\"sk-estimator-id-104\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "        method=&#x27;mean&#x27;,\n",
       "        value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-105\" type=\"checkbox\" ><label for=\"sk-estimator-id-105\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Scaler</label><div class=\"sk-toggleable__content\"><pre>Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-106\" type=\"checkbox\" ><label for=\"sk-estimator-id-106\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-107\" type=\"checkbox\" ><label for=\"sk-estimator-id-107\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Encoder</label><div class=\"sk-toggleable__content\"><pre>Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-108\" type=\"checkbox\" ><label for=\"sk-estimator-id-108\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('num_imputer',\n",
       "                 Imputer(features=Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object'),\n",
       "                         method='mean',\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                ('scaler',\n",
       "                 Scaler(features=Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object'))),\n",
       "                ('cat_imputer',\n",
       "                 Imputer(features=Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))),\n",
       "                ('encoder',\n",
       "                 Encoder(features=Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Imputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, method='constant', value='missing'):\n",
    "        self.features = features\n",
    "        self.method = method\n",
    "        self.value = value\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.method=='mean':\n",
    "            self.value = X[self.features].mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.features] = X[self.features].fillna(self.value)\n",
    "        return X_transformed\n",
    "    \n",
    "class Scaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.min = X[self.features].min()\n",
    "        self.range = X[self.features].max()-self.min\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.features] = (X[self.features]-self.min)/self.range\n",
    "        return X_transformed\n",
    "  \n",
    "class Encoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, drop='first'):\n",
    "        self.features = features\n",
    "        self.drop = drop\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.encoder = OneHotEncoder(sparse=False, drop=self.drop)\n",
    "        self.encoder.fit(X[self.features])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = pd.concat([X.drop(columns=self.features).reset_index(drop=True), \n",
    "                                   pd.DataFrame(self.encoder.transform(X[self.features]), \n",
    "                                                columns=self.encoder.get_feature_names_out(self.features))], axis=1)\n",
    "        return X_transformed\n",
    "        \n",
    "pipe = Pipeline([\n",
    "    ('num_imputer', Imputer(NUMERICAL, method='mean')),\n",
    "    ('scaler', Scaler(NUMERICAL)),\n",
    "    ('cat_imputer', Imputer(CATEGORICAL)),\n",
    "    ('encoder', Encoder(CATEGORICAL)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(x_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.8592\n",
      "Test ROC-AUC: 0.8407\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train ROC-AUC: {calculate_roc_auc(pipe, x_train, y_train):.4f}\")\n",
    "print(f\"Test ROC-AUC: {calculate_roc_auc(pipe, x_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7642276422764228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogisticRegressionTuner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, param_grid=None, cv=3):\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.model = LogisticRegression()\n",
    "        self.grid_search = GridSearchCV(self.model, self.param_grid, cv=self.cv)\n",
    "        self.grid_search.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # LogisticRegressionTuner не изменяет данные, поэтому просто возвращаем X\n",
    "        return X\n",
    "\n",
    "# Определите сетку параметров, которые вы хотите оптимизировать для LogisticRegression\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Добавьте LogisticRegressionTuner в ваш конвейер\n",
    "pipe = Pipeline([\n",
    "    ('num_imputer', Imputer(NUMERICAL, method='mean')),\n",
    "    ('scaler', Scaler(NUMERICAL)),\n",
    "    ('cat_imputer', Imputer(CATEGORICAL)),\n",
    "    ('encoder', Encoder(CATEGORICAL)),\n",
    "    ('logistic_regression_tuner', LogisticRegressionTuner(param_grid=param_grid, cv=3)),\n",
    "    ('model', LogisticRegression())  # Добавьте оптимизированную модель\n",
    "])\n",
    "\n",
    "# Запустите конвейер на тренировочных данных\n",
    "pipe.fit(x_train, y_train)\n",
    "print(pipe.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.8592\n",
      "Test ROC-AUC: 0.8407\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train ROC-AUC: {calculate_roc_auc(pipe, x_train, y_train):.4f}\")\n",
    "print(f\"Test ROC-AUC: {calculate_roc_auc(pipe, x_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;num_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "                         method=&#x27;mean&#x27;,\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VR...\n",
       "                 Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;encoder&#x27;,\n",
       "                 Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;GBCtuner&#x27;,\n",
       "                 GBCTuner(param_grid={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1, 1,\n",
       "                                                        10],\n",
       "                                      &#x27;n_estimators&#x27;: [5, 8, 10],\n",
       "                                      &#x27;random_state&#x27;: [0, 42]})),\n",
       "                (&#x27;model&#x27;, GradientBoostingClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-109\" type=\"checkbox\" ><label for=\"sk-estimator-id-109\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;num_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "                         method=&#x27;mean&#x27;,\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VR...\n",
       "                 Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;encoder&#x27;,\n",
       "                 Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;GBCtuner&#x27;,\n",
       "                 GBCTuner(param_grid={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1, 1,\n",
       "                                                        10],\n",
       "                                      &#x27;n_estimators&#x27;: [5, 8, 10],\n",
       "                                      &#x27;random_state&#x27;: [0, 42]})),\n",
       "                (&#x27;model&#x27;, GradientBoostingClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-110\" type=\"checkbox\" ><label for=\"sk-estimator-id-110\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "        method=&#x27;mean&#x27;,\n",
       "        value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-111\" type=\"checkbox\" ><label for=\"sk-estimator-id-111\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Scaler</label><div class=\"sk-toggleable__content\"><pre>Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-112\" type=\"checkbox\" ><label for=\"sk-estimator-id-112\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-113\" type=\"checkbox\" ><label for=\"sk-estimator-id-113\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Encoder</label><div class=\"sk-toggleable__content\"><pre>Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-114\" type=\"checkbox\" ><label for=\"sk-estimator-id-114\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GBCTuner</label><div class=\"sk-toggleable__content\"><pre>GBCTuner(param_grid={&#x27;learning_rate&#x27;: [0.001, 0.01, 0.1, 1, 10],\n",
       "                     &#x27;n_estimators&#x27;: [5, 8, 10], &#x27;random_state&#x27;: [0, 42]})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-115\" type=\"checkbox\" ><label for=\"sk-estimator-id-115\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('num_imputer',\n",
       "                 Imputer(features=Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object'),\n",
       "                         method='mean',\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                ('scaler',\n",
       "                 Scaler(features=Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VR...\n",
       "                 Imputer(features=Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))),\n",
       "                ('encoder',\n",
       "                 Encoder(features=Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))),\n",
       "                ('GBCtuner',\n",
       "                 GBCTuner(param_grid={'learning_rate': [0.001, 0.01, 0.1, 1,\n",
       "                                                        10],\n",
       "                                      'n_estimators': [5, 8, 10],\n",
       "                                      'random_state': [0, 42]})),\n",
       "                ('model', GradientBoostingClassifier())])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "class GBCTuner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, param_grid=None, cv=3):\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.model = GradientBoostingClassifier()\n",
    "        self.grid_search = GridSearchCV(self.model, self.param_grid, cv=self.cv)\n",
    "        self.grid_search.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "# Определите сетку параметров, которые вы хотите оптимизировать для LogisticRegression\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1, 10],\n",
    "    #'penalty': ['l2']\n",
    "    'n_estimators': [5, 8, 10],\n",
    "    'random_state': [0, 42]\n",
    "}\n",
    "\n",
    "# Добавьте LogisticRegressionTuner в ваш конвейер\n",
    "pipe = Pipeline([\n",
    "    ('num_imputer', Imputer(NUMERICAL, method='mean')),\n",
    "    ('scaler', Scaler(NUMERICAL)),\n",
    "    ('cat_imputer', Imputer(CATEGORICAL)),\n",
    "    ('encoder', Encoder(CATEGORICAL)),\n",
    "    #('encoder_fit', Encoder(CATEGORICAL).transform),\n",
    "    ('GBCtuner', GBCTuner(param_grid=param_grid, cv=3)),\n",
    "    ('model', GradientBoostingClassifier())  # Добавьте оптимизированную модель\n",
    "])\n",
    "\n",
    "# Запустите конвейер на тренировочных данных\n",
    "pipe.fit(x_train, y_train)\n",
    "#print(pipe.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC-AUC: 0.9158\n",
      "Test ROC-AUC: 0.8802\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train ROC-AUC: {calculate_roc_auc(pipe, x_train, y_train):.4f}\")\n",
    "print(f\"Test ROC-AUC: {calculate_roc_auc(pipe, x_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Cabin_deck</th>\n",
       "      <th>Cabin_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>28.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7412</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3030.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>13.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>2983.0</td>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>E</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>Mars</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5411 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HomePlanet CryoSleep    Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "5339      Earth     False    TRAPPIST-1e  15.0  False          0.0        0.0   \n",
       "261      Europa     False    TRAPPIST-1e  28.0  False          0.0      587.0   \n",
       "7412      Earth     False    TRAPPIST-1e  39.0  False       3030.0       79.0   \n",
       "1881     Europa     False    TRAPPIST-1e  31.0  False          0.0        0.0   \n",
       "6464      Earth     False    TRAPPIST-1e  15.0  False          0.0      532.0   \n",
       "...         ...       ...            ...   ...    ...          ...        ...   \n",
       "5916       Mars      True    TRAPPIST-1e  13.0  False          0.0        0.0   \n",
       "4809      Earth      True  PSO J318.5-22  24.0  False          0.0        0.0   \n",
       "4143     Europa     False    55 Cancri e  39.0  False          3.0       83.0   \n",
       "7994      Earth     False  PSO J318.5-22  58.0  False        487.0        0.0   \n",
       "4757       Mars     False    TRAPPIST-1e  35.0  False       4608.0        0.0   \n",
       "\n",
       "      ShoppingMall    Spa  VRDeck Cabin_deck Cabin_side  \n",
       "5339         973.0   29.0     0.0          F          S  \n",
       "261           32.0    6.0  1460.0          B          P  \n",
       "7412           0.0    0.0     0.0          F          S  \n",
       "1881           0.0    0.0     0.0          B          P  \n",
       "6464          29.0    0.0   163.0          F          S  \n",
       "...            ...    ...     ...        ...        ...  \n",
       "5916           0.0    0.0     0.0          F          S  \n",
       "4809           0.0    0.0     0.0          G          P  \n",
       "4143           0.0  805.0  2983.0          D          S  \n",
       "7994         195.0    0.0     7.0          E          P  \n",
       "4757         926.0  382.0     0.0          F          S  \n",
       "\n",
       "[5411 rows x 12 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 2s 9ms/step - loss: 0.7238 - accuracy: 0.7100\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4972 - accuracy: 0.7524\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4716 - accuracy: 0.7664\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4637 - accuracy: 0.7769\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4617 - accuracy: 0.7666\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4374 - accuracy: 0.7780\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4459 - accuracy: 0.7830\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4375 - accuracy: 0.7865\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4369 - accuracy: 0.7817\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 2s 9ms/step - loss: 0.4315 - accuracy: 0.7878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-36 {color: black;}#sk-container-id-36 pre{padding: 0;}#sk-container-id-36 div.sk-toggleable {background-color: white;}#sk-container-id-36 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-36 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-36 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-36 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-36 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-36 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-36 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-36 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-36 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-36 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-36 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-36 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-36 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-36 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-36 div.sk-item {position: relative;z-index: 1;}#sk-container-id-36 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-36 div.sk-item::before, #sk-container-id-36 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-36 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-36 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-36 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-36 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-36 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-36 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-36 div.sk-label-container {text-align: center;}#sk-container-id-36 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-36 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-36\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;num_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "                         method=&#x27;mean&#x27;,\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;cat_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;encoder&#x27;,\n",
       "                 Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;neural_network_trainer&#x27;, NeuralNetworkTrainer())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-218\" type=\"checkbox\" ><label for=\"sk-estimator-id-218\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;num_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "                         method=&#x27;mean&#x27;,\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;cat_imputer&#x27;,\n",
       "                 Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;encoder&#x27;,\n",
       "                 Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))),\n",
       "                (&#x27;neural_network_trainer&#x27;, NeuralNetworkTrainer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-219\" type=\"checkbox\" ><label for=\"sk-estimator-id-219\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;),\n",
       "        method=&#x27;mean&#x27;,\n",
       "        value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-220\" type=\"checkbox\" ><label for=\"sk-estimator-id-220\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Scaler</label><div class=\"sk-toggleable__content\"><pre>Scaler(features=Index([&#x27;Age&#x27;, &#x27;RoomService&#x27;, &#x27;FoodCourt&#x27;, &#x27;ShoppingMall&#x27;, &#x27;Spa&#x27;, &#x27;VRDeck&#x27;], dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-221\" type=\"checkbox\" ><label for=\"sk-estimator-id-221\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Imputer</label><div class=\"sk-toggleable__content\"><pre>Imputer(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-222\" type=\"checkbox\" ><label for=\"sk-estimator-id-222\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Encoder</label><div class=\"sk-toggleable__content\"><pre>Encoder(features=Index([&#x27;Cabin_deck&#x27;, &#x27;Cabin_side&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;HomePlanet&#x27;,\n",
       "       &#x27;VIP&#x27;],\n",
       "      dtype=&#x27;object&#x27;))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-223\" type=\"checkbox\" ><label for=\"sk-estimator-id-223\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetworkTrainer</label><div class=\"sk-toggleable__content\"><pre>NeuralNetworkTrainer()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('num_imputer',\n",
       "                 Imputer(features=Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object'),\n",
       "                         method='mean',\n",
       "                         value=Age              29.0155\n",
       "RoomService     223.5254\n",
       "FoodCourt       484.5862\n",
       "ShoppingMall    180.8329\n",
       "Spa             323.2144\n",
       "VRDeck          315.1421\n",
       "dtype: float64)),\n",
       "                ('scaler',\n",
       "                 Scaler(features=Index(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'], dtype='object'))),\n",
       "                ('cat_imputer',\n",
       "                 Imputer(features=Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))),\n",
       "                ('encoder',\n",
       "                 Encoder(features=Index(['Cabin_deck', 'Cabin_side', 'CryoSleep', 'Destination', 'HomePlanet',\n",
       "       'VIP'],\n",
       "      dtype='object'))),\n",
       "                ('neural_network_trainer', NeuralNetworkTrainer())])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "class NeuralNetworkTrainer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, epochs=10, batch_size=32, verbose=1):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        input_shape = (X.shape[1],)  # Определите форму входных данных на основе X\n",
    "        num_classes = len(np.unique(y))  # Количество классов в задаче классификации\n",
    "        \n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(1024, activation='tanh', input_shape=input_shape),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(512, activation='tanh'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        self.model = model\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # NeuralNetworkTrainer не изменяет данные, поэтому просто возвращаем X\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Предсказать метки классов для новых данных X\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        y_pred = self.model.predict(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    def score(self, X, y=None):\n",
    "        # Оцените производительность модели на данных X и y\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        y_pred = self.model.predict(X)\n",
    "        accuracy = accuracy_score(y, np.argmax(y_pred, axis=1))\n",
    "        return accuracy\n",
    "    \n",
    "    # def matrix(self, X, y=None):\n",
    "    #     if self.model is None:\n",
    "    #         raise ValueError(\"Модель не обучена\")\n",
    "    #     y_pred = self.model.predict(X)\n",
    "    #     predicted_confusion_matrix = confusion_matrix(y, y_pred)\n",
    "    #     plt.figure(figsize=(10, 8))\n",
    "    #     sns.heatmap(predicted_confusion_matrix, annot=True, fmt='g')\n",
    "    #     return self\n",
    "        \n",
    "\n",
    "\n",
    "# Добавьте NeuralNetworkTrainer в ваш конвейер\n",
    "pipe = Pipeline([\n",
    "    ('num_imputer', Imputer(NUMERICAL, method='mean')),\n",
    "    ('scaler', Scaler(NUMERICAL)),\n",
    "    ('cat_imputer', Imputer(CATEGORICAL)),\n",
    "    ('encoder', Encoder(CATEGORICAL)),\n",
    "    ('neural_network_trainer', NeuralNetworkTrainer()),\n",
    "    #('neural_network_martrix', NeuralNetworkTrainer().matrix(x_train, y_test)),\n",
    "])\n",
    "\n",
    "# Запустите конвейер на тренировочных данных\n",
    "pipe.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.7871396895787139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Сделайте предсказание на тестовых данных\n",
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Вычислите оценку точности (accuracy) модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Выведите оценку на экран\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "predicted_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(predicted_confusion_matrix, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 23:24:16.241722: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.298989: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.302508: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.305022: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.306741: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.331666: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.344873: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.362306: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.362306: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.362924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.363059: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.402712: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.403534: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.403911: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.404462: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.404584: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.438295: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.467396: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.469235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.480751: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.508342: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.509096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.550163: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.550674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.594324: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.604991: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.665504: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.665504: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.666030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.666036: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.716304: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.781110: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.781832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.782568: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.790168: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.798439: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.852897: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.852987: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.853581: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.853624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.869769: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:16.871236: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:16.882503: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:17.010054: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:17.010754: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:17.121153: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:17.189781: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-13 23:24:17.190730: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 23:24:17.968764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:17.995987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.063022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.177588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.201865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.207006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.323869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.390047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.493952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.513664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.548405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.594447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.669526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.726568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:18.888610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-13 23:24:19.178948: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56/113 [=============>................] - ETA: 0s - loss: 0.5649 - accuracy: 0.6987Epoch 1/30\n",
      "113/113 [==============================] - 2s 6ms/step - loss: 0.5235 - accuracy: 0.7322\n",
      " 31/113 [=======>......................] - ETA: 0s - loss: 0.5713 - accuracy: 0.6976Epoch 2/10\n",
      "113/113 [==============================] - 2s 8ms/step - loss: 0.5240 - accuracy: 0.7347\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 2s 8ms/step - loss: 0.5235 - accuracy: 0.7333\n",
      " 58/113 [==============>...............] - ETA: 0s - loss: 0.4550 - accuracy: 0.7764Epoch 2/20\n",
      "113/113 [==============================] - 2s 8ms/step - loss: 0.5319 - accuracy: 0.7256\n",
      "102/113 [==========================>...] - ETA: 0s - loss: 0.5359 - accuracy: 0.7194Epoch 2/20\n",
      "113/113 [==============================] - 2s 8ms/step - loss: 0.5153 - accuracy: 0.7377\n",
      " 83/113 [=====================>........] - ETA: 0s - loss: 0.4526 - accuracy: 0.7782Epoch 2/20\n",
      "113/113 [==============================] - 2s 9ms/step - loss: 0.5295 - accuracy: 0.7237\n",
      " 96/113 [========================>.....] - ETA: 0s - loss: 0.4486 - accuracy: 0.7809Epoch 2/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4480 - accuracy: 0.7804\n",
      " 32/113 [=======>......................] - ETA: 0s - loss: 0.4632 - accuracy: 0.7754Epoch 3/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4484 - accuracy: 0.7746\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4483 - accuracy: 0.7804\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4404 - accuracy: 0.7862\n",
      " 24/113 [=====>........................] - ETA: 0s - loss: 0.4347 - accuracy: 0.7930Epoch 3/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4571 - accuracy: 0.7738\n",
      "  1/113 [..............................] - ETA: 1s - loss: 0.3640 - accuracy: 0.8125Epoch 3/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4570 - accuracy: 0.7686\n",
      "  6/113 [>.............................] - ETA: 1s - loss: 0.4333 - accuracy: 0.8125Epoch 3/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4162 - accuracy: 0.8004\n",
      " 36/113 [========>.....................] - ETA: 0s - loss: 0.4253 - accuracy: 0.7865Epoch 4/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4232 - accuracy: 0.7921\n",
      " 16/113 [===>..........................] - ETA: 1s - loss: 0.6204 - accuracy: 0.6504Epoch 4/10\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4271 - accuracy: 0.7874\n",
      "100/113 [=========================>....] - ETA: 0s - loss: 0.4219 - accuracy: 0.7922Epoch 4/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4317 - accuracy: 0.7858\n",
      " 90/113 [======================>.......] - ETA: 0s - loss: 0.4291 - accuracy: 0.7913Epoch 4/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4215 - accuracy: 0.7937\n",
      " 86/113 [=====================>........] - ETA: 0s - loss: 0.4207 - accuracy: 0.7980Epoch 4/20\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4301 - accuracy: 0.7891\n",
      " 61/113 [===============>..............] - ETA: 0s - loss: 0.4175 - accuracy: 0.7920Epoch 4/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4120 - accuracy: 0.8034\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 4s 11ms/step - loss: 0.5148 - accuracy: 0.7463\n",
      " 42/113 [==========>...................] - ETA: 0s - loss: 0.4424 - accuracy: 0.7723Epoch 2/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4096 - accuracy: 0.7957\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4147 - accuracy: 0.8012\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4201 - accuracy: 0.7894\n",
      " 45/113 [==========>...................] - ETA: 0s - loss: 0.4616 - accuracy: 0.7771Epoch 5/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4083 - accuracy: 0.8057\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4233 - accuracy: 0.7874\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4481 - accuracy: 0.7832\n",
      "Epoch 3/30\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.4012 - accuracy: 0.8109\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 2s 16ms/step - loss: 0.4044 - accuracy: 0.7965\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.4074 - accuracy: 0.8007\n",
      " 68/113 [=================>............] - ETA: 0s - loss: 0.4005 - accuracy: 0.8056Epoch 6/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.4189 - accuracy: 0.8001\n",
      "Epoch 4/30\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.4110 - accuracy: 0.8010\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.4019 - accuracy: 0.8082\n",
      "108/113 [===========================>..] - ETA: 0s - loss: 0.4178 - accuracy: 0.7960Epoch 6/20\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.4170 - accuracy: 0.7960\n",
      " 97/113 [========================>.....] - ETA: 0s - loss: 0.4090 - accuracy: 0.8012Epoch 6/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4021 - accuracy: 0.8048\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4019 - accuracy: 0.7987\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4100 - accuracy: 0.8032\n",
      "107/113 [===========================>..] - ETA: 0s - loss: 0.4008 - accuracy: 0.8005Epoch 5/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4007 - accuracy: 0.7998\n",
      " 35/113 [========>.....................] - ETA: 0s - loss: 0.3829 - accuracy: 0.8116Epoch 7/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4090 - accuracy: 0.8040\n",
      "103/113 [==========================>...] - ETA: 0s - loss: 0.3948 - accuracy: 0.8140Epoch 7/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3947 - accuracy: 0.8162\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4128 - accuracy: 0.8049\n",
      " 24/113 [=====>........................] - ETA: 0s - loss: 0.4002 - accuracy: 0.8112Epoch 7/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3934 - accuracy: 0.8148\n",
      " 45/113 [==========>...................] - ETA: 0s - loss: 0.3844 - accuracy: 0.8153Epoch 8/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3968 - accuracy: 0.8051\n",
      " 68/113 [=================>............] - ETA: 0s - loss: 0.4026 - accuracy: 0.7996Epoch 8/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3987 - accuracy: 0.8076\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4050 - accuracy: 0.8052\n",
      "112/113 [============================>.] - ETA: 0s - loss: 0.3943 - accuracy: 0.8181Epoch 8/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3940 - accuracy: 0.8179\n",
      " 54/113 [=============>................] - ETA: 0s - loss: 0.3898 - accuracy: 0.8032Epoch 8/20\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.4057 - accuracy: 0.8049\n",
      " 41/113 [=========>....................] - ETA: 0s - loss: 0.4002 - accuracy: 0.7973Epoch 8/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3899 - accuracy: 0.8112\n",
      " 38/113 [=========>....................] - ETA: 0s - loss: 0.4166 - accuracy: 0.7944Epoch 9/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3910 - accuracy: 0.8018\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 2s 17ms/step - loss: 0.4019 - accuracy: 0.8073\n",
      "Epoch 6/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3935 - accuracy: 0.8048\n",
      " 37/113 [========>.....................] - ETA: 0s - loss: 0.3854 - accuracy: 0.8083Epoch 9/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4053 - accuracy: 0.8013\n",
      " 97/113 [========================>.....] - ETA: 0s - loss: 0.4061 - accuracy: 0.7977Epoch 9/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3865 - accuracy: 0.8173\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4045 - accuracy: 0.7991\n",
      " 15/113 [==>...........................] - ETA: 1s - loss: 0.3919 - accuracy: 0.8333Epoch 9/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3874 - accuracy: 0.8151\n",
      " 25/113 [=====>........................] - ETA: 0s - loss: 0.3948 - accuracy: 0.8000Epoch 10/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3993 - accuracy: 0.8101\n",
      "Epoch 7/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.3908 - accuracy: 0.8070\n",
      " 14/113 [==>...........................] - ETA: 0s - loss: 0.3939 - accuracy: 0.8237Epoch 10/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3918 - accuracy: 0.8051\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3895 - accuracy: 0.8104\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4002 - accuracy: 0.8071\n",
      "Epoch 10/20\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3999 - accuracy: 0.8054\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3839 - accuracy: 0.8181\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3844 - accuracy: 0.8065\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3986 - accuracy: 0.8134\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 7ms/step loss: 0.3808 - accuracy: 0.82\n",
      "57/57 [==============================] - 1s 7ms/step loss: 0.3842 - accuracy: 0.82\n",
      "57/57 [==============================] - 1s 5ms/step loss: 0.3898 - accuracy: 0.81\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3951 - accuracy: 0.8029\n",
      " 88/113 [======================>.......] - ETA: 0s - loss: 0.4014 - accuracy: 0.8097Epoch 11/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3969 - accuracy: 0.8093\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3835 - accuracy: 0.8151\n",
      "100/113 [=========================>....] - ETA: 0s - loss: 0.4031 - accuracy: 0.8084Epoch 11/20\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3982 - accuracy: 0.8124\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3912 - accuracy: 0.8151\n",
      "Epoch 9/30\n",
      " 86/113 [=====================>........] - ETA: 0s - loss: 0.3770 - accuracy: 0.8070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3879 - accuracy: 0.8059\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3836 - accuracy: 0.8106\n",
      "38/57 [===================>..........] - ETA: 0sEpoch 12/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3989 - accuracy: 0.8099\n",
      "  1/113 [..............................] - ETA: 0s - loss: 0.4373 - accuracy: 0.7812Epoch 12/20\n",
      " 70/113 [=================>............] - ETA: 0s - loss: 0.3914 - accuracy: 0.8103Epoch 1/30\n",
      " 13/113 [==>...........................] - ETA: 0s - loss: 0.4032 - accuracy: 0.7957Epoch 1/30\n",
      "57/57 [==============================] - 1s 6ms/step\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3887 - accuracy: 0.8062\n",
      " 74/113 [==================>...........] - ETA: 0s - loss: 0.3799 - accuracy: 0.8133Epoch 10/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3855 - accuracy: 0.8093\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3803 - accuracy: 0.8190\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3943 - accuracy: 0.8149\n",
      "  8/113 [=>............................] - ETA: 0s - loss: 0.3760 - accuracy: 0.8125Epoch 13/20\n",
      " 53/113 [=============>................] - ETA: 0s - loss: 0.3892 - accuracy: 0.8072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.8181\n",
      " 28/113 [======>.......................] - ETA: 0s - loss: 0.3799 - accuracy: 0.8158Epoch 11/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3868 - accuracy: 0.8073\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3844 - accuracy: 0.8143\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3946 - accuracy: 0.8099\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3857 - accuracy: 0.8181\n",
      "Epoch 12/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3804 - accuracy: 0.8131\n",
      " 71/113 [=================>............] - ETA: 0s - loss: 0.3672 - accuracy: 0.8292Epoch 15/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3797 - accuracy: 0.8209\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 3s 8ms/step - loss: 0.5256 - accuracy: 0.7302\n",
      "Epoch 2/30\n",
      "113/113 [==============================] - 3s 8ms/step - loss: 0.5327 - accuracy: 0.7259\n",
      " 60/113 [==============>...............] - ETA: 0s - loss: 0.3866 - accuracy: 0.7995Epoch 2/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3934 - accuracy: 0.8068\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3835 - accuracy: 0.8143\n",
      " 34/113 [========>.....................] - ETA: 0s - loss: 0.4859 - accuracy: 0.7472Epoch 13/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3804 - accuracy: 0.8062\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.4472 - accuracy: 0.7793\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3799 - accuracy: 0.8159\n",
      "Epoch 3/30\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.4629 - accuracy: 0.7644\n",
      " 74/113 [==================>...........] - ETA: 0s - loss: 0.3688 - accuracy: 0.8243Epoch 3/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3914 - accuracy: 0.8101\n",
      " 79/113 [===================>..........] - ETA: 0s - loss: 0.3675 - accuracy: 0.8244Epoch 16/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3801 - accuracy: 0.8187\n",
      " 57/113 [==============>...............] - ETA: 0s - loss: 0.4474 - accuracy: 0.7654Epoch 14/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3800 - accuracy: 0.8120\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3744 - accuracy: 0.8251\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4260 - accuracy: 0.7843\n",
      "Epoch 4/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4347 - accuracy: 0.7810\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3917 - accuracy: 0.8074\n",
      "Epoch 4/30\n",
      " 13/113 [==>...........................] - ETA: 0s - loss: 0.3754 - accuracy: 0.8077Epoch 17/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3819 - accuracy: 0.8057\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3789 - accuracy: 0.8209\n",
      "Epoch 15/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3740 - accuracy: 0.8220\n",
      "104/113 [==========================>...] - ETA: 0s - loss: 0.3929 - accuracy: 0.8071Epoch 18/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3892 - accuracy: 0.8088\n",
      " 65/113 [================>.............] - ETA: 0s - loss: 0.3788 - accuracy: 0.8072Epoch 18/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.4084 - accuracy: 0.7962\n",
      " 66/113 [================>.............] - ETA: 0s - loss: 0.3659 - accuracy: 0.8295Epoch 5/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4215 - accuracy: 0.7957\n",
      "Epoch 5/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3776 - accuracy: 0.8126\n",
      " 45/113 [==========>...................] - ETA: 0s - loss: 0.3819 - accuracy: 0.8160Epoch 19/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3771 - accuracy: 0.8206\n",
      "Epoch 16/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3725 - accuracy: 0.8181\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3885 - accuracy: 0.8140\n",
      " 57/113 [==============>...............] - ETA: 0s - loss: 0.3613 - accuracy: 0.8229Epoch 19/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.4165 - accuracy: 0.7916\n",
      "Epoch 6/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.4047 - accuracy: 0.8029\n",
      "  1/113 [..............................] - ETA: 0s - loss: 0.3344 - accuracy: 0.8750Epoch 6/30\n",
      "57/57 [==============================] - 1s 7ms/step loss: 0.3652 - accuracy: 0.82\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3784 - accuracy: 0.8054\n",
      " 42/113 [==========>...................] - ETA: 0s - loss: 0.3932 - accuracy: 0.8073Epoch 20/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3714 - accuracy: 0.8228\n",
      "Epoch 17/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3677 - accuracy: 0.8206\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3854 - accuracy: 0.8110\n",
      " 25/113 [=====>........................] - ETA: 0s - loss: 0.3755 - accuracy: 0.8275Epoch 20/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.4011 - accuracy: 0.8026\n",
      " 72/113 [==================>...........] - ETA: 0s - loss: 0.3805 - accuracy: 0.8199Epoch 7/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.4066 - accuracy: 0.8093\n",
      "  7/113 [>.............................] - ETA: 0s - loss: 0.3781 - accuracy: 0.8214Epoch 7/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3758 - accuracy: 0.8123\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3736 - accuracy: 0.8215\n",
      "24/57 [===========>..................] - ETA: 0sEpoch 18/300.3692 - accuracy: 0.82\n",
      " 58/113 [==============>...............] - ETA: 0s - loss: 0.3926 - accuracy: 0.7899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 7ms/step loss: 0.3610 - accuracy: 0.82\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3699 - accuracy: 0.8240\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3877 - accuracy: 0.8137\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3983 - accuracy: 0.7960\n",
      "Epoch 8/30\n",
      "22/57 [==========>...................] - ETA: 0s0s - loss: 0.4024 - accuracy: 0.80"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 8ms/step - loss: 0.4033 - accuracy: 0.8040\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 6ms/step\n",
      "57/57 [==============================] - 0s 5ms/step loss: 0.3859 - accuracy: 0.83\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3784 - accuracy: 0.8226\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 0s 5ms/step loss: 0.4067 - accuracy: 0.7881\n",
      " 73/113 [==================>...........] - ETA: 0s - loss: 0.4096 - accuracy: 0.7868Epoch 1/10\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.4000 - accuracy: 0.7979\n",
      "Epoch 9/30\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.4014 - accuracy: 0.8088\n",
      "Epoch 9/30\n",
      " 1/57 [..............................] - ETA: 9s0s - loss: 0.3678 - accuracy: 0.8283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3715 - accuracy: 0.8245\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 0s 5ms/step loss: 0.3982 - accuracy: 0.8007\n",
      "57/57 [==============================] - 0s 6ms/step loss: 0.4047 - accuracy: 0.79\n",
      " 56/113 [=============>................] - ETA: 0s - loss: 0.4098 - accuracy: 0.8041Epoch 1/10\n",
      " 98/113 [=========================>....] - ETA: 0s - loss: 0.3956 - accuracy: 0.8010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3925 - accuracy: 0.8059\n",
      "Epoch 10/30\n",
      " 20/113 [====>.........................] - ETA: 0s - loss: 0.3739 - accuracy: 0.8188Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 6ms/step - loss: 0.4060 - accuracy: 0.7985\n",
      "Epoch 10/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3725 - accuracy: 0.8248\n",
      "Epoch 21/30\n",
      " 66/113 [================>.............] - ETA: 0s - loss: 0.3578 - accuracy: 0.8291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 6ms/step\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3885 - accuracy: 0.8076\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 2s 8ms/step - loss: 0.5403 - accuracy: 0.7294\n",
      "104/113 [==========================>...] - ETA: 0s - loss: 0.3645 - accuracy: 0.8290Epoch 2/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3997 - accuracy: 0.8065\n",
      "Epoch 11/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3692 - accuracy: 0.8259\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4664 - accuracy: 0.7677\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3894 - accuracy: 0.8070\n",
      "Epoch 12/30\n",
      "26/57 [============>.................] - ETA: 0s - loss: 0.4351 - accuracy: 0.788522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3967 - accuracy: 0.8099\n",
      "Epoch 12/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3665 - accuracy: 0.8289\n",
      " 33/113 [=======>......................] - ETA: 0s - loss: 0.3642 - accuracy: 0.8172Epoch 23/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.4384 - accuracy: 0.7893\n",
      "Epoch 4/10\n",
      "15/57 [======>.......................] - ETA: 0s - loss: 0.6214 - accuracy: 0.6583Epoch 1/20\n",
      "57/57 [==============================] - 3s 10ms/step - loss: 0.5464 - accuracy: 0.7266\n",
      " 59/113 [==============>...............] - ETA: 0s - loss: 0.3962 - accuracy: 0.8109Epoch 2/10\n",
      "57/57 [==============================] - 3s 11ms/step - loss: 0.5570 - accuracy: 0.7040\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3856 - accuracy: 0.8109\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4158 - accuracy: 0.8034\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3956 - accuracy: 0.8068\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4691 - accuracy: 0.7696\n",
      " 29/113 [======>.......................] - ETA: 0s - loss: 0.3684 - accuracy: 0.8254Epoch 3/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3665 - accuracy: 0.8237\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4749 - accuracy: 0.7647\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4089 - accuracy: 0.8101\n",
      " 72/113 [==================>...........] - ETA: 0s - loss: 0.3831 - accuracy: 0.8155Epoch 6/10\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4356 - accuracy: 0.7896\n",
      " 82/113 [====================>.........] - ETA: 0s - loss: 0.3987 - accuracy: 0.8041Epoch 4/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3880 - accuracy: 0.8098\n",
      "Epoch 14/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3952 - accuracy: 0.8063\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4447 - accuracy: 0.7802\n",
      "32/57 [===============>..............] - ETA: 0s - loss: 0.4236 - accuracy: 0.7861Epoch 4/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3991 - accuracy: 0.8129\n",
      " 20/113 [====>.........................] - ETA: 0s - loss: 0.3715 - accuracy: 0.8188Epoch 7/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3649 - accuracy: 0.8248\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4250 - accuracy: 0.7874\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4324 - accuracy: 0.7869\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3955 - accuracy: 0.8068\n",
      " 79/113 [===================>..........] - ETA: 0s - loss: 0.3857 - accuracy: 0.8062Epoch 8/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4131 - accuracy: 0.7896\n",
      "17/57 [=======>......................] - ETA: 0s - loss: 0.3942 - accuracy: 0.8116Epoch 6/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3855 - accuracy: 0.8026\n",
      "Epoch 15/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.3895 - accuracy: 0.8146\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.4003 - accuracy: 0.8079Epoch 15/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4182 - accuracy: 0.7996\n",
      "48/57 [========================>.....] - ETA: 0s - loss: 0.5539 - accuracy: 0.7230Epoch 6/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3983 - accuracy: 0.8090\n",
      " 16/113 [===>..........................] - ETA: 0s - loss: 0.3840 - accuracy: 0.8125Epoch 9/10\n",
      "57/57 [==============================] - 3s 10ms/step - loss: 0.5406 - accuracy: 0.7297\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.3659 - accuracy: 0.8256\n",
      "54/57 [===========================>..] - ETA: 0s - loss: 0.4012 - accuracy: 0.8056Epoch 26/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4019 - accuracy: 0.8045\n",
      " 36/113 [========>.....................] - ETA: 0s - loss: 0.3982 - accuracy: 0.8038Epoch 7/10\n",
      "57/57 [==============================] - 1s 6ms/steposs: 0.4761 - accuracy: 0.7681\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4127 - accuracy: 0.8040\n",
      "56/57 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8136Epoch 7/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3923 - accuracy: 0.8129\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4654 - accuracy: 0.7693\n",
      " 64/113 [===============>..............] - ETA: 0s - loss: 0.3491 - accuracy: 0.8389Epoch 3/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3872 - accuracy: 0.8070\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3962 - accuracy: 0.8045\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 5ms/step loss: 0.3606 - accuracy: 0.82\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3943 - accuracy: 0.8063\n",
      "33/57 [================>.............] - ETA: 0s - loss: 0.4120 - accuracy: 0.8035Epoch 16/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.4101 - accuracy: 0.8013\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3888 - accuracy: 0.8129\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3704 - accuracy: 0.8259\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8023\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4326 - accuracy: 0.7932\n",
      "21/57 [==========>...................] - ETA: 0s - loss: 0.4069 - accuracy: 0.8051Epoch 4/20\n",
      "24/57 [===========>..................] - ETA: 0s - loss: 0.3875 - accuracy: 0.8034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8071\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3843 - accuracy: 0.8112\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.4232 - accuracy: 0.7935Epoch 17/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8034\n",
      "49/57 [========================>.....] - ETA: 0s - loss: 0.4225 - accuracy: 0.7930Epoch 10/10\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3914 - accuracy: 0.8126\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.4215 - accuracy: 0.7968\n",
      "Epoch 1/20\n",
      "Epoch 5/20\n",
      "50/57 [=========================>....] - ETA: 0s - loss: 0.4040 - accuracy: 0.8047Epoch 1/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3635 - accuracy: 0.8303\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4025 - accuracy: 0.8065\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8001\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8037\n",
      " 67/113 [================>.............] - ETA: 0s - loss: 0.3991 - accuracy: 0.8050Epoch 6/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8057\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3776 - accuracy: 0.8112\n",
      "Epoch 18/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3898 - accuracy: 0.8110\n",
      " 1/57 [..............................] - ETA: 6sEpoch 18/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8095\n",
      " 10/113 [=>............................] - ETA: 0s - loss: 0.3521 - accuracy: 0.8375Epoch 7/20\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3598 - accuracy: 0.8292\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 0s 5ms/step loss: 0.3828 - accuracy: 0.80\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8106\n",
      "30/57 [==============>...............] - ETA: 0sEpoch 8/20\n",
      "57/57 [==============================] - 0s 4ms/step loss: 0.3840 - accuracy: 0.81\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3900 - accuracy: 0.8135\n",
      "Epoch 19/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3797 - accuracy: 0.8131\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3642 - accuracy: 0.8223\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8167\n",
      " 24/113 [=====>........................] - ETA: 0s - loss: 0.4242 - accuracy: 0.7930Epoch 9/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.8170\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 2s 9ms/step - loss: 0.5453 - accuracy: 0.7261\n",
      " 76/113 [===================>..........] - ETA: 0s - loss: 0.3576 - accuracy: 0.8343Epoch 2/20\n",
      "57/57 [==============================] - 2s 8ms/step - loss: 0.5620 - accuracy: 0.7051\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.5418 - accuracy: 0.7344Epoch 2/20\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3868 - accuracy: 0.8088\n",
      "Epoch 20/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3788 - accuracy: 0.8073\n",
      "Epoch 20/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3605 - accuracy: 0.8323\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.7680\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3849 - accuracy: 0.8203\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.7600\n",
      "Epoch 3/20\n",
      " 49/113 [============>.................] - ETA: 0s - loss: 0.3916 - accuracy: 0.8106Epoch 11/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7796\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.7797\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3777 - accuracy: 0.8084\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8179\n",
      "  1/113 [..............................] - ETA: 0s - loss: 0.4278 - accuracy: 0.7812Epoch 12/20\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3857 - accuracy: 0.8090\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7935\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7924\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3864 - accuracy: 0.8151\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3725 - accuracy: 0.8165\n",
      "Epoch 22/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3864 - accuracy: 0.8157\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.7962\n",
      "Epoch 6/20\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7985\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3808 - accuracy: 0.8231\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4027 - accuracy: 0.7976\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.4160 - accuracy: 0.7993\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3790 - accuracy: 0.8203\n",
      " 1/57 [..............................] - ETA: 7sEpoch 15/20\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3849 - accuracy: 0.8085\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.3966 - accuracy: 0.8101Epoch 23/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3738 - accuracy: 0.8134\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 0s 5ms/step loss: 0.4102 - accuracy: 0.78\n",
      "57/57 [==============================] - 0s 5ms/steposs: 0.4082 - accuracy: 0.80\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3973 - accuracy: 0.8082\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8013\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8131\n",
      "14/57 [======>.......................] - ETA: 0s - loss: 0.4130 - accuracy: 0.7913Epoch 16/20\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.4477 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.7979\n",
      " 1/57 [..............................] - ETA: 9sEpoch 9/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4080 - accuracy: 0.8060\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8251\n",
      "Epoch 17/20\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.4129 - accuracy: 0.8125Epoch 1/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3830 - accuracy: 0.8121\n",
      "Epoch 24/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3716 - accuracy: 0.8118\n",
      "57/57 [==============================] - 0s 5ms/step\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8026\n",
      " 32/113 [=======>......................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8242Epoch 10/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8104\n",
      "Epoch 10/20\n",
      " 51/113 [============>.................] - ETA: 0s - loss: 0.3608 - accuracy: 0.8229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3727 - accuracy: 0.8217\n",
      "14/57 [======>.......................] - ETA: 0s - loss: 0.4018 - accuracy: 0.7824Epoch 18/20\n",
      "32/57 [===============>..............] - ETA: 0s - loss: 0.3964 - accuracy: 0.8115Epoch 1/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8001\n",
      "110/113 [============================>.] - ETA: 0s - loss: 0.3792 - accuracy: 0.8145Epoch 11/20\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3798 - accuracy: 0.8146\n",
      "Epoch 25/30\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3714 - accuracy: 0.8165\n",
      "  1/113 [..............................] - ETA: 0s - loss: 0.2737 - accuracy: 0.9062Epoch 25/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8038\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3746 - accuracy: 0.8226\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8057\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8076\n",
      "Epoch 12/20\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8234\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3736 - accuracy: 0.8176\n",
      "Epoch 26/30\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3818 - accuracy: 0.8157\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.7968\n",
      "14/57 [======>.......................] - ETA: 0s - loss: 0.6252 - accuracy: 0.6596Epoch 13/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8048\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3713 - accuracy: 0.8198\n",
      "57/57 [==============================] - 2s 8ms/step - loss: 0.5426 - accuracy: 0.7280\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3914 - accuracy: 0.8132\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8090\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.4668 - accuracy: 0.8125Epoch 14/20\n",
      "113/113 [==============================] - 1s 6ms/step - loss: 0.3708 - accuracy: 0.8104\n",
      "16/57 [=======>......................] - ETA: 0s - loss: 0.3829 - accuracy: 0.8057Epoch 27/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3800 - accuracy: 0.8179\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7774\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 0s 5ms/step loss: 0.3637 - accuracy: 0.82\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8034\n",
      " 8/57 [===>..........................] - ETA: 0s - loss: 0.6468 - accuracy: 0.6406  Epoch 15/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3917 - accuracy: 0.8118\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 2s 8ms/step - loss: 0.5459 - accuracy: 0.7280\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7918\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8010\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8032\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.3538 - accuracy: 0.8125Epoch 16/20\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3713 - accuracy: 0.8140\n",
      "Epoch 28/30\n",
      "15/57 [======>.......................] - ETA: 0s - loss: 0.4186 - accuracy: 0.7885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3812 - accuracy: 0.8187\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4697 - accuracy: 0.7638\n",
      "55/57 [===========================>..] - ETA: 0s - loss: 0.3841 - accuracy: 0.8060Epoch 3/30\n",
      "Epoch 1/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3836 - accuracy: 0.8068\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.3491 - accuracy: 0.8594Epoch 17/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3950 - accuracy: 0.8054\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.3322 - accuracy: 0.8438Epoch 17/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4165 - accuracy: 0.8004\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 1s 6ms/steposs: 0.3800 - accuracy: 0.8380\n",
      " 98/113 [=========================>....] - ETA: 0s - loss: 0.3795 - accuracy: 0.8103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.7865\n",
      "Epoch 4/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3672 - accuracy: 0.8090\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3819 - accuracy: 0.8093\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.4148 - accuracy: 0.8010Epoch 29/30\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3900 - accuracy: 0.8129\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3792 - accuracy: 0.8135\n",
      "Epoch 18/20\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4082 - accuracy: 0.8090\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3763 - accuracy: 0.8156\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.4193 - accuracy: 0.7926\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8079\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3890 - accuracy: 0.8146\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.3671 - accuracy: 0.8165\n",
      "Epoch 30/30\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3786 - accuracy: 0.8157\n",
      "  6/113 [>.............................] - ETA: 1s - loss: 0.3748 - accuracy: 0.8125Epoch 30/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.3786 - accuracy: 0.8112\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7907\n",
      "Epoch 20/20\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3950 - accuracy: 0.8159\n",
      " 7/57 [==>...........................] - ETA: 0s - loss: 0.3844 - accuracy: 0.8058Epoch 8/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3915 - accuracy: 0.8054\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8034\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.4085 - accuracy: 0.8001\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8106\n",
      " 8/57 [===>..........................] - ETA: 0s - loss: 0.4044 - accuracy: 0.8086Epoch 9/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8160\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3657 - accuracy: 0.8179\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.3762 - accuracy: 0.8207\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.7904\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8118\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 3s 8ms/step - loss: 0.5547 - accuracy: 0.7098\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 0s 5ms/steposs: 0.3975 - accuracy: 0.79\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8004\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3890 - accuracy: 0.8151\n",
      " 8/57 [===>..........................] - ETA: 0s - loss: 0.3903 - accuracy: 0.8145Epoch 11/30\n",
      "57/57 [==============================] - 0s 5ms/steposs: 0.4968 - accuracy: 0.74\n",
      "57/57 [==============================] - 1s 6ms/step\n",
      "22/57 [==========>...................] - ETA: 0s - loss: 0.3851 - accuracy: 0.8118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.7608\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3904 - accuracy: 0.8051\n",
      "48/57 [========================>.....] - ETA: 0s - loss: 0.3873 - accuracy: 0.8180Epoch 10/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3905 - accuracy: 0.8137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4515 - accuracy: 0.7808\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 0s 6ms/steposs: 0.3895 - accuracy: 0.81\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3928 - accuracy: 0.8098\n",
      "31/57 [===============>..............] - ETA: 0sEpoch 11/30\n",
      "57/57 [==============================] - 0s 5ms/steposs: 0.4405 - accuracy: 0.78\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3849 - accuracy: 0.8181\n",
      "Epoch 13/30\n",
      "48/57 [========================>.....] - ETA: 0sEpoch 1/10.4365 - accuracy: 0.78\n",
      "57/57 [==============================] - 1s 7ms/steposs: 0.4360 - accuracy: 0.78\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4315 - accuracy: 0.7930\n",
      "28/57 [=============>................] - ETA: 0s - loss: 0.3898 - accuracy: 0.7991Epoch 5/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3876 - accuracy: 0.8093\n",
      "31/57 [===============>..............] - ETA: 0s - loss: 0.4163 - accuracy: 0.7954Epoch 12/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3811 - accuracy: 0.8215\n",
      "Epoch 14/30\n",
      " 5/57 [=>............................] - ETA: 0s - loss: 0.2938 - accuracy: 0.8875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4233 - accuracy: 0.7924\n",
      "Epoch 6/30\n",
      "54/57 [===========================>..] - ETA: 0s - loss: 0.3799 - accuracy: 0.8229Epoch 1/10\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.3792 - accuracy: 0.8231\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3855 - accuracy: 0.8087\n",
      "Epoch 13/30\n",
      "48/57 [========================>.....] - ETA: 0s - loss: 0.4138 - accuracy: 0.8093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 9ms/steposs: 0.3808 - accuracy: 0.81\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4132 - accuracy: 0.8016\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 7ms/steposs: 0.3967 - accuracy: 0.80\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.3788 - accuracy: 0.8215\n",
      "Epoch 16/30\n",
      "46/57 [=======================>......] - ETA: 0s - loss: 0.3816 - accuracy: 0.8101Epoch 1/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3873 - accuracy: 0.8065\n",
      "16/57 [=======>......................] - ETA: 0s - loss: 0.3779 - accuracy: 0.8281Epoch 14/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.4092 - accuracy: 0.8049\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3744 - accuracy: 0.8240\n",
      "43/57 [=====================>........] - ETA: 0s - loss: 0.3841 - accuracy: 0.8085Epoch 17/30\n",
      "34/57 [================>.............] - ETA: 0s - loss: 0.4149 - accuracy: 0.7909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3865 - accuracy: 0.8079\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.4077 - accuracy: 0.7979\n",
      "30/57 [==============>...............] - ETA: 0sEpoch 9/30.6624 - accuracy: 0.6406\n",
      "45/57 [======================>.......] - ETA: 0s - loss: 0.5794 - accuracy: 0.7144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 11ms/step - loss: 0.5719 - accuracy: 0.7108\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 9ms/steposs: 0.5136 - accuracy: 0.75\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3731 - accuracy: 0.8240\n",
      "48/57 [========================>.....] - ETA: 0s - loss: 0.3842 - accuracy: 0.8076Epoch 18/30\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3844 - accuracy: 0.8101\n",
      "42/57 [=====================>........] - ETA: 0s - loss: 0.4022 - accuracy: 0.8136Epoch 16/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.4946 - accuracy: 0.7580\n",
      " 6/57 [==>...........................] - ETA: 0s - loss: 0.3812 - accuracy: 0.8151Epoch 3/10\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.4022 - accuracy: 0.8104\n",
      "24/57 [===========>..................] - ETA: 0s - loss: 0.3883 - accuracy: 0.8197Epoch 10/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4636 - accuracy: 0.7749\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3727 - accuracy: 0.8240\n",
      " 5/29 [====>.........................] - ETA: 0s - loss: 0.6660 - accuracy: 0.6094  Epoch 19/30\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3818 - accuracy: 0.8106\n",
      "14/29 [=============>................] - ETA: 0s - loss: 0.4517 - accuracy: 0.7790Epoch 17/30\n",
      "29/29 [==============================] - 3s 13ms/step - loss: 0.5740 - accuracy: 0.7058\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.4029 - accuracy: 0.8010\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.5070 - accuracy: 0.7656Epoch 11/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4408 - accuracy: 0.7865\n",
      " 6/29 [=====>........................] - ETA: 0s - loss: 0.5106 - accuracy: 0.7474Epoch 5/10\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.5008 - accuracy: 0.7519\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.4307 - accuracy: 0.7920Epoch 3/10\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3772 - accuracy: 0.8231\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4250 - accuracy: 0.7976\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3819 - accuracy: 0.8076\n",
      "18/29 [=================>............] - ETA: 0s - loss: 0.4712 - accuracy: 0.7652Epoch 18/30\n",
      "29/29 [==============================] - 3s 17ms/step - loss: 0.5889 - accuracy: 0.6768\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4657 - accuracy: 0.7696\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3983 - accuracy: 0.8099\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.4144 - accuracy: 0.8032\n",
      "21/57 [==========>...................] - ETA: 0s - loss: 0.3625 - accuracy: 0.8237Epoch 7/10\n",
      "13/29 [============>.................] - ETA: 0s - loss: 0.4392 - accuracy: 0.7933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 15ms/step - loss: 0.5062 - accuracy: 0.7478\n",
      "14/29 [=============>................] - ETA: 0s - loss: 0.4155 - accuracy: 0.7946Epoch 3/10\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4448 - accuracy: 0.7838\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3732 - accuracy: 0.8192\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.4592 - accuracy: 0.7969Epoch 21/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4069 - accuracy: 0.8057\n",
      "38/57 [===================>..........] - ETA: 0s - loss: 0.4040 - accuracy: 0.8043Epoch 8/10\n",
      "57/57 [==============================] - 1s 10ms/stepss: 0.3711 - accuracy: 0.81\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3751 - accuracy: 0.8156\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 1s 10ms/step\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4723 - accuracy: 0.7691\n",
      "32/57 [===============>..............] - ETA: 0s - loss: 0.3727 - accuracy: 0.8242Epoch 4/10\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3988 - accuracy: 0.8024\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4265 - accuracy: 0.7923\n",
      "11/57 [====>.........................] - ETA: 0s - loss: 0.4090 - accuracy: 0.7827Epoch 6/10\n",
      " 6/29 [=====>........................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8047Epoch 1/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8051\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3710 - accuracy: 0.8248\n",
      "10/29 [=========>....................] - ETA: 0s - loss: 0.4119 - accuracy: 0.8078Epoch 22/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.4491 - accuracy: 0.7844\n",
      "18/29 [=================>............] - ETA: 0s - loss: 0.4183 - accuracy: 0.7990Epoch 5/10\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.4152 - accuracy: 0.8040\n",
      "33/57 [================>.............] - ETA: 0sEpoch 7/10\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3954 - accuracy: 0.8112\n",
      "26/57 [============>.................] - ETA: 0sEpoch 10/103990 - accuracy: 0.80\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3800 - accuracy: 0.8051\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.4009 - accuracy: 0.8040\n",
      "57/57 [==============================] - 1s 8ms/step\n",
      "35/57 [=================>............] - ETA: 0s - loss: 0.3721 - accuracy: 0.8156Epoch 14/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4341 - accuracy: 0.7866\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4078 - accuracy: 0.7987\n",
      "57/57 [==============================] - 1s 8ms/step\n",
      "13/29 [============>.................] - ETA: 0s - loss: 0.3792 - accuracy: 0.8263Epoch 8/10\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3704 - accuracy: 0.8203\n",
      "Epoch 23/30\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.3871 - accuracy: 0.8238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 18ms/step - loss: 0.3937 - accuracy: 0.8165\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4305 - accuracy: 0.7880\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.4026 - accuracy: 0.8034Epoch 7/10\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4020 - accuracy: 0.8029\n",
      " 5/29 [====>.........................] - ETA: 0s - loss: 0.4274 - accuracy: 0.7937Epoch 9/10\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3934 - accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      " 8/29 [=======>......................] - ETA: 0s - loss: 0.4090 - accuracy: 0.7959Epoch 1/20\n",
      "40/57 [====================>.........] - ETA: 0s - loss: 0.3681 - accuracy: 0.8230Epoch 1/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.3776 - accuracy: 0.8143\n",
      "20/29 [===================>..........] - ETA: 0s - loss: 0.4053 - accuracy: 0.7973Epoch 21/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4217 - accuracy: 0.7988\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3710 - accuracy: 0.8245\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4000 - accuracy: 0.8043\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.7960\n",
      "51/57 [=========================>....] - ETA: 0s - loss: 0.3907 - accuracy: 0.8122Epoch 9/10\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3941 - accuracy: 0.8099\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.3960 - accuracy: 0.8012\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3759 - accuracy: 0.8051\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3672 - accuracy: 0.8301\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4072 - accuracy: 0.8086Epoch 25/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.4065 - accuracy: 0.8093\n",
      "10/57 [====>.........................] - ETA: 0s - loss: 0.3907 - accuracy: 0.8203Epoch 10/10\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.4047 - accuracy: 0.8049\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3904 - accuracy: 0.8160\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3759 - accuracy: 0.8087\n",
      " 5/57 [=>............................] - ETA: 0s - loss: 0.4307 - accuracy: 0.7719Epoch 23/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3672 - accuracy: 0.8278\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 1s 7ms/steposs: 0.3632 - accuracy: 0.83\n",
      "38/57 [===================>..........] - ETA: 0s - loss: 0.3723 - accuracy: 0.8232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 15ms/step - loss: 0.5712 - accuracy: 0.7119\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3875 - accuracy: 0.8126\n",
      "Epoch 2/20\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3726 - accuracy: 0.8195\n",
      "18/57 [========>.....................] - ETA: 0s - loss: 0.3687 - accuracy: 0.8281Epoch 24/30\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 0.3725 - accuracy: 0.8220\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.3884 - accuracy: 0.7656Epoch 27/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4913 - accuracy: 0.7613\n",
      " 5/29 [====>.........................] - ETA: 0s - loss: 0.6717 - accuracy: 0.5969  Epoch 3/20\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3872 - accuracy: 0.8157\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 1s 10ms/stepss: 0.4421 - accuracy: 0.7570  \n",
      "29/29 [==============================] - 3s 17ms/step - loss: 0.5867 - accuracy: 0.6918\n",
      "53/57 [==========================>...] - ETA: 0s - loss: 0.3725 - accuracy: 0.8157Epoch 2/20\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3743 - accuracy: 0.8148\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.4584 - accuracy: 0.7796\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.5829 - accuracy: 0.7001Epoch 4/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.3664 - accuracy: 0.8292\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 3s 16ms/step - loss: 0.5759 - accuracy: 0.7050\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.4764 - accuracy: 0.7969Epoch 2/20\n",
      "57/57 [==============================] - 1s 10ms/stepss: 0.4448 - accuracy: 0.77\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.5083 - accuracy: 0.7400\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4402 - accuracy: 0.7810\n",
      "28/57 [=============>................] - ETA: 0s - loss: 0.3658 - accuracy: 0.8265Epoch 5/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3895 - accuracy: 0.8057\n",
      " 7/29 [======>.......................] - ETA: 0s - loss: 0.4925 - accuracy: 0.7567Epoch 20/30\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.4997 - accuracy: 0.7544\n",
      " 7/29 [======>.......................] - ETA: 0s - loss: 0.4308 - accuracy: 0.7835Epoch 3/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.3679 - accuracy: 0.8278\n",
      "12/29 [===========>..................] - ETA: 0s - loss: 0.4853 - accuracy: 0.7572Epoch 29/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.7730\n",
      "22/29 [=====================>........] - ETA: 0s - loss: 0.4288 - accuracy: 0.7919Epoch 4/20\n",
      "23/57 [===========>..................] - ETA: 0s - loss: 0.3954 - accuracy: 0.8105Epoch 1/30\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.3738 - accuracy: 0.8120\n",
      " 6/29 [=====>........................] - ETA: 0s - loss: 0.4582 - accuracy: 0.7786Epoch 26/30\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 0.4258 - accuracy: 0.7923\n",
      "33/57 [================>.............] - ETA: 0s - loss: 0.4037 - accuracy: 0.7997Epoch 6/20\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4672 - accuracy: 0.7691\n",
      " 9/57 [===>..........................] - ETA: 0s - loss: 0.3622 - accuracy: 0.8212Epoch 4/20\n",
      "47/57 [=======================>......] - ETA: 0s - loss: 0.3929 - accuracy: 0.8082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4537 - accuracy: 0.7788\n",
      "18/29 [=================>............] - ETA: 0s - loss: 0.4250 - accuracy: 0.7990Epoch 5/20\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3866 - accuracy: 0.8101\n",
      " 8/29 [=======>......................] - ETA: 0s - loss: 0.4067 - accuracy: 0.8135Epoch 21/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4439 - accuracy: 0.7849\n",
      "14/29 [=============>................] - ETA: 0s - loss: 0.4240 - accuracy: 0.7974Epoch 5/20\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.4147 - accuracy: 0.8054\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.4330 - accuracy: 0.7888\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3682 - accuracy: 0.8140\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.3640 - accuracy: 0.8298\n",
      " 9/29 [========>.....................] - ETA: 0s - loss: 0.4238 - accuracy: 0.7917Epoch 30/30\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.4276 - accuracy: 0.7879\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.4063 - accuracy: 0.8104\n",
      "13/57 [=====>........................] - ETA: 0s - loss: 0.3506 - accuracy: 0.8317Epoch 1/30\n",
      "24/29 [=======================>......] - ETA: 0s - loss: 0.4272 - accuracy: 0.7917Epoch 8/20\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4210 - accuracy: 0.7974\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3882 - accuracy: 0.8101\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3991 - accuracy: 0.8137\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.4156 - accuracy: 0.8016\n",
      " 9/57 [===>..........................] - ETA: 0s - loss: 0.3213 - accuracy: 0.8594Epoch 8/20\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.4185 - accuracy: 0.7971\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 11ms/stepss: 0.3563 - accuracy: 0.8386\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3754 - accuracy: 0.8131\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3642 - accuracy: 0.8287\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3977 - accuracy: 0.8062\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4137 - accuracy: 0.8024\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4066 - accuracy: 0.8004\n",
      "17/57 [=======>......................] - ETA: 0s - loss: 0.3764 - accuracy: 0.8180Epoch 9/20\n",
      " 9/29 [========>.....................] - ETA: 0s - loss: 0.3955 - accuracy: 0.8177Epoch 8/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.3825 - accuracy: 0.8090\n",
      "10/29 [=========>....................] - ETA: 0s - loss: 0.3814 - accuracy: 0.8195Epoch 23/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3936 - accuracy: 0.8159\n",
      "Epoch 11/20\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.4059 - accuracy: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4017 - accuracy: 0.8045\n",
      "57/57 [==============================] - 1s 9ms/step\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.4073 - accuracy: 0.8040\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.3615 - accuracy: 0.8203Epoch 10/20\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.3704 - accuracy: 0.8201\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3920 - accuracy: 0.8154\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.3874 - accuracy: 0.8118Epoch 12/20\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3844 - accuracy: 0.8107\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4062 - accuracy: 0.8005Epoch 24/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.4055 - accuracy: 0.8010\n",
      " 1/57 [..............................] - ETA: 0s - loss: 0.4015 - accuracy: 0.7812Epoch 11/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3981 - accuracy: 0.8073\n",
      "16/57 [=======>......................] - ETA: 0s - loss: 0.3840 - accuracy: 0.7949Epoch 10/20\n",
      "57/57 [==============================] - 1s 8ms/steposs: 0.3538 - accuracy: 0.8447\n",
      " 8/29 [=======>......................] - ETA: 0s - loss: 0.3976 - accuracy: 0.7988Epoch 1/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.3905 - accuracy: 0.8162\n",
      "17/57 [=======>......................] - ETA: 0s - loss: 0.3699 - accuracy: 0.8217Epoch 13/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3970 - accuracy: 0.8032\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4037 - accuracy: 0.8035\n",
      "22/29 [=====================>........] - ETA: 0s - loss: 0.5801 - accuracy: 0.7003Epoch 12/20\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3719 - accuracy: 0.8170\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 4s 15ms/step - loss: 0.5693 - accuracy: 0.7064\n",
      "10/29 [=========>....................] - ETA: 0s - loss: 0.3930 - accuracy: 0.8078Epoch 2/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3888 - accuracy: 0.8129\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3826 - accuracy: 0.8176\n",
      "14/29 [=============>................] - ETA: 0s - loss: 0.3969 - accuracy: 0.8041Epoch 25/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3961 - accuracy: 0.8059\n",
      "21/57 [==========>...................] - ETA: 0s - loss: 0.3974 - accuracy: 0.8103Epoch 12/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4024 - accuracy: 0.8101\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.3853 - accuracy: 0.8206Epoch 13/20\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.3842 - accuracy: 0.8212\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4919 - accuracy: 0.7555\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3866 - accuracy: 0.8135\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.3982 - accuracy: 0.8089Epoch 26/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3924 - accuracy: 0.8068\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3788 - accuracy: 0.8106\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3966 - accuracy: 0.8107\n",
      "22/29 [=====================>........] - ETA: 0s - loss: 0.4691 - accuracy: 0.7781Epoch 14/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3826 - accuracy: 0.8245\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4657 - accuracy: 0.7749\n",
      " 9/29 [========>.....................] - ETA: 0s - loss: 0.3939 - accuracy: 0.8186Epoch 4/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3901 - accuracy: 0.8090\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4023 - accuracy: 0.8068\n",
      "26/29 [=========================>....] - ETA: 0s - loss: 0.5750 - accuracy: 0.7040Epoch 15/20\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3833 - accuracy: 0.8195\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 4s 16ms/step - loss: 0.5697 - accuracy: 0.7083\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.7860\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 1s 9ms/steposs: 0.3867 - accuracy: 0.81\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.3834 - accuracy: 0.8124\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3826 - accuracy: 0.8223\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3861 - accuracy: 0.8118\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.3945 - accuracy: 0.8113\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4981 - accuracy: 0.7521\n",
      " 6/29 [=====>........................] - ETA: 0s - loss: 0.3727 - accuracy: 0.8216Epoch 3/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4305 - accuracy: 0.7887\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.4868 - accuracy: 0.7344Epoch 6/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3764 - accuracy: 0.8226\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3879 - accuracy: 0.8070\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3955 - accuracy: 0.8076\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.4119 - accuracy: 0.8051Epoch 17/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4672 - accuracy: 0.7738\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.4140 - accuracy: 0.8043\n",
      " 8/29 [=======>......................] - ETA: 0s - loss: 0.4093 - accuracy: 0.7900Epoch 7/30\n",
      "57/57 [==============================] - 1s 11ms/stepss: 0.3707 - accuracy: 0.82\n",
      "50/57 [=========================>....] - ETA: 0s - loss: 0.3760 - accuracy: 0.8194Epoch 4/30\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 0.3789 - accuracy: 0.8168\n",
      "30/57 [==============>...............] - ETA: 0sEpoch 28/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3947 - accuracy: 0.8118\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3760 - accuracy: 0.8201\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 1s 7ms/steposs: 0.4425 - accuracy: 0.7806\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3830 - accuracy: 0.8106\n",
      "13/57 [=====>........................] - ETA: 0s - loss: 0.3849 - accuracy: 0.8125Epoch 17/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.4081 - accuracy: 0.8051\n",
      " 9/29 [========>.....................] - ETA: 0s - loss: 0.4017 - accuracy: 0.8108Epoch 8/30\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.4385 - accuracy: 0.7838\n",
      "12/29 [===========>..................] - ETA: 0s - loss: 0.3919 - accuracy: 0.8177Epoch 5/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3754 - accuracy: 0.8234\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 0.3908 - accuracy: 0.8143\n",
      "19/29 [==================>...........] - ETA: 0s - loss: 0.4046 - accuracy: 0.8137Epoch 19/20\n",
      "29/29 [==============================] - 3s 14ms/step - loss: 0.5865 - accuracy: 0.6868\n",
      "57/57 [==============================] - 1s 9ms/step\n",
      "44/57 [======================>.......] - ETA: 0s - loss: 0.3826 - accuracy: 0.8171Epoch 2/30\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 0.3830 - accuracy: 0.8104\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3995 - accuracy: 0.8137\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.3835 - accuracy: 0.8179\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 1s 17ms/step - loss: 0.4242 - accuracy: 0.7896\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.3942 - accuracy: 0.8085\n",
      "14/57 [======>.......................] - ETA: 0s - loss: 0.3603 - accuracy: 0.8281Epoch 20/20\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.7395\n",
      "24/29 [=======================>......] - ETA: 0s - loss: 0.3967 - accuracy: 0.8148Epoch 3/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.3830 - accuracy: 0.8090\n",
      "12/29 [===========>..................] - ETA: 0s - loss: 0.3915 - accuracy: 0.8053Epoch 19/20\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.3982 - accuracy: 0.8129\n",
      "18/29 [=================>............] - ETA: 0s - loss: 0.3852 - accuracy: 0.8129Epoch 10/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.4171 - accuracy: 0.7932\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.3885 - accuracy: 0.8160\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.4730 - accuracy: 0.7664\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.3788 - accuracy: 0.8154\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3805 - accuracy: 0.8154\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.4099 - accuracy: 0.7971\n",
      "Epoch 20/20\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.3941 - accuracy: 0.8148\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.4525 - accuracy: 0.7808\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.3791 - accuracy: 0.8115\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.4037 - accuracy: 0.8084\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.3915 - accuracy: 0.8181\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.3781 - accuracy: 0.8137\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.7885\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.4011 - accuracy: 0.8015\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3908 - accuracy: 0.8181\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4282 - accuracy: 0.7921\n",
      "12/29 [===========>..................] - ETA: 0s - loss: 0.3773 - accuracy: 0.8197Epoch 7/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.3860 - accuracy: 0.8176\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.3993 - accuracy: 0.8048\n",
      "Epoch 14/30\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.4225 - accuracy: 0.7919\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 7ms/steposs: 0.3740 - accuracy: 0.83\n",
      "57/57 [==============================] - 1s 6ms/steposs: 0.3976 - accuracy: 0.80\n",
      "57/57 [==============================] - 0s 6ms/steposs: 0.3770 - accuracy: 0.82\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.3952 - accuracy: 0.8043\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.3807 - accuracy: 0.8245\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4212 - accuracy: 0.7866\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3954 - accuracy: 0.8068\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3887 - accuracy: 0.8181\n",
      "24/29 [=======================>......] - ETA: 0s - loss: 0.4173 - accuracy: 0.7956Epoch 16/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4142 - accuracy: 0.7968\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3876 - accuracy: 0.8143\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3817 - accuracy: 0.8228\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8046\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 0s 5ms/steposs: 0.4090 - accuracy: 0.79\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.8015\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8082\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3857 - accuracy: 0.8148\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8159\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3852 - accuracy: 0.8151\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3983 - accuracy: 0.8079\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8162\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3814 - accuracy: 0.8115\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4005 - accuracy: 0.8118\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.3958 - accuracy: 0.7656Epoch 14/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.8195\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8079\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8032\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8240\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 0s 4ms/steposs: 0.3363 - accuracy: 0.85\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.3843 - accuracy: 0.8098\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8074\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 0s 4ms/steposs: 0.3811 - accuracy: 0.81\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8267\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8101\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8007\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.4182 - accuracy: 0.7812Epoch 17/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8245\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8126\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8118\n",
      "10/29 [=========>....................] - ETA: 0s - loss: 0.3633 - accuracy: 0.8383Epoch 18/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8276\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8046\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8145\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8262\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8157\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8040\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8240\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8104\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8159\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8270\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8084\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8126\n",
      "Epoch 25/30\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8273\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8101\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8148\n",
      "Epoch 23/30\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8278\n",
      "21/29 [====================>.........] - ETA: 0s - loss: 0.3848 - accuracy: 0.8065Epoch 30/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8168\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8106\n",
      " 1/29 [>.............................] - ETA: 0s - loss: 0.3756 - accuracy: 0.8047Epoch 27/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8270\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8143\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8131\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8126\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8070\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 0s 2ms/steposs: 0.3785 - accuracy: 0.81\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8135\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8165\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8096\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8059\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8085\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 0s 2ms/steposs: 0.3873 - accuracy: 0.81\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8149\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 0s 2ms/steposs: 0.3873 - accuracy: 0.81\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8076\n",
      "57/57 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gea/.local/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры: {'neural_network__batch_size': 128, 'neural_network__epochs': 20, 'neural_network__verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class NeuralNetworkTrainer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, epochs=10, batch_size=32, verbose=1):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        input_shape = (X.shape[1],)  # Определите форму входных данных на основе X\n",
    "        num_classes = len(np.unique(y))  # Количество классов в задаче классификации\n",
    "        \n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(2048, activation='relu', input_shape=input_shape),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        self.model = model\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # NeuralNetworkTrainer не изменяет данные, поэтому просто возвращаем X\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Предсказать метки классов для новых данных X\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        y_pred = self.model.predict(X)\n",
    "        return np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    def score(self, X, y=None):\n",
    "        # Оцените производительность модели на данных X и y\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Модель не обучена\")\n",
    "        y_pred = self.model.predict(X)\n",
    "        accuracy = accuracy_score(y, np.argmax(y_pred, axis=1))\n",
    "        return accuracy\n",
    "\n",
    "# Остальной код остается без изменений\n",
    "\n",
    "# Создайте экземпляр нейронной сети\n",
    "neural_network = NeuralNetworkTrainer()\n",
    "\n",
    "# Определите сетку параметров для нейронной сети\n",
    "param_grid = {\n",
    "    'neural_network__epochs': [10, 20, 30],  # Разные значения числа эпох\n",
    "    'neural_network__batch_size': [32, 64, 128],  # Разные значения размера пакета\n",
    "    'neural_network__verbose': [0, 1],  # Разные уровни вывода\n",
    "}\n",
    "\n",
    "# Создайте конвейер с нейронной сетью\n",
    "pipeline = Pipeline([\n",
    "    ('num_imputer', Imputer(NUMERICAL, method='mean')),\n",
    "    ('scaler', Scaler(NUMERICAL)),\n",
    "    ('cat_imputer', Imputer(CATEGORICAL)),\n",
    "    ('encoder', Encoder(CATEGORICAL)),\n",
    "    ('neural_network', neural_network),\n",
    "])\n",
    "\n",
    "# Создайте GridSearchCV объект с конвейером и сеткой параметров\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "# Запустите поиск по сетке на тренировочных данных\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Получите наилучшие параметры\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Наилучшие параметры:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.7945306725794531\n"
     ]
    }
   ],
   "source": [
    "# Сделайте предсказание на тестовых данных\n",
    "y_pred = pipe.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Вычислите оценку точности (accuracy) модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Выведите оценку на экран\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

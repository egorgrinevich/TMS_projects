{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблемы исчезновения / взрывного роста градиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 21:27:23.836305: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-07 21:27:24.062160: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-07 21:27:24.065425: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 21:27:26.631433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы обсуждали ранее, алгоритм обратного распространения работает, переходя от выходного слоя к входному слою, распространяя градиент ошибки по пути. После того как алгоритм вычислил градиент функции стоимости для каждого параметра в сети, он использует эти градиенты для обновления каждого параметра с шагом градиентного спуска.\n",
    "К сожалению, градиенты часто становятся все меньше и меньше по мере продвижения алгоритма к нижним уровням. В результате обновление Gradient Descent практически не изменяет вес соединений нижних уровней, и обучение никогда не приводит к хорошему решению. Мы называем это проблемой исчезающих градиентов . В некоторых случаях может произойти обратное: градиенты могут увеличиваться и увеличиваться до тех пор, пока слои не получат безумно большие обновления веса, а алгоритм не будет расходиться. Это проблема взрывающихся градиентов , которая возникает в рекуррентных нейронных сетях. В целом, глубокие нейронные сети страдают от нестабильных градиентов; разные слои могут учиться на разных скоростях.\n",
    "Это неудачное поведение наблюдалось эмпирически давно, и это было одной из причин, по которой глубокие нейронные сети были в основном заброшены в начале 2000-х годов. Неясно, что послужило причиной нестабильности градиентов при обучении DNN, но в 2010 paper https://homl.info/47 года Ксавье Глорот и Йошуа Бенджо был пролит свет. Авторы обнаружили несколько решений, в том числе сочетание популярной функции активации логистической сигмоиды и техники инициализации веса, которая была наиболее популярной в то время (то есть нормальное распределение со средним значением 0 и стандартным отклонением 1). Вкратце, они показали, что с этой функцией активации и этой схемой инициализации дисперсия выходов каждого слоя намного больше, чем дисперсия его входов. Продвигаясь вперед в сети, дисперсия продолжает увеличиваться после каждого слоя, пока функция активации не насыщается на верхних слоях. Это насыщение фактически усугубляется тем фактом, что логистическая функция имеет среднее значение 0,5, а не 0 (гиперболическая касательная функция имеет среднее значение 0 и ведет себя немного лучше, чем логистическая функция в глубоких сетях).\n",
    "Рассматривая функцию логистической активации (см. Рис. 11-1), вы можете видеть, что, когда входы становятся большими (отрицательными или положительными), функция насыщается на 0 или 1, а производная очень близка к 0. Таким образом, когда обратное распространение начинается у него практически нет градиента для распространения по сети; и то, что существует небольшой градиент, продолжает разбавляться по мере того, как обратное распространение распространяется вниз через верхние слои, поэтому для нижних слоев действительно ничего не остается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glorot и He инициализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В своей работе Glorot и Bengio предлагают способ значительно облегчить проблему нестабильных градиентов. Они указывают на то, что нам нужно, чтобы сигнал работал правильно в обоих направлениях: в прямом направлении при прогнозировании и в обратном направлении при обратном распространении градиентов. Мы не хотим, чтобы сигнал угас, и при этом мы не хотим, чтобы он взрывался и насыщался. Для получения требуемого уровня сигнала, авторы утверждают, что нам нужно чтобы дисперсия выходов каждого слоя должна быть равной дисперсии его входов, и нам нужно градиент, которые имеют равные дисперсии до и после прохождения через слой в обратном направлении. Это на самом деле не представляется возможным, чтобы это гарантировать так как если слой не имеет равное количество входов и нейронов, но Glorot и Bengio предложили хороший компромисс, который доказал свою работу очень хорошо на практике: веса соединений каждого слоя должны быть инициализированы случайным образом, как описано в уравнении 11-1 , где $fan_{avg} =\n",
    "(fan_{in} + fan_{out})/2$. Эта стратегия инициализации называется инициализацией Ксавье или инициализация Glorot, после первого автора статьи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-1: Xavier initialization (when using the logistic activation function)**\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "& \\text{Normal distribution with mean 0 and standard deviation }\n",
    "\\sigma = \\sqrt{\\dfrac{2}{n_\\text{inputs} + n_\\text{outputs}}}\\\\\n",
    "& \\text{Or a uniform distribution between -r and +r, with }\n",
    "r = \\sqrt{\\dfrac{6}{n_\\text{inputs} + n_\\text{outputs}}}\n",
    "\\end{split}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы замените $fan_{avg}$ на $fan_{in}$ в уравнении 11-1, вы получите стратегию инициализации, предложенную Yann LeCun в 1990-х годах. Он назвал это инициализацией LeCun . Женевьева Орр и Клаус-Роберт Мюллер даже рекомендовали это в своей книге «Нейронные сети: хитрости торговли» (Springer) 1998 года. Инициализация LeCun эквивалентна инициализации Glorot, когда $fan_{in} = fan_{out}$. Исследователям потребовалось более десяти лет, чтобы понять, насколько важен этот трюк. Использование инициализации Glorot может значительно ускорить обучение, и это один из приемов, которые привели к успеху глубокого обучения.\n",
    "В некоторых статьях представлены аналогичные стратегии для разных функций активации. Эти стратегии отличаются только масштабом дисперсии и используют ли они $fan_{avg}$ на $fan_{in}$, как показано в таблице 11-1  (для равномерного распределения, просто вычислить $r = \\sqrt{3 \\sigma^2}$. Стратегия инициализации для функции активации ReLU (и ее варианты, включая активацию ELU, описанную ниже) иногда называется инициализацией He в честь имени первого автора статьи. Функция активации SELU будет объяснена позже. Она может быть использована с инициализацией LeCun (желательно с нормальным распределением, как мы увидим)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 11-1: Initialization parameters for each type of activation function**\n",
    "\n",
    "* Logistic uniform: $ r = \\sqrt{\\dfrac{6}{n_\\text{inputs} + n_\\text{outputs}}} $\n",
    "* Logistic normal: $ \\sigma = \\sqrt{\\dfrac{2}{n_\\text{inputs} + n_\\text{outputs}}} $\n",
    "* Hyperbolic tangent uniform: $ r = 4 \\sqrt{\\dfrac{6}{n_\\text{inputs} + n_\\text{outputs}}} $\n",
    "* Hyperbolic tangent normal: $ \\sigma = 4 \\sqrt{\\dfrac{2}{n_\\text{inputs} + n_\\text{outputs}}} $\n",
    "* ReLU (and its variants) uniform: $ r = \\sqrt{2} \\sqrt{\\dfrac{6}{n_\\text{inputs} + n_\\text{outputs}}} $\n",
    "* ReLU (and its variants) normal: $ \\sigma = \\sqrt{2} \\sqrt{\\dfrac{2}{n_\\text{inputs} + n_\\text{outputs}}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"tab11_1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию Keras использует инициализацию Glorot с равномерным распределением. При создании слоя вы можете изменить это на инициализацию He, установив ```python kernel_initializer = \"he_uniform\"``` или ```python kernel_initializer = \"he_normal\"``` следующим образом:\n",
    "```python keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\") ```\n",
    "Если вы хотите его инициализацию с равномерным распределением, но на основе $fan_{avg}$ , а $fan_{in}$ в , вы можете использовать ```python VarianceScaling``` инициализатора, например так:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                                 distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'HeNormal',\n",
       " 'HeUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'LecunNormal',\n",
       " 'LecunUniform',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'random_normal',\n",
       " 'random_uniform',\n",
       " 'serialize',\n",
       " 'truncated_normal',\n",
       " 'variance_scaling',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x1a505872f50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x1a5057ebd90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ненасыщенные функции активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из выводов, сделанных Глоротом и Бенжио в статье 2010 года, было то, что проблемы с нестабильными градиентами частично были связаны с плохим выбором функции активации. До тех пор большинство людей полагали, что, если Мать-Природа решила использовать функции активации сигмовидной железы в биологических нейронах, то сигмоида должна быть отличным выбором. Но оказывается, что другие функции активации ведут себя намного лучше в глубоких нейронных сетях - в частности, функция активации ReLU, главным образом потому, что она не насыщает положительные значения (и потому, что она быстро вычисляется).\n",
    "К сожалению, функция активации ReLU не идеальна. Он страдает от проблемы, известной как умирающие ReLU : во время обучения некоторые нейроны эффективно «умирают», что означает, что они перестают выводить что-либо кроме 0. В некоторых случаях вы можете обнаружить, что половина нейронов вашей сети мертва, особенно если вы использовали большая скорость обучения. Нейрон умирает, когда его веса изменяются таким образом, что взвешенная сумма его входов является отрицательной для всех экземпляров в обучающем наборе. Когда это происходит, он просто продолжает выводить нули, и Gradient Descent больше не влияет на него, потому что градиент функции ReLU равен нулю, когда ее вход отрицателен.\n",
    "Чтобы решить эту проблему, вы можете использовать вариант функции LeakyReLU, такой как ReLU с утечкой . Эта функция определяется как LeakyReLU $α( z ) = max(αz , z)$ (см. Рис. 11-2  ). Гиперпараметр α определяет, насколько «утечка» функции: это угол наклона функции для z <0 и обычно устанавливается на 0,01. Этот небольшой уклон гарантирует, что протекающие ReLU никогда не погибнут; они могут впасть в длительную кому, но у них есть шанс в конце концов проснуться. В 2015 году сравнивалось несколько вариантов функции активации ReLU, и один из ее выводов заключался в том, что неплотные варианты всегда превосходили строгую функцию активации ReLU. Фактически, установка α = 0,2 (огромная утечка), казалось, привела к лучшей производительности, чем α = 0,01 (небольшая утечка). В документе также оценивалась рандомизированная утечка ReLU (RReLU), где α выбирается случайным образом в заданном диапазоне во время обучения и фиксируется на среднем значении во время тестирования. RReLU также работал довольно хорошо и, похоже, выступал в качестве регуляризатора (снижая риск переобучения). Наконец, в статье оценивается параметрическая утечка ReLU (PReLU), где α разрешается изучать во время обучения (вместо того, чтобы быть гиперпараметром, он становится параметром, который может быть изменен путем обратного распространения, как любой другой параметр). Сообщалось, что PReLU сильно превосходит ReLU в наборах данных с большими изображениями, но для небольших наборов данных он рискует переобучить тренировочный набор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'mish',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "alpha = 0.02\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha = alpha),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha = alpha),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.7422 - accuracy: 0.7584 - val_loss: 0.5340 - val_accuracy: 0.8190\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4939 - accuracy: 0.8267 - val_loss: 0.4425 - val_accuracy: 0.8468\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4494 - accuracy: 0.8409 - val_loss: 0.5517 - val_accuracy: 0.7944\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4237 - accuracy: 0.8525 - val_loss: 0.4040 - val_accuracy: 0.8610\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4055 - accuracy: 0.8578 - val_loss: 0.3838 - val_accuracy: 0.8658\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3881 - accuracy: 0.8637 - val_loss: 0.3811 - val_accuracy: 0.8690\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3763 - accuracy: 0.8673 - val_loss: 0.3725 - val_accuracy: 0.8700\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3651 - accuracy: 0.8704 - val_loss: 0.3925 - val_accuracy: 0.8602\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3545 - accuracy: 0.8750 - val_loss: 0.3636 - val_accuracy: 0.8702\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3456 - accuracy: 0.8779 - val_loss: 0.3552 - val_accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как влияет на качество обучения RPLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6930 - accuracy: 0.7709 - val_loss: 0.5145 - val_accuracy: 0.8282\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4796 - accuracy: 0.8329 - val_loss: 0.4319 - val_accuracy: 0.8550\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4349 - accuracy: 0.8467 - val_loss: 0.5297 - val_accuracy: 0.8068\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4082 - accuracy: 0.8567 - val_loss: 0.3898 - val_accuracy: 0.8666\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3896 - accuracy: 0.8629 - val_loss: 0.3783 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3714 - accuracy: 0.8683 - val_loss: 0.3701 - val_accuracy: 0.8738\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3600 - accuracy: 0.8727 - val_loss: 0.3636 - val_accuracy: 0.8772\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3484 - accuracy: 0.8754 - val_loss: 0.3899 - val_accuracy: 0.8588\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3379 - accuracy: 0.8794 - val_loss: 0.3551 - val_accuracy: 0.8722\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3292 - accuracy: 0.8818 - val_loss: 0.3502 - val_accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И последнее, но не менее важное: статья Djork-Arné Clevert et al. предложил новую функцию активации, названную экспоненциальной линейной единицей (ELU), которая превзошла все варианты ReLU в экспериментах авторов: время обучения было сокращено, и нейронная сеть работала лучше на тестовом наборе. На рисунке 11-3  представлена функция графика, а в уравнении 11-2 показано ее определение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-2: ELU activation function**\n",
    "\n",
    "$\n",
    "\\operatorname{ELU}_\\alpha(z) =\n",
    "\\begin{cases}\n",
    "\\alpha(\\exp(z) - 1) & \\text{if } z < 0\\\\\n",
    "z & if z \\ge 0\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция активации ELU очень похожа на функцию ReLU, с некоторыми существенными отличиями:\n",
    "*\tОн принимает отрицательные значения, когда z <0, что позволяет устройству иметь средний выходной сигнал ближе к 0 и помогает решить проблему исчезающих градиентов. Гиперпараметр α определяет значение, к которому приближается функция ELU, когда z является большим отрицательным числом. Обычно он равен 1, но вы можете настроить его, как любой другой гиперпараметр.\n",
    "*\tОн имеет ненулевой градиент для z <0, что позволяет избежать проблемы мертвых нейронов.\n",
    "*\tЕсли α равно 1, то функция является гладкой везде, в том числе около z = 0, что помогает ускорить градиентный спуск, поскольку она не сильно отскакивает влево и вправо от z = 0.\n",
    "Основным недостатком функции активации ELU является то, что она медленнее вычисляется, чем функция ReLU и ее варианты (из-за использования экспоненциальной функции). Более высокая скорость сходимости во время обучения компенсирует это медленное вычисление, но, тем не менее, во время тестирования сеть ELU будет работать медленнее, чем сеть ReLU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x1a50b8baf50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем в 2017[great paper](https://arxiv.org/pdf/1706.02515.pdf) Гюнтер Кламбауэр и соавт. представил функцию активации Scaled ELU (SELU): как следует из названия, это масштабированный вариант функции активации ELU. Авторы показали, что если вы строите нейронную сеть, состоящую исключительно из стека плотных слоев, и если все скрытые слои используют функцию активации SELU, то сеть будет самостоятельно нормализоваться: выходные данные каждого слоя будут иметь тенденцию сохранять среднее значение 0 и стандартное отклонение 1 во время тренировки, что решает проблему исчезающих / взрывных градиентов. В результате функция активации SELU часто значительно превосходит другие функции активации для таких нейронных сетей (особенно глубоких). Однако есть несколько условий для самонормализации (математическое обоснование см. В статье):\n",
    "•\tВходные характеристики должны быть стандартизированы (среднее значение 0 и стандартное отклонение 1).\n",
    "•\tВес каждого скрытого слоя должен быть инициализирован с помощью обычной инициализации LeCun. В Keras это означает установку kernel_initializer = \"lecun_normal\" .\n",
    "•\tАрхитектура сети должна быть последовательной. К сожалению, если вы попытаетесь использовать SELU в непоследовательных архитектурах, таких как рекуррентные сети или сети с пропущенными соединениями (т. Е. Соединения, которые пропускают слои, например, в сетях Wide & Deep), самонормализация не гарантируется Таким образом, SELU не обязательно будет превосходить другие функции активации.\n",
    "•\tВ статье гарантируется самонормализация только в том случае, если все слои плотные, но некоторые исследователи отмечают, что функция активации SELU может улучшить производительность и в сверточных нейронных сетях "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SELU is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x1a50b957b10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 38s 19ms/step - loss: 2.0725 - accuracy: 0.1800 - val_loss: 1.9937 - val_accuracy: 0.1744\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 33s 19ms/step - loss: nan - accuracy: 0.1521 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 32s 19ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 33s 19ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.0914\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 33s 19ms/step - loss: nan - accuracy: 0.1008 - val_loss: nan - val_accuracy: 0.0914\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at what happens if we try to use the ReLU activation function instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 19s 8ms/step - loss: 1.7183 - accuracy: 0.2600 - val_loss: 1.4668 - val_accuracy: 0.4008\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 2.1356 - accuracy: 0.1545 - val_loss: 1.8413 - val_accuracy: 0.1996\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 1.8328 - accuracy: 0.2362 - val_loss: 1.3505 - val_accuracy: 0.3760\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 1.5698 - accuracy: 0.3375 - val_loss: 1.3402 - val_accuracy: 0.4504\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 1.5496 - accuracy: 0.3429 - val_loss: 1.3213 - val_accuracy: 0.4270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, какую функцию активации вы должны использовать для скрытых слоев ваших глубоких нейронных сетей? Хотя ваш разброс будет варьироваться, в общем SELU> ELU> неплотный ReLU (и его варианты)> ReLU> tanh> logistic. Если архитектура сети предотвращает ее самонормализацию, то ELU может работать лучше, чем SELU (поскольку SELU не является плавным при z = 0). Если вас сильно волнует задержка во время выполнения, вы можете предпочесть негерметичный ReLU. Если вы не хотите настраивать еще один гиперпараметр, вы можете использовать значения α по умолчанию, используемые Keras (например, 0,3 для неплотного ReLU). Если у вас есть свободное время и вычислительные мощности, вы можете использовать перекрестную проверку для оценки других функций активации, таких как RReLU, если ваша сеть перегружена, или PReLU, если у вас огромный тренировочный набор. Тем не менее, поскольку ReLU является наиболее часто используемой функцией активации (на данный момент), многие библиотеки и аппаратные ускорители обеспечивают специфичные для ReLU оптимизации; поэтому, если скорость является вашим приоритетом, ReLU все еще может быть лучшим выбором.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пакетная нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя использование инициализации He вместе с ELU (или любым вариантом ReLU) может значительно снизить опасность проблем исчезающего/взрывного градиента в начале обучения, это не гарантирует, что они не вернутся во время обучения.\n",
    "В 2015 Сергей Иоффе и Кристиан Сегеди предложили метод, называемый нормализацией партии (BN), который решает эти проблемы. Техника состоит в добавлении операции в модель непосредственно перед или после функции активации каждого скрытого слоя. Эта операция просто центрирует и нормализует каждый вход, затем масштабирует и сдвигает результат, используя два новых вектора параметров на слой: один для масштабирования, другой для сдвига. Другими словами, операция позволяет модели узнать оптимальный масштаб и среднее значение каждого из входов слоя. Во многих случаях, если вы добавляете слой BN в качестве самого первого слоя вашей нейронной сети, вам не нужно стандартизировать свой тренировочный набор (например, используя StandardScaler ); слой BN сделает это за вас (ну, примерно, так как он просматривает только один пакет за раз, и он также может масштабировать и сдвигать каждую входную функцию).\n",
    "Для того, чтобы центрировать и нормализовать входы, алгоритм должен оценить среднее значение и стандартное отклонение каждого входа. Это достигается путем оценки среднего и стандартного отклонения входного сигнала по текущей мини-партии (отсюда и название «нормализация партии»). Вся операция суммируется шаг за шагом в уравнении 11-3 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-3: Batch Normalization algorithm**\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "1.\\quad & \\mathbf{\\mu}_B = \\dfrac{1}{m_B}\\sum\\limits_{i=1}^{m_B}{\\mathbf{x}^{(i)}}\\\\\n",
    "2.\\quad & {\\mathbf{\\sigma}_B}^2 = \\dfrac{1}{m_B}\\sum\\limits_{i=1}^{m_B}{(\\mathbf{x}^{(i)} - \\mathbf{\\mu}_B)^2}\\\\\n",
    "3.\\quad & \\hat{\\mathbf{x}}^{(i)} = \\dfrac{\\mathbf{x}^{(i)} - \\mathbf{\\mu}_B}{\\sqrt{{\\mathbf{\\sigma}_B}^2 + \\epsilon}}\\\\\n",
    "4.\\quad & \\mathbf{z}^{(i)} = \\gamma \\otimes \\hat{\\mathbf{x}}^{(i)} + \\beta\n",
    "\\end{split}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом алгоритме:\n",
    "*\t${\\mu}_B$ - вектор средних значений ввода, оцениваемый по всей мини-партии B (он содержит одно среднее значение для каждого входа).\n",
    "*\t${\\sigma}_B$ - вектор стандартных отклонений на входе, также оцениваемый по всей мини-партии (он содержит одно стандартное отклонение на вход).\n",
    "*\t$m_B$ - количество экземпляров в мини-партии.\n",
    "*\t$\\hat{\\mathbf{x}}^{(i)}$ - вектор нулевых центрированных и нормализованных входных данных, например, i .\n",
    "*\t$\\gamma$ - вектор выходного параметра масштаба для слоя (он содержит один параметр масштаба на вход).\n",
    "*\t$\\otimes$ представляет поэлементное умножение (каждый вход умножается на соответствующий выходной масштабный параметр).\n",
    "*\t$\\beta$ - вектор параметров выходного смещения (смещения) для слоя (он содержит один параметр смещения на вход). Каждый вход смещен соответствующим параметром сдвига.\n",
    "*\t$\\epsilon$ - крошечное число, которое избегает деления на ноль (обычно $10^{–5}$ ). Это называется сглаживающим термином.\n",
    "*\t${z}^{(i)}$ - результат операции BN. Это измененная и измененная версия входных данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, во время обучения BN стандартизирует свои входные данные, затем масштабирует и компенсирует их. Хорошо! Как насчет во время теста? Ну, это не так просто. Действительно, нам может потребоваться делать прогнозы для отдельных экземпляров, а не для пакетов экземпляров: в этом случае у нас не будет возможности вычислить среднее значение и стандартное отклонение для каждого входа. Более того, даже если у нас есть пакет экземпляров, он может быть слишком маленьким или экземпляры могут быть независимыми и одинаково распределенными, поэтому вычисление статистики по экземплярам пакета будет ненадежным. Одним из решений может быть ожидание до конца обучения, а затем выполнение всего обучающего набора через нейронную сеть и вычисление среднего и стандартного отклонения каждого входа уровня BN. Эти «окончательные» средства ввода и стандартные отклонения могут затем использоваться вместо средств пакетного ввода и стандартных отклонений при прогнозировании. Тем не менее, большинство реализаций Пакетной нормализации оценивают эти окончательные статистические данные во время обучения, используя скользящую среднюю из средств ввода слоя и стандартные отклонения. Это то, что делает Keras автоматически, когда вы используете слой BatchNormalization . Подводя итог, можно узнать четыре вектора параметров в каждом нормированном на пакет уровне: γ (вектор выходного масштаба) и β (вектор выходного смещения) изучаются посредством регулярного обратного распространения, а μ (конечный вектор среднего входного значения) и σ ( конечный входной вектор стандартного отклонения) оценивается с использованием экспоненциальной скользящей средней. Обратите внимание, что μ и σ оцениваются во время обучения, но они используются только после обучения (для замены средств пакетного ввода и стандартных отклонений в уравнении 11-3 ).\n",
    "Иоффе и Сегеди продемонстрировали, что пакетная нормализация значительно улучшила все глубокие нейронные сети, с которыми они экспериментировали, что привело к значительному улучшению задачи классификации ImageNet (ImageNet - это большая база данных изображений, классифицированных по многим классам, которые обычно используются для оценки систем компьютерного зрения). Проблема исчезающих градиентов была сильно уменьшена до такой степени, что они могли использовать насыщающие функции активации, такие как танх и даже логистическую функцию активации. Сети были также намного менее чувствительны к инициализации веса. Авторы смогли использовать гораздо более высокие темпы обучения, значительно ускоряя процесс обучения. В частности, они отмечают, что:\n",
    "Применительно к современной модели классификации изображений нормализация партии достигает той же точности с 14-кратным сокращением шагов обучения и значительно превосходит исходную модель. […] Используя ансамбль нормализованных по партиям сетей, мы улучшаем лучший опубликованный результат по классификации ImageNet: достигаем 4,9% ошибок проверки топ-5 (и 4,8% ошибок тестирования), превышая точность оценок людей.\n",
    "Наконец, как подарок, который продолжает дарить, нормализация партии действует как регуляризатор, уменьшая потребность в других методах регуляризации (таких как выпадение, описанное ниже в этой главе).\n",
    "Пакетная нормализация, однако, добавляет некоторую сложность модели (хотя она может устранить необходимость нормализации входных данных, как мы обсуждали ранее). Кроме того, существует штраф за время выполнения: нейронная сеть делает более медленные прогнозы из-за дополнительных вычислений, требуемых на каждом уровне. К счастью, после тренировки часто можно объединить слой BN с предыдущим, что позволяет избежать штрафа за время выполнения. Это делается путем обновления весов и смещений предыдущего уровня, чтобы он напрямую генерировал выходные данные соответствующего масштаба и смещения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в большинстве случаев с Keras, реализация нормализации партии проста и интуитивно понятна. Просто добавьте слой BatchNormalization до или после функции активации каждого скрытого слоя и при необходимости добавьте слой BN, а также первый слой в вашей модели. Например, эта модель применяет BN после каждого скрытого слоя и в качестве первого слоя в модели (после выравнивания входных изображений):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 784)               3136      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 300)               1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271346 (1.04 MB)\n",
      "Trainable params: 268978 (1.03 MB)\n",
      "Non-trainable params: 2368 (9.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, каждый уровень BN добавляет четыре параметра на вход: γ , β , µ и σ (например, первый уровень BN добавляет 3136 параметров, что составляет 4 × 784). Последние два параметра, μ и σ , являются скользящими средними; обратное распространение не влияет на них, поэтому Keras называет их «необучаемыми» 9 (если вы посчитаете общее количество параметров BN, 3136 + 1200 + 400 и разделите на 2, вы получите 2 368, то есть общее число -тренируемые параметры в этой модели).\n",
    "Давайте посмотрим на параметры первого слоя BN. Два обучаемых (путем обратного распространения), а два нет:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда вы создаете слой BN в Keras, он также создает две операции, которые будут вызываться Keras на каждой итерации во время обучения. Эти операции обновят скользящие средние. Поскольку мы используем бэкэнд TensorFlow, эти операции являются операциями TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sidromnik\\AppData\\Local\\Temp\\ipykernel_34664\\2538512196.py:1: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  bn1.updates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Авторы статьи BN высказались за добавление слоев BN перед функциями активации, а не после (как мы только что сделали). Существует некоторая дискуссия по этому поводу, которая, кажется, является предпочтительной, зависит от задачи - вы также можете поэкспериментировать с этим, чтобы увидеть, какой вариант лучше всего работает с вашим набором данных. Чтобы добавить слои BN перед функциями активации, необходимо удалить функцию активации из скрытых слоев и добавить их как отдельные слои после слоев BN. Более того, поскольку слой нормализации партии включает в себя один параметр смещения на вход, вы можете удалить член смещения из предыдущего слоя (просто передайте use_bias = False при его создании):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5364 - accuracy: 0.8146 - val_loss: 0.3731 - val_accuracy: 0.8726\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3927 - accuracy: 0.8601 - val_loss: 0.3461 - val_accuracy: 0.8778\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3577 - accuracy: 0.8713 - val_loss: 0.3406 - val_accuracy: 0.8786\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3288 - accuracy: 0.8812 - val_loss: 0.3211 - val_accuracy: 0.8844\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3080 - accuracy: 0.8893 - val_loss: 0.3071 - val_accuracy: 0.8916\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2922 - accuracy: 0.8944 - val_loss: 0.3104 - val_accuracy: 0.8886\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2808 - accuracy: 0.8987 - val_loss: 0.3092 - val_accuracy: 0.8904\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2644 - accuracy: 0.9035 - val_loss: 0.3122 - val_accuracy: 0.8904\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2533 - accuracy: 0.9073 - val_loss: 0.3058 - val_accuracy: 0.8930\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2439 - accuracy: 0.9112 - val_loss: 0.3080 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `BatchNormalization` имеет несколько гиперпараметров, которые можно настроить. Значения по умолчанию, как правило, будут хорошими, но иногда вам может понадобиться настроить импульс. Этот гиперпараметр используется слоем `BatchNormalization` при обновлении экспоненциальных скользящих средних; задается новое значение $\\hat V$ (т.е., новый вектор входных параметров или стандартных отклонений, вычисленных по текущей партии), слой обновляет скользящий средний $\\hat V$\n",
    "используя следующее уравнение:\n",
    "$$\\hat V ← \\hat V × momentum + V × (1 − momentum)$$\n",
    "Хорошее значение импульса обычно близко к 1; например, 0,9, 0,99 или 0,999 (вам нужно больше 9 с для больших наборов данных и меньших мини-пакетов).\n",
    "Другим важным гиперпараметром является ось : она определяет, какую ось следует нормализовать. По умолчанию он равен –1, что означает, что по умолчанию он нормализует последнюю ось (используя средние значения и стандартные отклонения, рассчитанные по другим осям). Когда входной пакет является 2D (т. е. Форма пакета [batch size, features]), это означает, что каждый входной объект будет нормализован на основе среднего значения и стандартного отклонения, рассчитанного для всех экземпляров в пакете. Например, первый уровень BN в предыдущем примере кода будет независимо нормализовать (и масштабировать и сдвигать) каждую из 784 входных параметров. Если мы переместим первый слой BN перед слоем Flatten, то входные пакеты будут 3D, с формой [batch size, height, width]; следовательно, слой BN будет вычислять 28 средних значений и 28 стандартных отклонений (1 на столбец пикселей, рассчитанный для всех экземпляров в пакете и для всех строк в столбце), и он будет нормализовать все пиксели в данном столбце с использованием того же среднего значения и стандартное отклонение. Также будет только 28 масштабных параметров и 28 параметров сдвига. Если вместо этого вы все еще хотите обрабатывать каждый из 784 пикселей независимо, то вам следует установить axis = [1, 2].\n",
    "Обратите внимание, что уровень BN не выполняет одинаковые вычисления во время тренировки и после тренировки: он использует статистику партии во время тренировки и «окончательную» статистику после тренировки (т. е. конечные значения скользящих средних). Давайте посмотрим на исходный код этого класса, чтобы увидеть, как это обрабатывается:\n",
    "```python\n",
    "class BatchNormalization(keras.layers.Layer):\n",
    "    [...]\n",
    "    def call(self, inputs, training=None):\n",
    "        [...]\n",
    "```\n",
    "Метод `call()` - он непосредственно выполняет вычисления; как видите, он имеет дополнительный обучающий аргумент, который по умолчанию имеет значение None , но метод `fit()` устанавливает его равным 1 во время обучения. Если вам когда-нибудь понадобится написать пользовательский слой, и он должен вести себя по-разному во время обучения и тестирования, добавьте обучающий аргумент в метод `call()` и используйте этот аргумент в методе, чтобы решить, что вычислять 10.\n",
    "Пакетная нормализация стала одним из наиболее часто используемых слоев в глубоких нейронных сетях, так что на диаграммах она часто опускается, так как предполагается, что BN добавляется после каждого слоя. Но недавняя статья Хонги Чжан и соавт. может изменить это предположение: используя новую методику инициализации веса с фиксированным обновлением (fixup), авторам удалось обучить очень глубокую нейронную сеть (10 000 слоев!) без BN, достигая современного уровня производительности при сложной классификации изображений задачи. Однако, так как это новейшее исследование, вы можете подождать дополнительных исследований, чтобы подтвердить этот вывод, прежде чем отказаться от нормализации партии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5328 - accuracy: 0.8125 - val_loss: 0.3690 - val_accuracy: 0.8704\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3926 - accuracy: 0.8597 - val_loss: 0.3395 - val_accuracy: 0.8802\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3579 - accuracy: 0.8708 - val_loss: 0.3416 - val_accuracy: 0.8760\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3278 - accuracy: 0.8817 - val_loss: 0.3166 - val_accuracy: 0.8844\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3086 - accuracy: 0.8880 - val_loss: 0.3073 - val_accuracy: 0.8894\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2933 - accuracy: 0.8931 - val_loss: 0.3107 - val_accuracy: 0.8886\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2788 - accuracy: 0.8977 - val_loss: 0.3107 - val_accuracy: 0.8894\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2664 - accuracy: 0.9028 - val_loss: 0.3125 - val_accuracy: 0.8886\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2535 - accuracy: 0.9060 - val_loss: 0.3073 - val_accuracy: 0.8910\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2438 - accuracy: 0.9117 - val_loss: 0.3006 - val_accuracy: 0.8940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиент отсечения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой популярный метод для смягчения проблемы взрывающихся градиентов состоит в том, чтобы обрезать градиенты во время обратного распространения, чтобы они никогда не превышали некоторый порог. Это называется Gradient Clipping. Этот метод чаще всего используется в рекуррентных нейронных сетях, так как пакетная нормализация сложно использовать в RNN, как мы увидим позже. Для других типов сетей обычно достаточно BN.\n",
    "В Keras реализация Gradient Clipping - это просто вопрос установки аргумента clipvalue или clipnorm при создании оптимизатора, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот оптимизатор будет обрезать каждый компонент вектора градиента до значения от –1,0 до 1,0. Это означает, что все частные производные потери (в отношении каждого обучаемого параметра) будут ограничены между –1,0 и 1,0. Порог - это гиперпараметр, который вы можете настроить. Обратите внимание, что это может изменить ориентацию вектора градиента. Например, если исходный вектор градиента равен [0,9, 100,0], он в основном указывает в направлении второй оси; но как только вы обрезаете его по значению, вы получите [0,9, 1,0], который примерно указывает на диагональ между двумя осями. На практике этот подход работает хорошо. Если вы хотите убедиться, что Gradient Clipping не меняет направление вектора градиента, вы должны обрезать по норме, установив clipnorm вместо clipvalue. Это будет обрезать весь градиент, если его ℓ 2 нормы больше порога вы выбрали. Например, если вы установите clipnorm = 1.0 , то вектор [0.9, 100.0] будет обрезан до [0.00899964, 0.9999595], сохраняя его ориентацию, но почти исключая первый компонент. Если вы заметили, что градиенты сильно возрастают во время обучения (вы можете отслеживать размер градиентов с помощью TensorBoard), вы можете попробовать как урезать по значению, так и урезать по норме, с различными пороговыми значениями, и посмотрите, какая опция лучше всего работает на наборе при проверки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Повторное использование предварительно обученных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, не очень хорошая идея тренировать очень большое DNN с нуля: вместо этого вы всегда должны пытаться найти существующую нейронную сеть, которая выполняет задачу, аналогичную той, которую вы пытаетесь решить, затем повторно используйте нижние уровни этой сети. Эта техника называется трансферным обучением. Это не только значительно ускорит обучение, но и потребует значительно меньшего количества тренировочных данных.\n",
    "Предположим, у вас есть доступ к DNN, который был обучен для классификации изображений на 100 различных категорий, включая животных, растения, транспортные средства и предметы быта. Теперь вы хотите обучить DNN для классификации определенных типов транспортных средств. Эти задачи очень похожи, даже частично перекрываются, поэтому вы должны попытаться повторно использовать части первой сети (см. Рис. 11-4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"transfer.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если входные изображения вашей новой задачи не имеют такой же размер, как те, что использовались в исходной задаче, вам обычно нужно добавить шаг предварительной обработки, чтобы изменить их размер до размера, ожидаемого исходной моделью. В более общем смысле, трансферное обучение будет работать лучше всего, когда входы имеют схожие низкоуровневые функции.\n",
    "Выходной слой исходной модели обычно следует заменять, поскольку он, скорее всего, вообще не полезен для новой задачи и может даже не иметь нужного количества выходов для новой задачи.\n",
    "Точно так же верхние скрытые слои исходной модели с меньшей вероятностью будут столь же полезны, как и нижние слои, поскольку высокоуровневые функции, наиболее полезные для новой задачи, могут значительно отличаться от тех, которые были наиболее полезны для исходной задачи. , Вы хотите найти правильное количество слоев для повторного использования.\n",
    "Примечание\n",
    "Чем больше похожих задач, тем больше слоев вы хотите использовать повторно (начиная с нижних уровней). Для очень похожих задач попробуйте сохранить все скрытые слои и просто заменить выходной слой.\n",
    "Попробуйте сначала заморозить все повторно используемые слои (т. е. Сделать их веса необучаемыми, чтобы градиентный спуск не изменил их), затем обучите свою модель и посмотрите, как она работает. Затем попробуйте разморозить один или два верхних скрытых слоя, чтобы позволить обратному распространению настроить их, и посмотреть, улучшится ли производительность. Чем больше у вас тренировочных данных, тем больше слоев вы сможете разморозить. Также полезно уменьшить скорость обучения, когда вы размораживаете повторно используемые слои: это позволит избежать разрушения их точно настроенных весов.\n",
    "Если вы все еще не можете добиться хорошей производительности, и у вас мало тренировочных данных, попробуйте сбросить верхний скрытый слой (слои) и снова заморозить все оставшиеся скрытые слои. Вы можете перебирать, пока не найдете нужное количество слоев для повторного использования. Если у вас много тренировочных данных, вы можете попробовать заменить верхние скрытые слои вместо того, чтобы отбрасывать их, и даже добавить больше скрытых слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на пример. Предположим, что набор данных Fashion MNIST содержит только восемь классов - например, все классы, кроме сандалии и рубашки. Кто-то построил и обучил модель Keras на этом наборе и получил достаточно хорошую производительность (точность> 90%). Давайте назовем эту модель А. Теперь вы хотите решить другую задачу: у вас есть изображения сандалий и рубашек, и вы хотите обучить двоичный классификатор (положительный = рубашка, отрицательный = сандалия). Ваш набор данных довольно маленький; у вас есть только 200 помеченных изображений. Когда вы готовите новую модель для этой задачи (назовем ее моделью B) с той же архитектурой, что и модель A, она работает достаточно хорошо (точность 97,2%). Но так как это намного более легкая задача (есть только два класса), вы надеялись на большее. Выпивая утренний кофе, вы понимаете, что ваша задача очень похожа на задачу А, поэтому, возможно, вам поможет трансферное обучение? Давайте разберемся!\n",
    "Сначала вам нужно загрузить модель A и создать новую модель на основе слоев этой модели. Давайте повторно используем все слои, кроме выходного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.3542 - accuracy: 0.8745 - val_loss: 0.3080 - val_accuracy: 0.8889\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2666 - accuracy: 0.9074 - val_loss: 0.2685 - val_accuracy: 0.9038\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2447 - accuracy: 0.9124 - val_loss: 0.2404 - val_accuracy: 0.9153\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2290 - accuracy: 0.9196 - val_loss: 0.2478 - val_accuracy: 0.9160\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2161 - accuracy: 0.9236 - val_loss: 0.2295 - val_accuracy: 0.9213\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2071 - accuracy: 0.9252 - val_loss: 0.2199 - val_accuracy: 0.9180\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1987 - accuracy: 0.9300 - val_loss: 0.2286 - val_accuracy: 0.9193\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1916 - accuracy: 0.9320 - val_loss: 0.2234 - val_accuracy: 0.9218\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1854 - accuracy: 0.9338 - val_loss: 0.2266 - val_accuracy: 0.9220\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1797 - accuracy: 0.9349 - val_loss: 0.2248 - val_accuracy: 0.9190\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1742 - accuracy: 0.9371 - val_loss: 0.1990 - val_accuracy: 0.9307\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1690 - accuracy: 0.9400 - val_loss: 0.2426 - val_accuracy: 0.9158\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1645 - accuracy: 0.9405 - val_loss: 0.2040 - val_accuracy: 0.9275\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1605 - accuracy: 0.9423 - val_loss: 0.2031 - val_accuracy: 0.9258\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.1566 - accuracy: 0.9428 - val_loss: 0.2498 - val_accuracy: 0.9093\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1519 - accuracy: 0.9439 - val_loss: 0.2088 - val_accuracy: 0.9268\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1494 - accuracy: 0.9458 - val_loss: 0.2426 - val_accuracy: 0.9203\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1451 - accuracy: 0.9473 - val_loss: 0.2086 - val_accuracy: 0.9297\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1412 - accuracy: 0.9496 - val_loss: 0.2041 - val_accuracy: 0.9265\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.1382 - accuracy: 0.9499 - val_loss: 0.2043 - val_accuracy: 0.9255\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sidromnik\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 34ms/step - loss: 0.5158 - accuracy: 0.7850 - val_loss: 0.1479 - val_accuracy: 0.9797\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0993 - accuracy: 0.9900 - val_loss: 0.1052 - val_accuracy: 0.9817\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0641 - accuracy: 0.9950 - val_loss: 0.0843 - val_accuracy: 0.9848\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0488 - accuracy: 0.9950 - val_loss: 0.0736 - val_accuracy: 0.9828\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0371 - accuracy: 0.9950 - val_loss: 0.0651 - val_accuracy: 0.9838\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.9950 - val_loss: 0.0620 - val_accuracy: 0.9848\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9950 - val_loss: 0.0650 - val_accuracy: 0.9817\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9848\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9868\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9868\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9868\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9868\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9868\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9868\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9878\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9878\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9878\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 784)               3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 300)               235200    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 300)               1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 100)               30000     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270946 (1.03 MB)\n",
      "Trainable params: 268578 (1.02 MB)\n",
      "Non-trainable params: 2368 (9.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что model_A и model_B_on_A теперь совместно используют несколько слоев. Когда вы тренируете model_B_on_A , это также повлияет на model_A . Если вы хотите избежать этого, вам нужно клонировать model_A, прежде чем повторно использовать его слои. Для этого вы клонируете архитектуру модели A с помощью clone_model () , а затем копируете ее веса (поскольку clone_model () не клонирует веса): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вы можете обучить model_B_on_A для задачи B, но поскольку новый выходной слой был инициализирован случайным образом, он будет делать большие ошибки (по крайней мере, в течение первых нескольких эпох), поэтому будут большие градиенты ошибок, которые могут разрушить повторно используемые веса. Чтобы избежать этого, один из подходов состоит в том, чтобы заморозить повторно используемые слои в течение первых нескольких эпох, давая новому слою некоторое время для изучения разумных весов. Для этого установите обучаемый атрибут каждого слоя в False и скомпилируйте модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы должны всегда компилировать свою модель после замораживания или размораживания слоев.\n",
    "Теперь вы можете обучить модель в течение нескольких эпох, затем разморозить повторно используемые слои (что требует повторной компиляции модели) и продолжить обучение для точной настройки повторно используемых слоев для задачи B. После размораживания повторно используемых слоев обычно это хорошая идея. чтобы уменьшить скорость обучения, еще раз, чтобы не повредить повторно используемые веса:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 31ms/step - loss: 0.7770 - accuracy: 0.7000 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4008 - accuracy: 0.7900 - val_loss: 0.3370 - val_accuracy: 0.8154\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2476 - accuracy: 0.8850 - val_loss: 0.2263 - val_accuracy: 0.8986\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1696 - accuracy: 0.9250 - val_loss: 0.1606 - val_accuracy: 0.9493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 31ms/step - loss: 0.0831 - accuracy: 0.9850 - val_loss: 0.0583 - val_accuracy: 0.9848\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 0.0450 - val_accuracy: 0.9868\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9899\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9909\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9909\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9909\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9929\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9909\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9909\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9909\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9919\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9919\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9919\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9919\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9919\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, каков окончательный вердикт? Что ж, точность теста этой модели составляет 98.99%, что означает, что при обучении с помощью переноса частота ошибок снижается с 2,8% до почти 1.1%! Это в два раза!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02596135437488556, 0.9929999709129333]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01623493619263172, 0.9965000152587891]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.933333333333337"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100 - 97.05) / (100 - 99.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы убеждены? Не должно быть: я обманул! Я перепробовал много конфигураций, пока не нашел, что продемонстрировало сильное улучшение. Если вы попытаетесь изменить классы или случайное начальное число, вы увидите, что улучшение обычно падает, или даже исчезает или меняется на противоположное. То, что я сделал, называется «пытать данные до тех пор, пока они не признаются». Когда бумага выглядит слишком позитивно, вы должны быть подозрительны: возможно, эффектная новая техника на самом деле мало помогает (на самом деле, она может даже ухудшить производительность), но авторы перепробовали много вариантов и сообщили только о лучших результатах (что может быть связано с чистой удачей), не упоминая, сколько неудач они встретили на пути. В большинстве случаев это вовсе не вредно, но это одна из причин того, что многие результаты в науке никогда не могут быть воспроизведены.\n",
    "Почему я обманул? Оказывается, что обучение передаче не очень хорошо работает с небольшими плотными сетями, возможно потому, что маленькие сети изучают мало шаблонов, а плотные сети изучают очень специфические шаблоны, которые вряд ли будут полезны в других задачах. Трансферное обучение лучше всего работает с глубокими сверточными нейронными сетями, которые, как правило, изучают детекторы функций, которые являются гораздо более общими (особенно на нижних уровнях). Мы вернемся к трансферному обучению позже, используя методы, которые мы только что обсудили."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Необслуживаемая предварительная подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что вы хотите решить сложную задачу, для которой у вас не так много помеченных обучающих данных, но, к сожалению, вы не можете найти модель, обученную для аналогичной задачи. Не теряй надежду! Во-первых, вы должны попытаться собрать больше помеченных данных об обучении, но если вы не можете, вы все равно сможете выполнять неконтролируемую предварительную подготовку (см. Рисунок 11-5). Действительно, собирать немаркированные учебные примеры зачастую дешево, но дорого их маркировать. Если вы можете собрать большое количество немаркированных обучающих данных, вы можете попытаться использовать их для обучения неконтролируемой модели, такой как автоэнкодер или генеративная состязательная сеть. Затем вы можете повторно использовать нижние уровни автоэнкодера или нижние уровни дискриминатора GAN, добавить выходной слой для вашей задачи сверху и настроить конечную сеть, используя контролируемое обучение (т. е. с помеченными примерами обучения).\n",
    "Именно эту технику Джеффри Хинтон и его команда использовали в 2006 году, что привело к возрождению нейронных сетей и успеху Deep Learning. До 2010 года неконтролируемая предварительная подготовка - как правило, с ограниченными машинами Больцмана - была нормой для глубоких сетей, и только после того, как была устранена проблема исчезающих градиентов, стало гораздо более распространенным обучение DNN исключительно с использованием контролируемого обучения. Необслуживаемая предварительная подготовка (сегодня, как правило, с использованием авто-кодеров или GAN, а не RBM) по-прежнему является хорошим вариантом, когда вам нужно решить сложную задачу, нет аналогичной модели, которую вы можете использовать повторно, и мало помеченных данных обучения, но много немаркированных данных обучения.\n",
    "Обратите внимание, что в первые дни глубокого обучения было трудно обучать глубокие модели, поэтому люди использовали технику, называемую жадным послойным предварительным обучением (изображено на рисунке 11-5  ). Сначала они обучают неконтролируемую модель с одним слоем, обычно RBM, затем замораживают этот слой и добавляют еще один поверх него, затем обучают модель снова (фактически просто обучая новый слой), затем замораживают новый слой и добавьте еще один слой поверх него, снова обучите модель и так далее. В настоящее время все намного проще: люди обычно обучают полную неконтролируемую модель за один раз (т. е. На Рисунке 11-5  , просто начните прямо с третьего шага) и используют автоэнкодеры или GAN, а не RBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"transfer1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Рисунок 11-5. При неконтролируемом обучении модель обучается на немаркированных данных (или на всех данных) с использованием неконтролируемой методики обучения, затем она настраивается для окончательного задания на маркированных данных с использованием методики контролируемого обучения; неконтролируемая часть может тренироваться по одному слою за раз, как показано здесь, или она может тренировать полную модель напрямую"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предварительная подготовка по вспомогательному заданию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас мало обученных данных с метками, последний вариант - обучить первую нейронную сеть вспомогательной задаче, для которой вы можете легко получить или сгенерировать обучающие данные с маркировкой, а затем повторно использовать нижние уровни этой сети для вашей реальной задачи. Нижние уровни первой нейронной сети будут изучать детекторы функций, которые, вероятно, будут использоваться во второй нейронной сети.\n",
    "Например, если вы хотите создать систему распознавания лиц, у вас может быть только несколько изображений каждого человека - явно недостаточно для обучения хорошего классификатора. Собирать сотни фотографий каждого человека было бы не практично. Тем не менее, вы могли бы собрать много изображений случайных людей в Интернете и обучить первую нейронную сеть, чтобы определить, изображают ли два разных изображения одного и того же человека. Такая сеть выучит хорошие детекторы функций для лиц, поэтому повторное использование ее нижних уровней позволит вам обучить хороший классификатор лиц, который использует мало обучающих данных.\n",
    "Для приложений обработки естественного языка (NLP) вы можете загрузить корпус миллионов текстовых документов и автоматически генерировать из них помеченные данные. Например, вы можете случайным образом замаскировать некоторые слова и обучить модель, чтобы предсказать, что такое пропущенные слова (например, он должен предсказать, что пропущенное слово в предложении «Что вы говорите?», Вероятно, «есть» или «было») ). Если вы можете обучить модель для достижения высокой производительности при выполнении этой задачи, то она уже будет достаточно много знать о языке, и вы, безусловно, сможете повторно использовать ее для своей реальной задачи и точно настроить ее на свои маркированные данные.\n",
    "Заметка\n",
    "Самостоятельное обучение - это когда вы автоматически генерируете метки из самих данных, а затем тренируете модель в результирующем «помеченном» наборе данных, используя методы контролируемого обучения. Поскольку этот подход не требует никакой человеческой маркировки, его лучше всего классифицировать как форму обучения без учителя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ускоренные оптимизаторы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение очень большой глубокой нейронной сети может быть мучительно медленным. До сих пор мы видели четыре способа ускорить обучение (и найти лучшее решение): применение хорошей стратегии инициализации для весов соединений, использование хорошей функции активации, использование нормализации партии и повторное использование частей предварительно обученной сети (возможно, построенной на вспомогательное задание или использование обучения без учителя). Еще один огромный прирост скорости связан с использованием более быстрого оптимизатора, чем у обычного оптимизатора Gradient Descent. Далее мы представим самые популярные алгоритмы: оптимизацию импульса, ускоренный градиент Нестерова, AdaGrad, RMSProp и, наконец, оптимизацию Адама и Надама."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импульсный оптимизатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представьте себе шар для боулинга, катящийся по пологому склону по гладкой поверхности: он начнет медленно, но будет быстро набирать обороты, пока не достигнет конечной скорости (если есть некоторое трение или сопротивление воздуха). Это очень простая идея, лежащая в основе оптимизации импульса , proposed by Boris Polyak in 1964.13 В отличие от этого, регулярный градиентный спуск просто делает небольшие, регулярные шаги вниз по склону, поэтому алгоритму потребуется гораздо больше времени, чтобы достичь дна.\n",
    "Оптимизация импульса во многом запоминает о том, какими были предыдущие градиенты: на каждой итерации она вычитает локальный градиент из вектора импульса m (умноженного на скорость обучения η ) и обновляет веса, добавляя этот вектор импульса (см. Уравнение 11- 4 ) Другими словами, градиент используется для ускорения, а не для скорости. Чтобы смоделировать какой-то механизм трения и предотвратить слишком большой импульс, алгоритм вводит новый гиперпараметр β , называемый импульсом , который должен быть установлен между 0 (высокое трение) и 1 (без трения). Типичное значение импульса составляет 0,9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-4: Momentum algorithm**\n",
    "\n",
    "1. $\\mathbf{m} \\gets \\beta \\mathbf{m} - \\eta \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta})$\n",
    "2. $\\boldsymbol{\\theta} \\gets \\boldsymbol{\\theta} + \\mathbf{m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете легко проверить, что если градиент остается постоянным, конечная скорость (т. е. Максимальный размер обновлений веса) равна этому градиенту, умноженному на скорость обучения η, умноженную на 1 / (1– β ) (игнорируя знак) , Например, если β = 0,9, то конечная скорость равна 10-кратному градиенту, умноженному на скорость обучения, поэтому оптимизация импульса заканчивается в 10 раз быстрее, чем Gradient Descent! Это позволяет ускорить оптимизацию импульса с плато гораздо быстрее, чем Gradient Descent. Ранее мы видели, что когда входные данные имеют очень разные масштабы, функция стоимости будет выглядеть как удлиненная чаша. Градиентный спуск довольно быстро спускается по крутому склону, но затем спуск по долине занимает очень много времени. Напротив, оптимизация импульса будет катиться вниз по долине все быстрее и быстрее, пока не достигнет дна (оптимальный). В глубоких нейронных сетях, которые не используют пакетную нормализацию, верхние уровни часто заканчивают тем, что имеют входы с очень разными масштабами, поэтому использование оптимизации импульса очень помогает. Это также может помочь проехать мимо локального оптимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственным недостатком оптимизации импульса является то, что он добавляет еще один гиперпараметр для настройки. Однако значение импульса 0,9 обычно хорошо работает на практике и почти всегда идет быстрее, чем обычный градиентный спуск. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нестеров Ускоренный градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один небольшой вариант оптимизации импульса, предложенный Yurii Nesterov in 1983, почти всегда быстрее, чем обыкновенная оптимизация импульса. Метод ускоренного градиента Нестерова (NAG), также известный как оптимизация импульса Нестерова, измеряет градиент функции стоимости не в локальной позиции θ, а немного вперед в направлении импульса при θ + β m (см. Уравнение 11-5 )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-5: Nesterov Accelerated Gradient algorithm**\n",
    "\n",
    "1. $\\mathbf{m} \\gets \\beta \\mathbf{m} - \\eta \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta} + \\beta \\mathbf{m})$\n",
    "2. $\\boldsymbol{\\theta} \\gets \\boldsymbol{\\theta} + \\mathbf{m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот небольшой трюк работает, потому что в общем случае вектор импульса будет указывать в правильном направлении (то есть в направлении оптимума), поэтому будет немного точнее использовать градиент, измеренный немного дальше в этом направлении, а не градиент в исходном положение, как вы можете видеть на рисунке 11-6  (где ∇ 1 представляет градиент функции стоимости, измеренной в начальной точке θ , а ∇ 2 представляет градиент в точке, расположенной в θ + β m ).\n",
    "Как видите, обновление Nesterov заканчивается чуть ближе к оптимальному. Через некоторое время эти небольшие улучшения складываются, и NAG оказывается значительно быстрее, чем обычная оптимизация импульса. Кроме того, обратите внимание, что, когда импульс толкает веса через долину, ∇ 1 продолжает продвигаться дальше через долину, в то время как ∇ 2 толкает обратно к нижней части долины. Это помогает уменьшить колебания и, следовательно, NAG сходится быстрее.\n",
    "NAG, как правило, быстрее, чем обычная оптимизация импульса. Чтобы использовать его, просто установите nesterov = True при создании оптимизатора SGD :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"nesterov.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим снова проблему вытянутой чаши: градиентный спуск начинается с быстрого спуска по самому крутому склону, который не направлен прямо к глобальному оптимуму, а затем очень медленно опускается на дно долины. Было бы хорошо, если бы алгоритм мог скорректировать свое направление раньше, чтобы немного больше указывать на глобальный оптимум. В AdaGrad алгоритм достигает эта коррекция пути масштабирования вниз вектора градиента вдоль крутых размеров (см уравнения 11-6 )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-6: AdaGrad algorithm**\n",
    "\n",
    "1. $\\mathbf{s} \\gets \\mathbf{s} + \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta}) \\otimes \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta})$\n",
    "2. $\\boldsymbol{\\theta} \\gets \\boldsymbol{\\theta} - \\eta \\, \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta}) \\oslash {\\sqrt{\\mathbf{s} + \\epsilon}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "этот алгоритм снижает скорость обучения, но он делает это быстрее для крутых измерений, чем для измерений с более пологими склонами. Это называется адаптивной скоростью обучения . Это помогает более точно направлять полученные обновления к глобальному оптимуму (см. Рис. 11-7  ). Еще одним преимуществом является то, что он требует гораздо меньше настройки гиперпараметра скорости обучения "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"adagrad.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaGrad часто хорошо справляется с простыми квадратичными задачами, но часто останавливается слишком рано при обучении нейронных сетей. Скорость обучения уменьшается настолько, что алгоритм полностью останавливается, прежде чем достичь глобального оптимума. Поэтому, хотя в Keras имеется оптимизатор Adagrad , вы не должны использовать его для обучения глубоких нейронных сетей (хотя он может быть эффективен для более простых задач, таких как линейная регрессия). Тем не менее, понимание AdaGrad полезно для понимания других адаптивных оптимизаторов скорости обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adagrad.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже видели, AdaGrad рискует замедлиться слишком быстро и никогда не приблизится к глобальному оптимуму. В RMSProp алгоритм фиксирует это, накапливая только градиенты из самых последних итераций (в отличие от всех градиентов с самого начала обучения). Это достигается с помощью экспоненциального затухания на первом этапе (см. Уравнение 11-7 )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-7: RMSProp algorithm**\n",
    "\n",
    "1. $\\mathbf{s} \\gets \\beta \\mathbf{s} + (1 - \\beta ) \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta}) \\otimes \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta})$\n",
    "2. $\\boldsymbol{\\theta} \\gets \\boldsymbol{\\theta} - \\eta \\, \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta}) \\oslash {\\sqrt{\\mathbf{s} + \\epsilon}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорость затухания β обычно устанавливается равной 0,9. Да, это снова новый гиперпараметр, но это значение по умолчанию часто работает хорошо, поэтому вам, возможно, не нужно его настраивать вообще.\n",
    "Как и следовало ожидать, Keras имеет оптимизатор RMSprop :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что аргумент rho соответствует β в уравнении 11-7 . За исключением очень простых задач, этот оптимизатор почти всегда работает намного лучше, чем AdaGrad. Фактически, это был предпочтительный алгоритм оптимизации многих исследователей, пока не пришла оптимизация Адама."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Адам , который обозначает адаптивную оценку момента, объединяет идеи оптимизации импульса и RMSProp: так же, как оптимизация импульса, он отслеживает экспоненциально убывающее среднее значение прошлых градиентов; и точно так же, как RMSProp, он отслеживает экспоненциально убывающее среднее из прошлых квадратов градиентов (см. уравнение 11-8 )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equation 11-8: Adam algorithm**\n",
    "\n",
    "1. $\\mathbf{m} \\gets \\beta_1 \\mathbf{m} - (1 - \\beta_1) \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta})$\n",
    "2. $\\mathbf{s} \\gets \\beta_2 \\mathbf{s} + (1 - \\beta_2) \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta}) \\otimes \\nabla_\\boldsymbol{\\theta}J(\\boldsymbol{\\theta})$\n",
    "3. $\\hat{\\mathbf{m}} \\gets \\left(\\dfrac{\\mathbf{m}}{1 - {\\beta_1}^T}\\right)$\n",
    "4. $\\hat{\\mathbf{s}} \\gets \\left(\\dfrac{\\mathbf{s}}{1 - {\\beta_2}^T}\\right)$\n",
    "5. $\\boldsymbol{\\theta} \\gets \\boldsymbol{\\theta} + \\eta \\, \\hat{\\mathbf{m}} \\oslash {\\sqrt{\\hat{\\mathbf{s}} + \\epsilon}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы просто посмотрите на шаги 1, 2 и 5, вы заметите близкое сходство Адама как с оптимизацией импульса, так и с RMSProp. Единственное отличие состоит в том , что шаг 1 вычисляет экспоненциально затухающее в среднем , а не экспоненциально затухающей суммы, но они фактически эквивалентны для коэффициента постоянная , за исключением (в среднем разлагающегося всего 1 - β 1 разы разлагающейся суммы). Шаги 3 и 4 представляют собой некоторые технические детали: поскольку m и s инициализируются в 0, они будут смещены в сторону 0 в начале обучения, поэтому эти два шага помогут повысить m и s в начале обучения.\n",
    "Гиперпараметр затухания импульса β 1 обычно инициализируется равным 0,9, а гиперпараметр затухания масштабирования β 2 часто инициализируется равным 0,999. Как и ранее, сглаживающий член ε обычно инициализируется крошечным числом, таким как 10 –7 . Это значения по умолчанию для класса Adam (точнее, epsilon по умолчанию имеет значение None , что говорит Keras использовать `keras.backend.epsilon()` , по умолчанию 10–7; вы можете изменить его, используя `keras.backend.set_epsilon()`. Вот как создать оптимизатор Adam с помощью Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, стоит упомянуть два варианта Адама:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что на шаге 2 уравнения 11-8 Адам накапливает квадраты градиентов в s (с большим весом для более поздних градиентов). На шаге 5, если мы проигнорируем ε и шаги 3 и 4 (которые в любом случае являются техническими подробностями), Адам уменьшит обновления параметров до квадратного корня из s . Короче говоря, Адам уменьшает масштаб обновления параметров по норме ℓ 2 убитых во времени градиентов (напомним, что норма ℓ 2 - это квадратный корень из суммы квадратов). AdaMax, введенный в той же статье , как Адам, заменяет ℓ 2 нормы на ℓ∞ нормы. В частности, он заменяет шаг2 в уравнении 11-8 с s ← max (β2s,∇θJ(θ)), она удаляется шаг 4, и на этапе 5 масштабировании вниз обновлений градиента на коэффициент х , который представляет из себя максимум затухающих во времени градиентов. На практике это может сделать AdaMax более стабильным, чем Адам, но это действительно зависит от набора данных, и в целом Адам работает лучше. Итак, это еще один оптимизатор, который вы можете попробовать, если у вас возникнут проблемы с Адамом в какой-то задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adamax.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadam Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация Надама - это оптимизация Адама плюс уловка Нестерова, поэтому она часто сходится немного быстрее, чем Адам. В his report introducing this technique, исследователь Тимоти Dozat сравнивает различные оптимизаторы на различных задачах, и считает, что Nadam обычно превосходит по Адаму, но иногда проигрывают RMSProp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Адаптивные методы оптимизации (включая оптимизацию RMSProp, Adam и Nadam) часто бывают хорошими, быстро сходясь к хорошему решению. Тем не менее, 2017 paper  с помощью Ashia С. Вильсона и др. показали, что они могут привести к решениям, которые плохо обобщают некоторые наборы данных. Поэтому, когда вы разочарованы производительностью вашей модели, попробуйте вместо этого использовать простой ускоренный градиент Нестерова: у вашего набора данных может быть просто аллергия на адаптивные градиенты. Также ознакомьтесь с последними исследованиями, потому что они быстро развиваются.\n",
    "Все методы оптимизации, обсуждаемые до сих пор, опираются только на частные производные первого порядка ( якобианы ). Литература по оптимизации также содержит удивительные алгоритмы, основанные на частных производных второго порядка ( гессианы , которые являются частными производными якобианов). К сожалению, эти алгоритмы очень трудно применить к глубоким нейронным сетям, потому что на вывод приходится n 2 гессиан (где n - количество параметров), а не просто n якобианов на выход. Так как DNN обычно имеют десятки тысяч параметров, алгоритмы оптимизации второго порядка часто даже не помещаются в памяти, и даже когда они делают, вычисление гессианов просто слишком медленное.\n",
    "Тренировка разреженных моделей\n",
    "Все только что представленные алгоритмы оптимизации дают плотные модели, что означает, что большинство параметров будет отличным от нуля. Если вам нужна невероятно быстрая модель во время выполнения или если она требует меньшего объема памяти, вы можете вместо этого использовать разреженную модель.\n",
    "Один из простых способов добиться этого - тренировать модель как обычно, а затем избавляться от крошечных весов (установите их на ноль). Обратите внимание, что это, как правило, не приведет к очень разреженной модели, и это может ухудшить производительность модели.\n",
    "Лучшим вариантом является применение сильной регуляризации ℓ 1 во время обучения, так как он подталкивает оптимизатор к обнулению как можно большего количества весов.\n",
    "Если эти методы остаются недостаточными, ознакомьтесь с TensorFlow Model Optimization Toolkit (TF-MOT), который предоставляет API сокращения, способный к итеративному удалению соединений во время обучения в зависимости от их величины.\n",
    "Таблица 11-2  сравнивает все оптимизаторы, которые мы обсуждали до сих пор (* плохо, ** - среднее значение, а *** - хорошо)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"tab11-2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Планирование скорости обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найти хорошую скорость обучения очень важно. Если вы установите его слишком высоко, обучение может отличаться. Если вы установите слишком низкое значение, тренировки в конечном итоге сойдутся к оптимальным, но это займет очень много времени. Если вы установите его немного слишком высоко, поначалу он будет очень быстро прогрессировать, но в итоге он будет танцевать вокруг оптимального значения, никогда не успокаиваясь. Если у вас ограниченный вычислительный бюджет, вам, возможно, придется прервать обучение, пока оно не сошлось должным образом, что приведет к неоптимальному решению (см. Рис. 11-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Lossoptim.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы обсуждали ранее, вы можете найти хорошую скорость обучения, обучив модель за несколько сотен итераций, экспоненциально увеличив скорость обучения от очень маленького значения до очень большого значения, а затем посмотрев на кривую обучения и выбрав Скорость обучения немного ниже той, на которой кривая обучения начинает подниматься. Затем вы можете повторно инициализировать свою модель и обучить ее с этой скоростью обучения.\n",
    "Но вы можете добиться большего успеха, чем постоянная скорость обучения: если вы начинаете с большой скорости обучения, а затем снижаете ее, как только тренировка перестает быстро прогрессировать, вы можете найти хорошее решение быстрее, чем с оптимальной постоянной скоростью обучения. Есть много разных стратегий для снижения скорости обучения во время обучения. Также может быть полезно начать с низкой скорости обучения, увеличить ее, а затем снова отбросить. Эти стратегии называются графиками обучения. Это наиболее часто используемые графики обучения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установите скорость обучения как функцию числа итераций $t : η ( t ) = η_0 / (1 + t / s ) c $. Начальная скорость обучения $η_0$ , мощность c (обычно равная 1) и шаги s являются гиперпараметрами. Скорость обучения падает на каждом этапе. После з шагов, то вплоть до $η_0 / 2$. После несколько стадий, то вплоть до $η_0 / 2$, то он идет вниз к $η_0 / 4$, то $η_0 / 5$, и так далее. Как видите, этот график сначала падает быстро, потом все медленнее. Конечно, планирование мощности требует настройки $η_0 $ и s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 / (1 + steps / s)**c```\n",
    "* Keras uses `c=1` and `s = 1 / decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4872 - accuracy: 0.8281 - val_loss: 0.3982 - val_accuracy: 0.8604\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3767 - accuracy: 0.8659 - val_loss: 0.3673 - val_accuracy: 0.8736\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3411 - accuracy: 0.8782 - val_loss: 0.3704 - val_accuracy: 0.8718\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3180 - accuracy: 0.8851 - val_loss: 0.3471 - val_accuracy: 0.8778\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3003 - accuracy: 0.8919 - val_loss: 0.3381 - val_accuracy: 0.8752\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2839 - accuracy: 0.8986 - val_loss: 0.3375 - val_accuracy: 0.8842\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2715 - accuracy: 0.9017 - val_loss: 0.3348 - val_accuracy: 0.8802\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2596 - accuracy: 0.9070 - val_loss: 0.3451 - val_accuracy: 0.8734\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2483 - accuracy: 0.9096 - val_loss: 0.3232 - val_accuracy: 0.8854\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2386 - accuracy: 0.9138 - val_loss: 0.3231 - val_accuracy: 0.8842\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2305 - accuracy: 0.9159 - val_loss: 0.3216 - val_accuracy: 0.8872\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2206 - accuracy: 0.9208 - val_loss: 0.3470 - val_accuracy: 0.8798\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2132 - accuracy: 0.9230 - val_loss: 0.3311 - val_accuracy: 0.8856\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2069 - accuracy: 0.9250 - val_loss: 0.3422 - val_accuracy: 0.8808\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1981 - accuracy: 0.9284 - val_loss: 0.3243 - val_accuracy: 0.8892\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1930 - accuracy: 0.9306 - val_loss: 0.3293 - val_accuracy: 0.8872\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1863 - accuracy: 0.9327 - val_loss: 0.3389 - val_accuracy: 0.8896\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1794 - accuracy: 0.9356 - val_loss: 0.3326 - val_accuracy: 0.8934\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1729 - accuracy: 0.9386 - val_loss: 0.3467 - val_accuracy: 0.8890\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1674 - accuracy: 0.9406 - val_loss: 0.3394 - val_accuracy: 0.8876\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1609 - accuracy: 0.9423 - val_loss: 0.3419 - val_accuracy: 0.8902\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1559 - accuracy: 0.9445 - val_loss: 0.3336 - val_accuracy: 0.8944\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1512 - accuracy: 0.9459 - val_loss: 0.3416 - val_accuracy: 0.8908\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1452 - accuracy: 0.9481 - val_loss: 0.3577 - val_accuracy: 0.8866\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1408 - accuracy: 0.9501 - val_loss: 0.3478 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установите скорость обучения $η_0$ = 0.1 для 5 эпох. Скорость обучения будет постепенно снижаться в 10 раз каждые 5 секунд . В то время как диспетчеризация мощности снижает скорость обучения все медленнее, экспоненциальная диспетчеризация продолжает снижать ее с коэффициентом 10 с шагом. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 * 0.1**(epoch / s)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7426 - accuracy: 0.7778 - val_loss: 0.6724 - val_accuracy: 0.8012 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6526 - accuracy: 0.8010 - val_loss: 0.7290 - val_accuracy: 0.8200 - lr: 0.0089\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6161 - accuracy: 0.8206 - val_loss: 0.5894 - val_accuracy: 0.8294 - lr: 0.0079\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5536 - accuracy: 0.8352 - val_loss: 0.5460 - val_accuracy: 0.8330 - lr: 0.0071\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5052 - accuracy: 0.8460 - val_loss: 0.5162 - val_accuracy: 0.8350 - lr: 0.0063\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4562 - accuracy: 0.8566 - val_loss: 0.4893 - val_accuracy: 0.8544 - lr: 0.0056\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4156 - accuracy: 0.8665 - val_loss: 0.5113 - val_accuracy: 0.8592 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3959 - accuracy: 0.8758 - val_loss: 0.5848 - val_accuracy: 0.8460 - lr: 0.0045\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3536 - accuracy: 0.8826 - val_loss: 0.4943 - val_accuracy: 0.8638 - lr: 0.0040\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3270 - accuracy: 0.8897 - val_loss: 0.4652 - val_accuracy: 0.8732 - lr: 0.0035\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3075 - accuracy: 0.8955 - val_loss: 0.4860 - val_accuracy: 0.8718 - lr: 0.0032\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2820 - accuracy: 0.9032 - val_loss: 0.4669 - val_accuracy: 0.8728 - lr: 0.0028\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2640 - accuracy: 0.9080 - val_loss: 0.4500 - val_accuracy: 0.8790 - lr: 0.0025\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2422 - accuracy: 0.9162 - val_loss: 0.4465 - val_accuracy: 0.8784 - lr: 0.0022\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2258 - accuracy: 0.9209 - val_loss: 0.4554 - val_accuracy: 0.8812 - lr: 0.0020\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2073 - accuracy: 0.9279 - val_loss: 0.4718 - val_accuracy: 0.8868 - lr: 0.0018\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1980 - accuracy: 0.9305 - val_loss: 0.4954 - val_accuracy: 0.8842 - lr: 0.0016\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1811 - accuracy: 0.9354 - val_loss: 0.4870 - val_accuracy: 0.8840 - lr: 0.0014\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1701 - accuracy: 0.9409 - val_loss: 0.5093 - val_accuracy: 0.8926 - lr: 0.0013\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1573 - accuracy: 0.9447 - val_loss: 0.4865 - val_accuracy: 0.8900 - lr: 0.0011\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1469 - accuracy: 0.9491 - val_loss: 0.5381 - val_accuracy: 0.8888 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1396 - accuracy: 0.9527 - val_loss: 0.5300 - val_accuracy: 0.8872 - lr: 8.9125e-04\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1289 - accuracy: 0.9567 - val_loss: 0.5476 - val_accuracy: 0.8912 - lr: 7.9433e-04\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1213 - accuracy: 0.9596 - val_loss: 0.5769 - val_accuracy: 0.8936 - lr: 7.0795e-04\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1146 - accuracy: 0.9616 - val_loss: 0.5766 - val_accuracy: 0.8928 - lr: 6.3096e-04\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule function can take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 0.4687 - accuracy: 0.8361 - val_loss: 0.3612 - val_accuracy: 0.8678 - lr: 8.9124e-04\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3379 - accuracy: 0.8778 - val_loss: 0.3815 - val_accuracy: 0.8676 - lr: 7.9430e-04\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2932 - accuracy: 0.8908 - val_loss: 0.3263 - val_accuracy: 0.8852 - lr: 7.0791e-04\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2592 - accuracy: 0.9030 - val_loss: 0.3252 - val_accuracy: 0.8824 - lr: 6.3092e-04\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2276 - accuracy: 0.9150 - val_loss: 0.3133 - val_accuracy: 0.8908 - lr: 5.6229e-04\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2033 - accuracy: 0.9238 - val_loss: 0.3310 - val_accuracy: 0.8864 - lr: 5.0114e-04\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1782 - accuracy: 0.9338 - val_loss: 0.3222 - val_accuracy: 0.8964 - lr: 4.4663e-04\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1564 - accuracy: 0.9410 - val_loss: 0.3270 - val_accuracy: 0.8966 - lr: 3.9805e-04\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1367 - accuracy: 0.9488 - val_loss: 0.3266 - val_accuracy: 0.9016 - lr: 3.5476e-04\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1202 - accuracy: 0.9550 - val_loss: 0.3461 - val_accuracy: 0.9004 - lr: 3.1618e-04\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1058 - accuracy: 0.9604 - val_loss: 0.3385 - val_accuracy: 0.9022 - lr: 2.8179e-04\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0915 - accuracy: 0.9674 - val_loss: 0.3690 - val_accuracy: 0.8992 - lr: 2.5114e-04\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9717 - val_loss: 0.3636 - val_accuracy: 0.9042 - lr: 2.2382e-04\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0703 - accuracy: 0.9760 - val_loss: 0.3698 - val_accuracy: 0.9054 - lr: 1.9948e-04\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0615 - accuracy: 0.9792 - val_loss: 0.3858 - val_accuracy: 0.8994 - lr: 1.7778e-04\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0538 - accuracy: 0.9824 - val_loss: 0.4082 - val_accuracy: 0.8996 - lr: 1.5845e-04\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.4068 - val_accuracy: 0.9036 - lr: 1.4121e-04\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.4191 - val_accuracy: 0.9050 - lr: 1.2586e-04\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.4277 - val_accuracy: 0.9014 - lr: 1.1217e-04\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0319 - accuracy: 0.9914 - val_loss: 0.4386 - val_accuracy: 0.9016 - lr: 9.9967e-05\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.4510 - val_accuracy: 0.9024 - lr: 8.9094e-05\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.4641 - val_accuracy: 0.9012 - lr: 7.9404e-05\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0226 - accuracy: 0.9949 - val_loss: 0.4659 - val_accuracy: 0.9034 - lr: 7.0768e-05\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 0.4738 - val_accuracy: 0.9038 - lr: 6.3071e-05\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.4844 - val_accuracy: 0.9010 - lr: 5.6211e-05\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAHOCAYAAABaeEesAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACEa0lEQVR4nO3deVxU1fsH8M/AwLDvgoIoiOIGipYi7qgk7iup5W5mauZSWpalfrPUtl9k2mIa5L5n5pKAgCuKu+C+oQKKguzbwJzfH8TkyICAozPA5/168cI599x7n2cuA4/3nnuuRAghQERERETPTU/bARARERFVFyysiIiIiDSEhRURERGRhrCwIiIiItIQFlZEREREGsLCioiIiEhDWFgRERERaQgLKyIiIiINYWFFREREpCEsrIioBBcXF7i4uDzXNhYsWACJRIKIiAiNxPQ8NJFPZWnqfVCXQ1BQECQSCYKCgp5r25qmUCjQsmVL9O7dW9uhlMvt27chkUgwduxYbYfyTBX9ebp+/TqkUilWrFjxYgMjJRZWpPOKf+mV9eXl5aXtMKuUsWPHQiKR4Pbt29oORUkIgbVr16Jbt26wtbWFoaEhHBwc0KpVK0yZMgWRkZHaDpHKKSgoCOfPn8eCBQu0HYrO0FZx37BhQ7z55ptYsGAB0tPTX/r+ayKptgMgKi83NzeMHDlS7bLatWu/5Giqt7CwsJe+z/HjxyMoKAjW1tbo27cvHB0d8ejRI1y9ehWrVq1Ceno6unTp8tLj0mWDBg1Cu3btUKdOHW2HolRYWIiFCxeiS5cuaNu2rbbDIQCzZ8/GH3/8gR9++AHz5s3TdjjVHgsrqjIaNmzI/wG/JG5ubi91f4cOHUJQUBC8vLwQGRkJCwsLleWpqam4ePHiS42pKrC0tISlpaW2w1CxZ88e3LlzB5999pm2Q6F/eXh4oGXLlli5ciU+/vhj6OnxYtWLxHeXqp1FixZBIpFg2rRpJZYVj0+YOXNmibaIiAisXLkSzZs3h5GREerVq4e5c+ciNzdX7X7+/vtv+Pr6wtLSEsbGxvDy8sL333+PwsJClX5Pjt+4efMmhg4dCmtra5iamqJHjx44d+6c2u0nJSVh5syZaNiwIWQyGezs7DBkyBDExMSU6Ft8mSErKwuzZs2Ck5MTZDIZWrRoga1bt5boGxwcDABwdXVVXk7t2rVrie09KSEhAfPnz0e7du1gb28PmUwGFxcXTJkyBUlJSWpzKK9jx44BAMaMGVOiqAIAKysrtG/fvkR7fn4+AgMD0bZtW5ibm8PMzAzNmjXDrFmz8Pjx4xL9y/P+PLnt7777Dq1bt4apqSnMzc3RqVMn/PXXX2r73717FyNGjICNjQ3MzMzQpUsXHDx4UG3fssZGRUREQCKRlOs/EaVtp/h4Pnz4EOPHj4e9vT2MjY3Rrl27UsfmnD9/Hr1794a5uTksLS3Ru3dvxMTEVPiycXFMQ4YMKbGsa9eukEgkyM3NxZw5c+Ds7AwjIyN4enpi9erVpW5z586d6N69O6ytrWFkZAQPDw988803JT5rT74fu3fvRqdOnWBubl6hS3AxMTHo1asXLC0tYWFhgX79+qkt6k+dOoV3330XHh4eyt8Bnp6eWLJkCeRyubJf8ec/Li4OcXFxKkMYnj7Ghw4dwqBBg+Dg4ACZTAZnZ2cMHjwYhw8fVhvr5s2b0bp1axgbG6NOnTp47733kJOTo7bv66+/jjt37mjlbHRNwzNWVO18/PHHCAkJwY8//ojXXnsN/fr1AwAcOXIEixYtQosWLbBkyZIS63377beIiIjAsGHD0LdvX+zZswdLlizBmTNnsHfvXkgkEmXfwMBAzJgxAzY2NnjjjTdgamqKXbt2YebMmTh06BC2bt2q0h8o+gXr7e2NZs2aYfz48bhx4wZ27twJX19fXLp0CQ4ODsq+N27cQNeuXREfH4/XXnsNAwcORFJSErZt24Z//vkHYWFh8Pb2Vtm+XC7Ha6+9hpSUFAwePBjZ2dnYuHEjXn/9dezbtw+vvfYaAGDGjBkICgrCuXPnMH36dFhZWQHAM//4HDx4EN9++y26d+8Ob29vGBgY4MyZM/jpp5/wzz//4PTp05U+e2JjYwOgaKBteeXm5qJnz544ePAgGjVqhHHjxkEmk+HatWv4+eefMXr0aFhbWyv7l/f9AYC8vDz4+/sjIiICrVq1woQJEyCXy7F7924MGDAAy5Ytw7vvvqvsn5iYCB8fH8THx6Nnz55o3bo1Ll26BD8/P/j6+lbqPXleqamp6NChAywsLPDmm28iKSkJmzZtQs+ePXHq1Cl4eHgo+547dw6dOnVCdnY2Bg8ejIYNG+LUqVPo2LEjWrZsWe59CiEQERGBJk2aKH+u1AkICMD58+cREBAAuVyOzZs3Y8KECXjw4AHmzp2r0vfjjz/G4sWLUbduXQwZMgQWFhY4ePAgZs+ejePHj2PLli0ltr9lyxbs378fffv2xZQpU5CRkVGu+G/evIkOHTqgbdu2mDJlCq5du4YdO3bg8OHDOHr0KJo2barsu3LlSuzatQudO3dG7969kZ2djYiICMydOxfR0dHYtm0bgKL/FMyfPx/ff/89gKLPX7En/zOzfPlyTJs2DcbGxhg0aBDq1auH+Ph4HD58GFu3bkXHjh1VYl2+fDn27t2LAQMGoGvXrti3bx+WLVuG5ORkrFu3rkRuPj4+AIADBw7Az8+vXO8HVZIg0nG3bt0SAISbm5uYP3++2q+9e/eqrHPnzh1hbW0t7OzsREJCgkhNTRUuLi7C2NhYxMbGqvSdP3++ACCMjIxETEyMsl0ulws/Pz8BQPzxxx/K9hs3bgipVCrs7e3FnTt3lO15eXmiS5cuAoBYs2ZNifgBiCVLlqjse968eQKAWLx4sUp7+/bthVQqFfv371dpv3LlijA3Nxeenp4q7fXr1xcAxIABA0ReXp6yPTQ0VAAQPXv2VOk/ZswYAUDcunWrxPtdvL369eurtD148EBkZGSU6BscHCwAiEWLFqm0F7+v4eHhavfxpDt37ghzc3Ohp6cnRo8eLXbs2KHy3qoze/ZsAUCMGjVKFBQUqCxLTU1VibWi78/HH38sAIgFCxYIhUKhbE9PTxevvvqqMDQ0FPHx8cr24vfz6ffgl19+UR77J9+H33//XQAQv//+e4m8wsPDBQAxf/58lXZ1x6S07RTvc8qUKaKwsFDZ/ttvvwkAYtKkSSr9O3bsKACILVu2qLQXH8OyflaeFBsbKwCIN998U+3y4s9Hs2bNRHp6urI9MTFR1KlTR0ilUnHjxg1l+/79+wUA0atXL5GVlaVsVygU4p133hEAxNatW0u8HxKJRISEhDwz3mJPfkbnzZunsqz457tbt24q7bdv3y7xc6dQKMT48eMFAHH48GGVZeqOX7Hz588LfX194ejoWOJ9VigUKj9rxcfE0tJSXL58WdmenZ0t3N3dhUQiUelfLD09XQAQnTt3LvV9IM1gYUU678lfeqV9TZ8+vcR6W7duFQBEjx49xPDhwwUAsWLFihL9in9RTZw4scSy6OhoAUB0795d2fa///1PABBLly4t0f/YsWMl+hfH7+rqqvJH7sllgwcPVradPn1aABATJkxQ+37MmjVLABAXLlxQthUXDjdv3izRv379+sLGxkalrTKFVWkUCoWwsLAQXbt2VWmvSGElhBD79u0Tzs7OKse1Vq1a4vXXXxdhYWEqfQsKCoSFhYWwtLQUKSkpz9x2Rd6fwsJCYW1tLRo2bKhSVBX766+/BACxbNkyIURRQW1kZCTs7e1FTk6OSt/CwkLh7u6ulcLK1NS0RCEsl8uFVCoVrVu3Vrbdvn1bABCtWrUqEUtWVpawsbEpd2H1zz//CABi1qxZapcXF1br1q0rsezrr78WAMTnn3+ubOvfv78AoLbITk1NFRKJRAwZMkTZVvx+DBo06JmxPqn4c2htbS0yMzNVlikUCuHh4VFqHE87deqUsih/UlmfqSlTpggAYvXq1c/cfvHn6rPPPit12V9//aV2XSMjI9GgQYNn7oOeDy8FUpXRs2dP7Nu3r9z9hwwZgrfeegu//fYbAGDAgAGYPHlyqf07depUou3VV1+FsbExzp49q2w7c+YMANXT+MXatWtXon+xli1blhg0WrduXQBFl22KRUVFAQDu37+vdpzN5cuXld+fvJxjZWUFV1fXEv3r1q2rHMP0vLZv345ffvkFp0+fxuPHj1XGuCQkJDzXtnv27ImbN28iIiICBw8exKlTp3D48GFs3rwZmzdvxty5c/Hll18CKMo9PT0dPXr0ULncV5byvj9XrlzB48eP4ejoiIULF5bo//DhQ2UMxf1zc3PRrVs3GBkZqfTV09ND+/btcfXq1fK9CRrUqFEjmJmZqbRJpVI4ODio/LwVj/FTN4bNxMQELVu2RHh4eLn2mZycDADPPCbqPmvFbU9+dqKiomBqaopVq1ap3Y6xsbHyODypsncjtmrVCqampiptEokEHTt2RExMDM6dOwdnZ2cARWPwfvzxR2zcuBGXL19GZmYmhBDK9SryeThx4gQAqFyOfpbWrVuXaFP3++RJNjY2ePToUbn3QZXDwoqqtcGDBysLq6lTp5bZ197evtT2+Ph45eviuWCeHBNVVv9i6sYfSaVFH8EnC5SUlBQAwO7du7F79+5S483Kynrm9ov3oVAoSt1OeX377bf44IMPUKtWLbz22muoW7cujI2NAQDff/898vLynnsfUqkUPXr0QI8ePQAABQUFCAoKwuTJk7F48WIMHToUrVu3Vv7hcHJyKve2y/v+FL//sbGxiI2NLXV7xe9/WloagNJ/fkr7OXnRysr3yZ+34p/nWrVqqe1fkfiLfx5KG0BdTN17Vbyf4vcTKDoWBQUFagvcYk9/Dp7cVkU96xg+GdvQoUOxa9cuuLu7Y9iwYbC3t4eBgQFSU1MRGBhYoc9DamoqJBJJhabNKO/vkyfl5OTAxMSk3PugymFhRdVWSkoK3n77bZiZmUEul+Pdd9/F6dOnS/yPtFhpd7YlJSWp/BIrvmvtwYMHqF+/vtr+6u5sK6/idZ8eIK1NBQUF+Pzzz+Ho6IizZ8+q/BEWQuCrr756IfuVSqV46623cOjQIfzxxx8IDw9H69atlQOj1RWwz6v4/R8yZEipdww+qfhno7SfnwcPHpRoKz5zWVBQUGLZk3+8X4bifIvPxD1NXfylKf65KC5OS5OUlKQ88/P0fp7+rEkkkgqfZXn6xpHyetYxLI4tOjoau3btQs+ePbF7927o6+sr+0ZFRSEwMLBC+7WysoIQAomJiRX6z0JFKBQKpKWloXnz5i9k+/QfTrdA1dbEiRNx7949/Pjjj1iyZAmuXr2K6dOnl9r/0KFDJdpOnjyJnJwclZndW7VqBQBqb1s/ceJEif4VVXy3n6Yu36lT/IegtP/ZPu3Ro0dIS0tDu3btSpzZKH6PXqSni+HGjRvDwsIC0dHRaqdVeB5NmzaFhYUFTp48qXLbfGkaN24MIyMjnDx5ssTUHAqFAkePHi2xTvGlMnWFYfGl5pel+K4/dXFmZ2eXOh2IOs2bN4eenh6uXbtWZj91n7Xitic/O97e3khOTn7m9jTlzJkzas+AHTlyBMB/79WNGzcAAH369FEpqgD1uQFFn7nSPm/Fly73799fucDL4dq1a1AoFPD09Hxh+6AiLKyoWlq5ciW2b9+OYcOGYcyYMZg+fTp69uyJVatWlXoWYs2aNSqXfgoKCvDxxx8DKJpfqdgbb7wBqVSK7777TmUchVwux0cffQQAz/XMsbZt28Lb2xsbNmzApk2bSixXKBTP/XiX4ukN7t27V67+xfMgnT59GtnZ2cr2x48fq50vrKL27duHnTt3qj2Dc/XqVeUxK77lXCqVYtKkSUhLS8P06dNL/MFKS0tDZmZmpWKRSqWYPHky4uLi8MEHH6gtrmJiYpRnNwwNDfH6668jKSkJ3377rUq/3377Te34qtatW0MikWDjxo0qxdi1a9cqfLbjedWvXx8dOnTAmTNnSnw2vv7662eefXqSlZUVWrRogZMnT6qMN3raF198oTIFwoMHD/Ddd99BKpXijTfeULa/9957AIpm5S8ev/Wk+/fv49KlS+WO71keP35cYiqWP/74AxcuXEC3bt2UZ9mKz1Q/Pb9UbGwsFi9erHbbxeOb1M2L984770BfXx/z5s1DXFycyrLiM1nP6/jx4wDApxe8BLwUSFXG9evXy5w0sXjZlStXMGPGDNSrVw8///wzACgnDWzRogXefvtteHt7l7gU0aNHD7Rr1w7Dhw+HjY0N9uzZg5iYGPTs2VPlUTpubm5YunQp3n//fbRo0QKvv/46TE1N8ffff+Py5csYMGBAqY/eKa8NGzbA19cXw4cPx/fff49XXnkFRkZGuHPnDo4dO4aHDx+WOnFpeXTr1g3ffPMNJk2ahICAAJiamqJevXoqf9SepKenhylTpuDbb79Fy5Yt0a9fP6Snp2Pv3r2oX78+HB0dKx0LUDQQfObMmbCzs0Pnzp3h5uYGIQSuX7+OPXv2ID8/H5MnT1aZu+t///sfoqKisGbNGkRFRaFXr16QyWS4efMm9u3bh8OHD1f6zOHChQtx+vRp/PDDD9i9eze6dOmCWrVqIT4+HhcuXMC5c+dw7Ngx5ZicJUuWICwsDPPmzcPhw4fRqlUrXLp0CXv27MFrr71W4kyEk5MThg0bho0bN+KVV16Bv78/kpKSsGPHDvj7+yvnQHpZli1bhs6dO2P48OEYMmQI3NzccPr0aURFRaFz5844ePBguWfrHjhwIBYsWIDo6OhSB5E3aNAAHh4eGDJkiHIeq6SkJHzxxRdo0KCBsp+/vz8+/fRTfP7552jYsCH8/f1Rv359JCcn4/r16zh06BAWLVqkMr/U8+jUqRN++OEHREVFoU2bNrh69Sp27NgBS0tL/Pjjj8p+bdu2Rdu2bbF582YkJiaiXbt2uHPnDv766y/06dNH7X/eunXrhpMnT6Jfv37o1KkTDA0N0bFjR3Ts2BGenp74/vvv8d5776F58+YYOHAg6tevj/v37+PgwYPo06ePch6sygoJCYG+vj769u37XNuhctDmLYlE5VGe6RaKf5Tz8vJE69athZ6enoiMjCyxrV27dinncime+uDJaQF++eUX0axZMyGTyUTdunXFRx99JLKzs9XGtXPnTtGlSxdhbm4uZDKZ8PT0FN9++62Qy+Vq4x8zZoza7QAQXbp0KdGekpIi5s2bJzw8PISxsbEwMzMTjRo1Em+88YbYvn27St+ybuUuvsX9aV999ZVo1KiRMDAwKBGDuu3l5+eLL774QjRq1EjIZDJRr149MWvWLJGRkaG2f0WmW0hKShIrV64UQ4cOFY0bNxbm5ubCwMBA1KlTR/Tt21dlrqIn5ebmim+++UZ4eXkp36NmzZqJ999/Xzx+/Pi53p+CggLxyy+/iA4dOggLCwtlzv7+/uKnn34qcVt+XFycGDZsmLCyshImJiaiU6dOIjIystT3ISsrS0ybNk04ODgImUwmWrRoIdatW6ex6RbU/UyV9V6cOXNG9OzZU5iZmQlzc3PRq1cvceHCBdG3b18BQOX9LMu9e/eEvr6+mDZtWollxe91dna2+OCDD4STk5MwNDQUzZs3F7/99lup2wwJCRH9+vUTtWrVEgYGBqJ27drCx8dHfP755ypTIJQ1jUVZnvyMnj9/Xvj7+wtzc3NhZmYm+vTpozK/XbGkpCQxfvx44ejoKIyMjISnp6dYvny5uHnzptrPe0ZGhpg4caKoU6eO0NPTU3uMw8PDRd++fYWNjY0wNDQUdevWFUOGDBFHjhxR9inrc1Va/llZWcLMzEwMHDiwQu8LVY5EiDLO1xLVAAsWLMDChQsRHh6udgoFopqqsLAQbm5uyMnJqdAg9jfeeAP79+9HXFycyvi4rl27IjIysszLhKR5q1evxoQJExAZGYnOnTtrO5xqj2OsiIhquIKCArV33i1ZsgRxcXEYOHBghbb3xRdfIDMzE8uXL9dQhFRZBQUF+PLLL9G/f38WVS8Jx1gREdVwmZmZcHJygp+fH9zd3SGXy3H8+HFER0ejTp065Xog9JNcXV0RHBzMySh1wL179zBy5EiMGjVK26HUGCysiIhqOBMTE0yYMAEHDhzAwYMHkZubizp16mDSpEn49NNPKzRxZbFhw4a9gEipolxcXCpcGNPz4RgrIiIiIg3hGCsiIiIiDWFhRURERKQhHGP1EikUCiQkJMDc3LzSz7IiIiKil0sIgYyMDDg6Oj5zslwWVi9RQkJCidm+iYiIqGq4e/cu6tatW2YfFlYvkbm5OQDg1q1byme1VUdyuRz79+/Ha6+9BgMDA22H80LUhBwB5lnd1IQ8a0KOAPN82dLT0+Hs7Kz8O14WFlYvUfHlP3Nzc1hYWGg5mhdHLpfDxMQEFhYW1fYDXxNyBJhndVMT8qwJOQLMU1vKM4yHg9eJiIiINISFFREREZGGsLAiIiIi0hAWVkREREQawsKKiIiISENYWBERERFpCAsrIiIiIg1hYUVERESkISysiIiIiDSEhRURERGRhrCwIiIiItIQFlZEREREGsLCioiIiEhDWFgRERERaQgLKyIiIiINYWFFREREpCEsrIiIiIg0hIUVERERkYawsCIiIiLSEBZWRERERBrCwoqIiIhIQ1hYEREREWkICysiIiIiDWFhRURERKQhLKyIiIiINEQnC6vMzEzMmDEDjo6OMDIygpeXFzZu3FiudZOSkjB27FjY2dnBxMQEPj4+CAsLK9Hv77//xujRo+Hp6QkDAwNIJJJStymXy7Fw4UK4uLhAJpOhSZMmWLZsWaXzIyIioupJqu0A1Bk8eDCio6OxZMkSuLu7Y/369RgxYgQUCgXeeOONUtfLy8tD9+7dkZqaisDAQNjb22P58uXw9/dHaGgounTpouy7Y8cOREVFoVWrVpDJZDh16lSp250yZQrWrFmDzz//HG3atME///yD6dOnIyMjAx9//LFGcyciIqKqS+cKqz179iAkJERZTAGAr68v4uLiMHv2bAwbNgz6+vpq1121ahViYmJw9OhR+Pj4KNdt2bIl5syZg+PHjyv7rly5Enp6RSfs3n333VILq9jYWKxatQpffPEFZs+eDQDo2rUrkpOTsWjRIrzzzjuwsbHRWP5ERERUdencpcAdO3bAzMwMAQEBKu3jxo1DQkKCSnGkbt3GjRsriyoAkEqlGDlyJE6cOIH4+Hhle3FR9Sx//vknhBAYN25ciXhycnKwb9++cm2HiIiIqj+dK6xiYmLQtGlTSKWqJ9NatGihXF7WusX91K0bGxtbqXhq1aqF2rVrVzie0mTlFVR4HSIiItJ9OncpMDk5GQ0aNCjRXny5LTk5ucx11V2WK8+6Fd2mqakpDA0Ny9xmXl4e8vLylK/T09MBAOui4vBBv+p7+VAul6t8r45qQo4A86xuakKeNSFHgHlqK47y0LnCCkCZd+iVtex519X0NhcvXoyFCxeWaP/96G24iESY6OS7rzkhISHaDuGFqwk5AsyzuqkJedaEHAHm+bJkZ2eXu6/O/Wm3tbVVexYoJSUFAMocKP4865a1zbNnz5Zoz8rKQn5+fpnbnDt3LmbNmqV8nZ6eDmdnZ+QWSnDHuBFm+TWqcDxVgVwuR0hICPz8/GBgYKDtcF6ImpAjwDyrm5qQZ03IEWCeL1vxFafy0LnCytPTExs2bEBBQYHKOKsLFy4AADw8PMpct7jfk8qzblnb3LhxI+7fv68yzqo825TJZJDJZGqXBR27g/Gd3FDLXP3y6sDAwKBaf+CBmpEjwDyrm5qQZ03IEWCeL3P/5aVzg9cHDRqEzMxMbNu2TaU9ODgYjo6O8Pb2LnPdy5cvq9w5WFBQgLVr18Lb2xuOjo4VjmfAgAGQSCQIDg5WaQ8KCoKxsTH8/f0rvE0AyJEXYnn49UqtS0RERLpJ585Y9erVC35+fpg8eTLS09PRsGFDbNiwAfv27cPatWuVc1hNmDABwcHBuHHjBurXrw8AGD9+PJYvX46AgAAsWbIE9vb2WLFiBa5cuYLQ0FCV/cTFxSE6OhoAcOPGDQDA1q1bAQAuLi549dVXAQDNmzfHhAkTMH/+fOjr66NNmzbYv38/fv31VyxatKhSlxeNDPSQD2D98Tt4q5Mr6lqbVOq9IiIiIt2ic4UVAGzfvh2ffPIJPvvsM6SkpKBJkybYsGEDhg8fruxTWFiIwsJCCCGUbTKZDGFhYZgzZw6mTZuG7OxseHl5Ye/evSqzrgNAeHh4ibmpiufOGjNmDIKCgpTtK1asgJOTE5YtW4b79+/DxcUFgYGBmDZtWqXye7OtM34/+RD5hQr8EHYNXw1tWantEBERkW7RycLKzMwMgYGBCAwMLLVPUFCQSvFTzMHBocRlO3XGjh2LsWPHliseAwMDLFiwAAsWLChX/2cZ3a4etsU8RnpuAbaeuodJXdzgVstMI9smIiIi7dG5MVY1gYWxASZ1cQMAKATwXchVLUdEREREmsDCSkvGtneBnZkhAGD3+UTEJqRpOSIiIiJ6XiystMRUJsVU34bK19/u51krIiKiqo6FlRa94V0PjpZGAIADl5Nw8naKliMiIiKi58HCSotkUn3M6OGufP3VP1dU7nIkIiKiqoWFlZYNbu2EBnamAIATt1IQceWhliMiIiKiymJhpWVSfT180LOx8vWSvZdRqOBZKyIioqqIhZUO6OVRG17OVgCAKw8ysO30Pe0GRERERJXCwkoHSCQSzO3VRPn6/0KuIldeqMWIiIiIqDJYWOkI7wa26N7EHgCQmJaL34/c1m5AREREVGEsrHTIh72aQE9S9O8VEdfxOCtfuwERERFRhbCw0iHuDuYY+kpdAEBGbgGWh1/XckRERERUESysdMxMP3fIpEWH5Y9jcbibkq3liIiIiKi8WFjpmDqWxhjf0RUAkF+o4AOaiYiIqhAWVjronS5usDIxAADsOBOPmHg+oJmIiKgqYGGlgyyNDfDuEw9oXrrvshajISIiovJiYaWjRvnUR11rYwDAoWuPcOgaH3VDRESk61hY6SiZVB+zn3jUzRe7L/FRN0RERDqOhZUO69fCEZ5OlgCAy/czsOXkXS1HRERERGVhYaXD9PQkmNenqfL1N/uvIjOvQIsRERERUVlYWOk47wa28G9eGwDwKDMPP0Vw0lAiIiJdxcKqCpjbuwkM9IuedbPy0C3ce8xJQ4mIiHQRC6sqoL6tKca2dwEA5Bco8NW+K9oNiIiIiNRiYVVFvNutEWxMDQEAf51LwOk7j7UcERERET2NhVUVYWlsgJk9GilfL/r7IoTg9AtERES6hIVVFTKibT00tDcDAJy+k4q/zydqOSIiIiJ6EgurKkSqr4dPnph+Ycney8iVF2oxIiIiInoSC6sqpqt7LXRqZAcAiE/Nweojt7QcERERERVjYVXFSCQSzOvTDHpFsy9gRfgNJGXkajcoIiIiAsDCqkpqXNscw9vWAwBk5hXga06/QEREpBNYWFVR7/u5w9xICgDYcuoezt5N1W5ARERExMKqqrI1k2GWn7vy9fy/YqFQcPoFIiIibWJhVYWNbFcf7g5F0y+cu5uKrafvaTkiIiKimo2FVRVmoK+HBf2aK19/te8y0nPlWoyIiIioZmNhVcW1b2iH3p61AQCPMvPxQ+g1LUdERERUc7GwqgY+7t0UMmnRoQw6ehvXkzK0HBEREVHNxMKqGqhrbYLJXd0AAAUKgYW7+BxBIiIibWBhVU2808UNTlbGAIBD1x5h/8UHWo6IiIio5mFhVU0YGehj3hPPEfz874t8jiAREdFLxsKqGvH3qI0ODW0BAPce52DlwZtajoiIiKhmYWFVjUgkEszv1xz6/z5IcHnEddxNydZyVERERDUHC6tqxt3BHGN8XAAAuXIFFu66qN2AiIiIahAWVtXQTL9GsDeXAQBCLz1ACAeyExERvRQsrKohcyMDfNq3mfL1gr9ikZ1foMWIiIiIagYWVtVU3xZ10LGhHQAgPjUHPx64ruWIiIiIqj8WVtWURCLB/wY0h6F+0SFeeegmZ2QnIiJ6wVhYVWMNaplhUpcGAAB5ocC8P2M4IzsREdELxMKqmpvq2xDONkUzskfdTMHOswlajoiIiKj6YmFVzRkZ6ON//T2UrxftvoS0HLkWIyIiIqq+WFjVAL5N7NGzuQMA4FFmHr7bf0XLEREREVVPLKxqiM/6NYexgT4AYE1UHC7cS9NyRERERNUPC6sawsnKGNN7NAIAKATw8Y4LKChUaDkqIiKi6oWFVQ0yoaMr3B3MAAAX4tMQdPS2dgMiIiKqZlhY1SAG+npYPLgFJEXPaMa3+6/yIc1EREQapJOFVWZmJmbMmAFHR0cYGRnBy8sLGzduLNe6SUlJGDt2LOzs7GBiYgIfHx+EhYWp7RsaGgofHx+YmJjAzs4OY8eORVJSUol+169fx6hRo1CvXj0YGxvDzc0Ns2bNQnJy8nPlqQ2v1LfGSO/6AIAceSHntiIiItIgnSysBg8ejODgYMyfPx979+5FmzZtMGLECKxfv77M9fLy8tC9e3eEhYUhMDAQO3fuhIODA/z9/REZGanSNzIyEr169YKDgwN27tyJwMBAhIaGonv37sjLy1P2e/jwIdq1a4cjR47g888/x549ezB16lSsXLkSPXr0gEJR9cYpzfFvjNoWRgCAyKsPset8opYjIiIiqh6k2g7gaXv27EFISAjWr1+PESNGAAB8fX0RFxeH2bNnY9iwYdDX11e77qpVqxATE4OjR4/Cx8dHuW7Lli0xZ84cHD9+XNl39uzZcHd3x9atWyGVFr0Nrq6u6NChA1avXo3JkycDAHbu3Ink5GRs2rQJ3bt3V24zLy8PH3/8Mc6dO4dWrVq9sPfjRTA3MsDCAc0xac0pAMD/dsWicyM7WJkYajkyIiKiqk3nzljt2LEDZmZmCAgIUGkfN24cEhISVIojdes2btxYWVQBgFQqxciRI3HixAnEx8cDAOLj4xEdHY1Ro0YpiyoAaN++Pdzd3bFjxw5lm4GBAQDA0tJSZV9WVlYAACMjo8olqmU9m9eGf/PaAIBHmfn4cs8lLUdERERU9elcYRUTE4OmTZuqFDwA0KJFC+XystYt7qdu3djYWJVtlNb3yX0MHDgQ9erVw/vvv4/Y2FhkZmbi4MGDWLJkCfr164emTZtWMEPdsaB/c5jLit7nzSfv4eiNR1qOiIiIqGrTuUuBycnJaNCgQYl2Gxsb5fKy1i3uV9a6xd9L6/vkPiwtLREVFYUhQ4bAw+O/R8MEBARgzZo1ZeaSl5enMl4rPT0dACCXyyGXa/+xMrYm+nj/tUZYsKvobNXcbRfw97s+MDJQf6m1vIpz04UcX5SakCPAPKubmpBnTcgRYJ7aiqM8dK6wAgBJ8XwAFVxW0XVL6/tk++PHjzFgwABkZ2dj3bp1cHZ2RkxMDD7//HP0798fu3fvLnF2rdjixYuxcOHCEu3h4eEwMTEpM4+XxVIArub6uJUhQVxKNt5fFYI+9TQzID8kJEQj29FlNSFHgHlWNzUhz5qQI8A8X5bs7PJPTaRzhZWtra3as1IpKSkA1J9lqui6tra2ANSf/UpJSVHZx9KlS3H27FnExcWhTp06AIBOnTqhSZMm6NatG9atW4cxY8aojWfu3LmYNWuW8nV6ejqcnZ3h6+urjEEXNG6TiQErjkFeKHAgUR/vDeyAxrXNK709uVyOkJAQ+Pn5KceoVTc1IUeAeVY3NSHPmpAjwDxftuIrTuWhc4WVp6cnNmzYgIKCApUzQRcuXAAAlctx6tYt7vekp9ct/n7hwgX07t27RN8n93H27Fk4OTkpi6pibdq0AVD2mC+ZTAaZTFai3cDAQKc+CM2crDG5a0P8EHYNBQqBuX9exI4p7SHVf74heLqW54tQE3IEmGd1UxPyrAk5AszzZe6/vHRu8PqgQYOQmZmJbdu2qbQHBwfD0dER3t7eZa57+fJllTsHCwoKsHbtWnh7e8PR0REA4OTkhLZt22Lt2rUoLCxU9o2KisKVK1cwePBgZZujoyPu3bunvKOw2LFjxwAAdevWrXyyOmSqrxsa2v/3uJtfD93UckRERERVj84VVr169YKfnx8mT56MlStXIjw8HG+//Tb27duHr776SjmH1YQJEyCVShEXF6dcd/z48WjevDkCAgKwfv16hIaG4vXXX8eVK1ewdOlSlf0sXboUly9fRkBAAEJDQ7F+/Xq8/vrr8PDwwLhx45T9pk6dCj09Pfj5+eGPP/5AeHg4li1bhpEjR8LBwQFvvvnmy3ljXjCZVB9fD20BvX+Hl30fcg3XkzK0GxQREVEVo3OFFQBs374do0aNwmeffQZ/f38cP34cGzZsUCliCgsLUVhYqPI4FplMhrCwMPj6+mLatGno168fEhMTsXfvXnTp0kVlH127dsWePXuQmJiIfv36Ydq0afD19UVYWJjK5btXXnkFUVFRaNKkCT755BP06tUL33//Pfr374/o6GjY2dm9+DfkJWlVzxpvdSq6IzO/UIHZW8+jUMHH3RAREZWXzo2xAgAzMzMEBgYiMDCw1D5BQUEICgoq0e7g4IDg4OBy7cfPzw9+fn7P7NeqVSts3769XNus6mb5uSP04gPcfJSFM3dSsfrwLUzsXHL6CyIiIipJJ89YkfYYGejjq6EtUDzjxDf7r+Dmw0ztBkVERFRFsLCiEl51scHY9i4AgLwCBT7cdh4KXhIkIiJ6JhZWpNbsno1Rz6ZoEtPo248RfOy2dgMiIiKqAlhYkVomhlIsHfLfsxS/2ncFd5LLP/MsERFRTcTCikrl42aLUe3qAwBy5IWYs+0cLwkSERGVgYUVlenDXk3gZGUMAIi6mYI1UXHPWIOIiKjmYmFFZTKTqV4SXLz3Eu8SJCIiKgULK3qmjo3sMNqn6JJgrlyBWZvPoaBQoeWoiIiIdA8LKyqXj3o1gaudKQDg7N1U/Bx5Q8sRERER6R4WVlQuJoZSfPt6y/+eJRh6DTHxadoNioiISMewsKJya13PGlO6NgQAFCgEZm0+i1x5oZajIiIi0h0aKaxSUlJw9+5dTWyKdNx73RuhWR0LAMDVB5n4LuSqliMiIiLSHZUurNLS0jB9+nQ4ODigVq1acHV1VS47fvw4evfujVOnTmkkSNIdhlI9/N8wLxjqF/3orDx0E8dvJms5KiIiIt1QqcIqJSUF3t7eWLZsGZydndG0aVMI8d/EkS1atMCRI0ewbt06jQVKuqNxbXO8/5o7AEAI4IOt55CZV6DlqIiIiLSvUoXVggULcPXqVWzYsAEnT55EQECAynJjY2N06dIFBw4c0EiQpHve6tQAbVysAQB3U3Kw6O+LWo6IiIhI+ypVWP3111/o27cvhg0bVmqf+vXr4969e5UOjHSbvp4E3wZ4wcRQHwCwMfou/om9r+WoiIiItKtShVViYiKaNWtWZh8jIyNkZWVVKiiqGurZmuDTvv/9HHy07TwepOdqMSIiIiLtqlRhZWtr+8y7AC9fvow6depUKiiqOoa3cUbP5g4AgMfZcry/mQ9qJiKimqtShVXnzp3x119/IT4+Xu3yixcvYt++fejRo8dzBUe6TyKRYMngFnCwkAEADl9/hN+P8UHNRERUM1WqsPrkk09QUFCADh06YP369Xj06BEA4NKlS1i1ahW6desGmUyG2bNnazRY0k3Wpob47nUvSP6dlf3bkGu4x6vARERUA0krs5Knpyc2bdqE0aNHY9SoUQAAIQQ8PDwghIC5uTk2b96MRo0aaTRY0l0dGtrh7U4N8MvBm5AXCvxxTR+j8gthYGCg7dCIiIhemkoVVgDQv39/3Lx5E8HBwTh+/DhSUlJgYWEBb29vjBs3DnZ2dpqMk6qA919rjCM3HiEmPh0PciT4ct8VLBnSUtthERERvTSVLqwAwMbGBjNnztRULFTFGUr1EDi8Ffr+cAg5cgU2Rt+DbxMH9GxeW9uhERERvRSVGmM1fvx4/PXXX2X22bNnD8aPH1+poKjqcqtlhk96N1G+5hQMRERUk1SqsAoKCsLZs2fL7HPhwgUEBwdXZvNUxb3+ihNa2CgAFE3BMGvzWU7BQERENUKlH8L8LLm5uZBKn+tKI1VREokEwxsolFMwHLmejBUR17UcFRER0YtX6cJKUnxv/VOEELh79y727NkDR0fHSgdGVZupAfDtUE/o/ftj8l3IVZy4laLdoIiIiF6wchdWenp60NfXh75+0bPhFixYoHz95JdUKoWLiwuio6MxfPjwFxY46T5vVxu8171oyg2FAN7bcAYpWflajoqIiOjFKfe1us6dOyvPUh08eBD16tWDi4tLiX76+vqwsbFBt27dMHHiRI0FSlXTtG6NcPxmCo7dTMb99Fy8v/ksVo1pAz099Wc8iYiIqrJyF1YRERHKf+vp6WHcuHH47LPPXkRMVI3o60kQONwLvX84hEeZ+Qi/8hC/Hb6Jtzu7aTs0IiIijavU6HKFQqHpOKgas7cwwv8N88Lo1ScgBPDVvit41cUGretZazs0IiIijXphdwUSPalTo1qY0rXoLFWBQmDa+jNIy5ZrOSoiIiLNqvR8CIWFhdi8eTNCQ0ORkJCAvLy8En0kEgnCwsKeK0CqPmb2cMeJWymIvv0Y8ak5mL31HH4Z9Uqpd5gSERFVNZUqrLKysvDaa68hKioKQghIJBII8d8EkMWv+QeTniTV18MPI1qhd+AhPM6WY//FBwg6ehvjOrhqOzQiIiKNqNSlwEWLFuHYsWNYuHAhHj16BCEEFixYgMTERGzatAmurq4YOnSo2rNYVLPVsTTGt6//92DmL/dcwuk7j7UYERERkeZUqrDavn072rVrh3nz5sHGxkbZ7uDggICAAERERCAsLAxff/21xgKl6qNbEwdM6twAACAvFJi67jSSM1mEExFR1VepwurOnTto167dfxvR01M5O1W3bl306dOHzwqkUs3u2RhtXYuK8sS0XLy38QwK+TxBIiKq4ipVWJmamkJP779VLS0tkZiYqNKndu3auHPnzvNFR9WWVF8PP45ohVrm/z1P8P9Crmo5KiIioudTqcKqfv36KkWTh4cHDhw4oDxrJYRAWFgY6tSpo5koqVqytzDC8jdaQ//fWdh/DL+O0IsPtBwVERFR5VWqsOrevTvCw8NRUFAAABgzZgzu3LkDHx8fzJ49Gx07dsTZs2cxZMgQjQZL1U9bVxvM7dVE+Xrm5rO4k5ytxYiIiIgqr1LTLUycOBG2trZ4+PAh6tSpg/Hjx+PMmTNYsWIFzp49CwAYMmQIFixYoMFQqbqa0NEVp+IeY2/MfWTkFuCdtaewfUp7GBnoazs0IiKiCqnUGatGjRrhww8/VLnUt2zZMty/fx/Hjh1DQkICtmzZAhMTE40FStWXRCLBV0NboIGdKQDgYmI6Pv0zRmVuNCIioqpAo4+0qVWrFry9vVG7dm0AwPXr1zW5earGzI0M8NPIV2D871mqLafuYWP0XS1HRUREVDEv5FmBcXFxGD9+PJo3b/4iNk/VVOPa5lgyxFP5ev7OWE4eSkREVUqFx1hFRkbi1KlTkEql6NChA1555RXlssTERCxcuBC///475HI5nJycNBosVX8DvJxw5k4qgo7eRn6hAu+sOYVd0zrCwcJI26ERERE9U7nPWOXn56N3797o1q0bZs+ejZkzZ6Jt27aYMWMGAGD16tVwd3fHr7/+ilq1auGHH37AjRs3XlTcVI190qepcvLQpIw8vLP2FPIKCrUcFRER0bOV+4xVYGAg9u3bB0dHRwwcOBBCCOzYsQPLli2Dvr4+/u///g/W1tb44osvMGnSJMhkshcZN1VjBvp6WPFma/RfdhgJabk4cycVn/0ZiyVDPPlgbyIi0mnlLqw2bdoEOzs7XLhwAdbW1gCABQsWoGnTpvj+++/Rpk0b7N69G3Z2di8sWKo57Mxk+HX0qxjy01HkFSiw6eRdeDhZYJSPi7ZDIyIiKlW5LwVevXoVAwcOVBZVQNFdgIMGDQIArFixgkUVaZSHkyW+GtpC+Xrhros4fjNZixERERGVrdyFVWZmJhwdHUu0Fw9Qb9mypeaiIvrXAC8nvN25AQCgQCEwZd1pxKfmaDkqIiIi9So03cKTD14uVjzmRSqt1CTuRM80p2djdGpUdDY0OSsfk9acRK6cg9mJiEj3VKgaunfvHk6cOFGiDQCio6PVzpTdtm3b5wiPCJDq62HZiFbo/+MR3EnJRkx8Oj7cdh7fD/PiYHYiItIpFSqsVq1ahVWrVpVoF0KgXbt2atcpLOSZBXp+ViaGWDn6VQxacQTZ+YXYeTYBjezN8G63RtoOjYiISKnchdWYMWNeZBxEz9S4tjm+e90L76w9BQD4Zv9VNKhlht6edZ6xJhER0ctR7sLq999/f5FxqMjMzMS8efOwefNmpKSkoEmTJvjoo48wfPjwZ66blJSEOXPm4O+//0Z2djZatmyJRYsWoXv37iX6hoaG4tNPP8W5c+dgYmKCvn374quvvoK9vX2JvjExMVi4cCEiIiKQnp6OOnXqoHfv3lixYoVGcqby8feojTn+jfHVvisAgFmbz6KutTFa1LXSbmBERER4Qc8KfF6DBw9GcHAw5s+fj71796JNmzYYMWIE1q9fX+Z6eXl56N69O8LCwhAYGIidO3fCwcEB/v7+iIyMVOkbGRmJXr16wcHBATt37kRgYCBCQ0PRvXt35OXlqfQNDw9H27ZtkZ6ejp9//hn79+/H559/DiMjPmZFGyZ3ccPg1kV3o+bKFZj4x0ncT8vVclRERESVeFbgi7Znzx6EhIRg/fr1GDFiBADA19cXcXFxmD17NoYNGwZ9fX21665atQoxMTE4evQofHx8lOu2bNkSc+bMwfHjx5V9Z8+eDXd3d2zdulV5R6Orqys6dOiA1atXY/LkyQCA7OxsvPnmm+jWrRt27dqlMlh61KhRL+Q9oLJJJBIsHuyJuynZiL79GA/S8zAhOBpb3vGBiaHO/UgTEVENonNnrHbs2AEzMzMEBASotI8bNw4JCQkqxZG6dRs3bqwsqoCiaSBGjhyJEydOID4+HgAQHx+P6OhojBo1SmWaiPbt28Pd3R07duxQtm3ZsgWJiYmYPXs270DTITKpPn4e+QqcbYwBALEJ6Zi16RwUipJ3phIREb0sOldYxcTEoGnTpiXmxWrRooVyeVnrFvdTt25sbKzKNkrr++Q+Dh48CKDo7saOHTvC0NAQ1tbWGDFiBBISEiqSGmmYrZkMq8a0gbms6GdlX+x9fLP/ipajIiKimkznrpskJyejQYMGJdptbGyUy8tat7hfWesWfy+t75P7KD7LNWTIELz99tv4/PPPcfXqVXzyySfo0qWLcuC7Onl5eSrjtdLT0wEAcrkccrm81DyquuLcXkaOrjZG+H5YC0xccxoKAayIuAEXG2MMalXyKQGa9DJz1CbmWb3UhDxrQo4A89RWHOWhc4UVgDIvuT3rclxF1i2t75PtCoUCADBs2DAsXboUQNG4rdq1a2PgwIFYv3493nrrLbXbWbx4MRYuXFiiPTw8vNRirDoJCQl5afsaWF+C7beLxt7N3XEBdy6fQyPLF39Z8GXmqE3Ms3qpCXnWhBwB5vmyZGdnl7uvzhVWtra2as9KpaSkAFB/lqmi69ra2gJQf/YrJSVFZR/FfXv27KnSr2fPnpBIJDh9+nSp8cydOxezZs1Svk5PT4ezszN8fX2V262O5HI5QkJC4OfnBwMDg5eyz15CwOjvS1h/4h4KhQTBN2XY9FZbNHIweyH700aO2sA8q5eakGdNyBFgni9b8RWn8tC5wsrT0xMbNmxAQUGByjirCxcuAAA8PDzKXLe435OeXrf4+4ULF9C7d+8SfZ/cR4sWLbBx48ZS96nu+YnFZDIZZDJZiXYDA4Nq/UEo9rLz/N8ATySm5SH8ykNk5BZg4toz2D6lPRwsXty0GDyW1QvzrD5qQo4A83yZ+y+vShVW48ePf2YfPT09WFhYoHHjxujbty+cnJzKte1BgwZh5cqV2LZtG4YNG6ZsDw4OhqOjI7y9vctcd8qUKTh+/LiyX0FBAdauXQtvb284OhaNu3FyckLbtm2xdu1afPDBB8rpG6KionDlyhXMmDFDZZuffPIJ9u7di0GDBinb9+7dW+ajfOjlk+rr4cc3WmPYr8cQE5+O+NQcjA+KxqZJPjCT6dz/IYiIqBqq1F+boKAg5TgkdQ9elkgkKu3Tpk3DZ599hnnz5j1z27169YKfnx8mT56M9PR0NGzYEBs2bMC+ffuwdu1aZRE0YcIEBAcH48aNG6hfvz6AooJv+fLlCAgIwJIlS2Bvb48VK1bgypUrCA0NVdnP0qVL4efnh4CAAEyZMgVJSUn46KOP4OHhgXHjxin7NWnSBFOnTsWKFStgbm6OXr164erVq5g3bx5atWqF119/veJvIL0wpjIpVo9tg0HLjyI+NQexCemYuu40Vo15FVJ9nbsJloiIqplK/aW5ceMG+vbtCwcHByxevBiRkZG4fPkyIiMj8eWXX8LBwQH9+/fH8ePH8euvv8LR0RHz58/Hpk2byrX97du3Y9SoUfjss8/g7++P48ePY8OGDXjzzTeVfQoLC1FYWKhSwMlkMoSFhcHX1xfTpk1Dv379kJiYiL1796JLly4q++jatSv27NmDxMRE9OvXD9OmTYOvry/CwsJKXL77/vvv8eWXX+Kvv/5C7969sWjRIgwfPhwHDhyAoaFhZd5CeoHszY0QPL4NLIyK/t8QefUh5v0Zo/Y/AURERJpUqTNWmzZtwokTJ3Du3DmV5+q5u7ujU6dOGDt2LLy8vBAeHo45c+agV69eaNasGVasWKFyea80ZmZmCAwMRGBgYKl9goKCEBQUVKLdwcEBwcHB5crDz88Pfn5+z+ynr6+PDz/8EB9++GG5tkva19DeHCtHv4pRq04gv1CBjdF3UdfaGO92a6Tt0IiIqBqr1BmrVatWISAgQO3DigGgdu3aCAgIwMqVKwEUjWnq27cvzp07V/lIiSrIu4Etvg74bxLYb/ZfxY4z97QYERERVXeVKqzu3bun9m63JxkZGeHevf/+iNWrVw+5uXxQLr1cA7yc8KF/E+XrOVvP4+DVh1qMiIiIqrNKFVZOTk7YuXOnyqziT8rLy8POnTtV7gRMSkqCtbV15aIkeg7vdGmAN73rAQDkhQLvrD2Fs3dTtRsUERFVS5UqrCZMmIDr16+jS5cu2L17t3ICzpSUFPz999/o3Lkzbty4oTItw6FDh9CyZUvNRE1UARKJBAv7N0fP5g4AgOz8Qoz7/QSuJ2VqOTIiIqpuKjV4fc6cObh06RLWrl2L/v37Ayiat6r48S9CCLz55pv46KOPAAAPHjxAnz594O/vr6GwiSpGqq+HwOGtMGb1CRy/lYLH2XKMWX0CWyf7oI6lsbbDIyKiaqJSZ6z09fXxxx9/ICQkBKNHj4aXlxdcXFzg5eWFMWPGICQkBGvWrFHOSu7g4ID/+7//K/FYGKKXychAHyvHvIqmdSwAAPGpORi96gRSs/O1HBkREVUXzzUddffu3dG9e3dNxUL0wlkYGSB4fBsM/ekY7qRk41pSJsYHRWPdW+1gbKiv7fCIiKiK41TUVOPYmxthzYS2sDMrurP19J1UTFl3CvJChZYjIyKiqu65zljdv38fp06dQmpqKgoLC9X2GT169PPsguiFqG9riqBxbTDi1yhk5BUg/MpDzNl6Ht8GtISenkTb4RERURVVqcIqNzcXEydOxIYNG0p9TIgQAhKJhIUV6SwPJ0v8OvpVjPn9BPILFNhxJh4WRlIs6N9c+SxMIiKiiqhUYfXhhx9i3bp1cHd3x4gRI1C3bl1Ipc918otIK3zcbPHD8FaYsu4UFAIIPhYHU5kUc56YVJSIiKi8KlUNbdmyBc2aNcOpU6eeOQM7ka7z96iNr4a2xAdbih65tCLiBkxlUkz1bajlyIiIqKqp1OD11NRU+Pv7s6iiamPoK3Xx+YDmytdf/3MFqw/f0mJERERUFVWqsGratCkePHig6ViItGqUjwvm9vrvEuD//r6ITdF3tBgRERFVNZUqrD788EPs3LkT169f13Q8RFo1qYsb3uv23yXAj7ZfwM6z8VqMiIiIqpJKjbGqXbs2/P390bZtW8yYMQOtWrWCpaWl2r6dO3d+rgCJXraZfu7Iyi/EqsO3IAQwa/M5mBhK4dfMQduhERGRjqtUYdW1a1dIJBIIIbBgwYIyb00vbX4rIl0lkUgwr09TZOcXYsOJOyhUCExddxq/jXkVnd1raTs8IiLSYZUqrD777DPO80PVmkQiwaKBHsjJL8CfZxOQX6jAxD9OYtWYNujYyE7b4RERkY6qVGG1YMECDYdBpHv09ST4JqAlcuUK7Iu9j7wCBSYER2P12DZoW1/9pW8iIqrZ+KxAojJI9fXww4hWeO3f8VXFxdWxm8lajoyIiHQRCyuiZzCU6uHHN1qjR9Oi4ipXrsDba8/gWhovhxMRkapyXQps0KABJBIJQkND4erqigYNGpRr4xKJBDdu3HiuAIl0gaFUDyvebI0p604h9FIScuUK/HpZD+1upaCjO+8WJCKiIuU6Y6VQKKBQKFReCyGe+fXkOkRVnaFUD8vfbI3uTewBAPkKCSauOY3jvCxIRET/KtcZq9u3b5f5mqimkEn1sWJka0z64yQirj5CjlyBcUHRCBrXFm1dbbQdHhERaRnHWBFVkEyqjx9HeKGZVdEZ2ez8QoxZfQJHrz/ScmRERKRtLKyIKkEm1cP4xgp0bmQLAMiRF2JcUDQiriRpOTIiItKmSs1jBQD5+fn4888/ER0djdTUVLUzrEskEqxateq5AiTSVQZ6wIoRXpix5QJCLyUhr6BoEtEf32iNns1razs8IiLSgkoVVnFxcfDz88ONGzcghCi1Hwsrqu5kBvpY8eYrmLHpDPZcuA95ocCUdafx/TAv9GvpqO3wiIjoJatUYTVz5kxcv34do0aNwvjx41G3bl1IpZU++UVUpRlK9fDD8FaQSc9jx5l4FCoEpm88g7wCBYa+Ulfb4RER0UtUqWrowIED6N69O4KDgzUdD1GVJNXXw7cBLWFkoIcNJ+5CIYAPtpxDXkEh3vSur+3wiIjoJanU4HWFQoFWrVppOhaiKk1PT4IvB3libHsXZdsnO2Kw+vAt7QVFREQvVaUKKx8fH1y6dEnTsRBVeRKJBPP7NcOkLv89neB/f1/ED2HXyhyPSERE1UOlCqslS5YgPDwcW7du1XQ8RFWeRCLBR/5NMKNHI2XbdyFX8b+/L0KhYHFFRFSdVWqM1a5du+Dr64thw4ahS5cuaNWqFSwtLUv0k0gk+PTTT587SKKqRiKRYEYPd5gaSvHFnqKzu78fuY3UbDm+GtoCBvqcQo6IqDqqVGG1YMEC5b8jIiIQERGhth8LK6rpJnZuAEsTA3y07TwUAthxJh7pOXIsf7M1jAz0tR0eERFpWKUKq/DwcE3HQVRtvf6qMyyNDTBtwxnkFygQdjkJo1edwMoxr8LS2EDb4RERkQZVqrCSSCSwsLCAl5eXhsMhqp56Nq+N4HFtMfGPk8jMK8CJ2ykY/msUgse3gb25kbbDIyIiDanUQA9fX1+sXLlS07EQVWs+brbYMLEdbEwNAQCXEtMR8PMx3E3J1nJkRESkKZUqrOzt7WFoaKjpWIiqPc+6ltjyjg+crIwBAHHJ2Rj801HExKdpOTIiItKEShVWPXv2RGRkJOflIaoEt1pm2PKODxramwEAHmbkYdgvx3Dw6kMtR0ZERM+rUoXVl19+ieTkZLz99ttISUnRdExE1Z6jlTG2TPLBK/WtAQBZ+YUYHxSNLSfvajkyIiJ6HpUavD5y5EhYWVlh9erVWLt2LVxdXeHg4ACJRKLSTyKRICwsTCOBElU31qaGWPeWN6ZvPIN/Yh+gQCEwe+t53E/LxbvdGpb4PBERke6rVGH15LxVeXl5uHz5Mi5fvlyiH/8wEJXNyEAfK958BZ//fRFBR28DAL4NuYqEtBx8PsADUk4kSkRUpVT6Iczl+SosLNR0vETVjr5e0fMFP+7dRNm24cRdvL3mFLLzC7QYGRERVRT/O0ykAyQSCd7u7IbA4V4w0C8603vgchKG/xqFhxl5Wo6OiIjKi4UVkQ4Z4OWE4PFtYW5UdJX+/L00DFx+BFfuZ2g5MiIiKo9KjbEqdu/ePYSHhyMhIQF5eSX/V81nBRJVXHs3O2x9pz3G/n4CiWm5iE/NwZCfjmLZiFbwbWKv7fCIiKgMlS6sZs+ejcDAQJVxVEII5YD14n+zsCKquMa1zbFzage89cdJnL+Xhsy8AkwIjsanfZthbHsX3hhCRKSjKnUpcOXKlfj222/h6+uLrVu3QgiBMWPGYMOGDXjnnXcglUoxdOhQHDhwQNPxEtUY9hZG2PS2D3p71gYAKASwcNdFfLYzFgWFCi1HR0RE6lSqsPr111/h4uKCvXv3YtCgQQAAFxcXDBs2DMuXL8f+/fvx559/4uFDziRN9DyMDfXx44jWeNe3obJtTVQcxgVFIy1HrsXIiIhInUoVVpcvX4a/vz/09P5bvaDgv9vCu3Tpgj59+uCbb755/giJajg9PQk+6NkY3wa0VN4xeOjaIwz56SjuJPMBzkREuqTSdwVaWVkp/21qaork5GSV5Y0bN0ZsbGylAyMiVUNeqYt1b7WDtYkBAOB6UiYGrjiCYzeSn7EmERG9LJUqrJycnHDv3j3lazc3Nxw/flylT0xMDExNTZ8vOiJS0dbVBn9O7QC3WkWfrZSsfIxcdRzBR2/zoehERDqgUoVVhw4dEBUVpXw9YMAAnDlzBu+88w52796NuXPnYu/evejcubPGAiWiIvVtTbF9Sgd0dq8FAChUCMz/KxYfbjuPvAI+7YCISJsqVViNGjUKbm5uiIuLA1A09YKXlxd+/fVX9O/fH0uXLkX9+vXx9ddfazRYIipiaWyA38e2waQuDZRtm0/ew7BfovAgPVeLkRER1WyVKqy6du2KvXv3on79+gAAMzMzREVFYfPmzfjyyy+xfv16XLhwQbm8ojIzMzFjxgw4OjrCyMgIXl5e2LhxY7nWTUpKwtixY2FnZwcTExP4+PggLCxMbd/Q0FD4+PjAxMQEdnZ2GDt2LJKSksrcfmhoKCQSCSQSCR49elTh3Ig0RV9Pgrm9miJwuBeMDIo+ymfvpqLfssM4feexlqMjIqqZnmvm9ScZGBhg6NChGtnW4MGDER0djSVLlsDd3R3r16/HiBEjoFAo8MYbb5S6Xl5eHrp3747U1FQEBgbC3t4ey5cvh7+/P0JDQ9GlSxdl38jISPTq1Qt9+vTBzp07kZSUhA8//BDdu3fHyZMnIZPJSmw/MzMTEydOhKOjIxISEjSSK9HzGuDlBLdaZpi05hTiU3OQlJGH4b9E4fOBzTGsTT1th0dEVKM8d2F18eJFXL58GVlZWRg1atRzB7Rnzx6EhIQoiykA8PX1RVxcHGbPno1hw4ZBX19f7bqrVq1CTEwMjh49Ch8fH+W6LVu2xJw5c1QG2M+ePRvu7u7YunUrpNKit8HV1RUdOnTA6tWrMXny5BLb/+ijj2BtbY0+ffpg0aJFz50rkaZ4OFnir3c7YMq60zh+KwX5hQp8uO0CYuLT8WnfZjCU8rGgREQvQ6V/20ZHR8PLywuenp4ICAjA2LFjlcsOHjwIExMT/PXXXxXe7o4dO2BmZoaAgACV9nHjxiEhIaHE3YdPr9u4cWNlUQUAUqkUI0eOxIkTJxAfHw8AiI+PR3R0NEaNGqUsqgCgffv2cHd3x44dO0ps+9ChQ/j111/x22+/lVrYEWmTrZkMa9/yxhif/y7Br4mKw7BfjyEhNUeLkRER1RyVOmMVGxuLbt26QU9PDzNnzsTly5exd+9e5fJOnTrBzs4OW7ZsQf/+/Su07ZiYGDRt2lSl4AGAFi1aKJe3b9++1HU7depUor143djYWDg5OSEmJkal/em+R44cUWnLycnBhAkTMGPGDLRu3brcBWNeXp7Kw6nT09MBAHK5HHJ59Z01uzg35qgd83o3RmMHM8zfdRHyQoEzd1LR54dD+L/XW6CDm22FtqXLeWoS86w+akKOAPPUVhzlUanCav78+QCAU6dOoWHDhli4cKFKYSWRSODj44Po6OgKbzs5ORkNGjQo0W5jY6NcXta6xf3KWrf4e2l9n97Hp59+isLCQixcuLCcWRRZvHix2nXCw8NhYmJSoW1VRSEhIdoO4YXT1RxNAUxvBqy+qo+UPAkeZ8sxLugkejkr4OckoFfBZzjrap6axjyrj5qQI8A8X5bs7PI/5aJShVVkZCSGDBmChg0bltqnXr162LdvX2U2D4mk9N/6ZS2r6Lql9X2y/cSJE/j++++xb98+GBsbl7nvp82dOxezZs1Svk5PT4ezszN8fX1ha1uxMwdViVwuR0hICPz8/GBgYKDtcF6IqpLjsGw5Pth2AZFXH0FAgj139ZFlbIdvhnjCyuTZcVeVPJ8X86w+akKOAPN82YqvOJVHpQqrjIwM2Nvbl9knNzcXhYUVn6zQ1tZW7VmplJQUAOrPMlV03eKiprS+T+5j/PjxGDx4MF599VWkpqYCKMoNKHqjZTIZzM3N1cYjk8nU3l1oYGBQrT8IxWpCnrqeYy1LA/w+ti2Wh1/Hd6FXIQQQefURBv0chZ/efAWedS3LtR1dz1NTmGf1URNyBJjny9x/eVVq8Lqzs7NynFJpTp06BTc3twpv29PTE5cuXVJ5qDMAXLhwAQDg4eFR5rrF/cpat/h7aX2f3EdsbCy2bNkCa2tr5dfSpUsBFD3KR92YLiJdoqcnwbTujfDH+LawMTUEANx7nIMhPx3FuuNxfBQOEZEGVaqw6tu3L/bv348DBw6oXb5582ZERUVh4MCBFd72oEGDkJmZiW3btqm0BwcHw9HREd7e3mWue/nyZZU7BwsKCrB27Vp4e3vD0dERQNGzDtu2bYu1a9eqnFWLiorClStXMHjwYGVbeHh4ia8xY8YAAP7880/89ttvFc6RSBs6NaqFv6d1RKt6VgCA/EIFPtkRg2kbziA9t3oPgCUielkqdSnw448/xtatW9GrVy+MGTMGiYmJAIAVK1bg2LFj2LBhA1xcXFTGF5VXr1694Ofnh8mTJyM9PR0NGzbEhg0bsG/fPqxdu1Y51cGECRMQHByMGzduKGd4Hz9+PJYvX46AgAAsWbIE9vb2WLFiBa5cuYLQ0FCV/SxduhR+fn4ICAjAlClTkJSUhI8++ggeHh4YN26csl/Xrl1LxBgREQGg6JmJdnZ2Fc6RSFscrYyx6W0ffLnnEoKO3gYA/H0+EefvpWHZiFZo6Wyl1fiIiKq6Sp2xqlWrFiIjI/Hqq6/it99+w+7duyGEwLvvvot169ahTZs2OHDgACwtyzd+42nbt2/HqFGj8Nlnn8Hf3x/Hjx/Hhg0b8Oabbyr7FBYWorCwUOUyhkwmQ1hYGHx9fTFt2jT069cPiYmJ2Lt3r8qs60BRwbRnzx4kJiaiX79+mDZtGnx9fREWFqZ2XBRRdWEo1cOC/s3x05utYW5U9H+rOynZGPLTUaw8eBMKBS8NEhFVVqVnXm/QoAGOHDmCs2fPIioqCikpKbCwsIC3tzfatGnzXEGZmZkhMDAQgYGBpfYJCgpCUFBQiXYHBwcEBweXaz9+fn7w8/OrcHwLFizAggULKrwekS7p5VkHHk6WeG/jGZy5k4oChcAXey7h6I1H+CagJWzN+B8MIqKKeu5H2nh5ecHLy6tE+7JlyxAeHo7t27c/7y6I6AVxtjHB5kk++Hb/VfwceQMAEH7lIXr/cAjfD2uFV+tZaDlCIqKq5YU9QOz06dPYuXPni9o8EWmIgb4ePurVBMHj28L237sGH6Tn4c3fohAYdh2FvDJIRFRufDIrEQEAurjXwt7pndChYdE8bwoB/BhxE4Ex+ohLLv+sw0RENRkLKyJSsrcwwh/jvTG7Z2Po//vcm7hMCfqvOIZN0Xc45xUR0TOwsCIiFfp6Ekz1bYit7/igvk3RMy2z8wvx4bYLmLTmFFKy8rUcIRGR7mJhRURqtapnjZ1T2sHHXqFs23/xAXp+fxARV5K0GBkRke5iYUVEpTKVSTHcTYGf3vBSPg7nYUYexv4ejfk7Y5Arr/jzQImIqrNyT7fQu3fvCm1Y3XP4iKhq6tHUHq+42mLO1vOIuPIQABB8LA6Hrz/Ct697wYszthMRAahAYbVv374Kb1wikVR4HSLSTfbmRvh9bBusjYrDot2XkFegwI2HWRi84ggmdXHDjB6NIJPqaztMIiKtKndhdevWrRcZBxFVARKJBKN8XODjZotZm8/h/L00KATwU8QNhF16gG8CWqJFXStth0lEpDXlLqyKH3RMRNTQ3hzbJ7fHLwdv4vvQq5AXClx9kIlBK45ichc3TOvekGeviKhG4uB1IqoUqb4epvo2xK5pHdHcsejRN4UKgR/Dr6P/siOIiU/TcoRERC8fCysiei5Nalvgz6kdMLOHO6T/Tip65UEGBiw/gu9CriK/QPGMLRARVR8srIjouRno62F6j0bY+W4HNK3z39mrH8Kuoe+yQzgV91jLERIRvRwsrIhIY5o7WmLn1A6Y3r2R8uzV1QeZGPrzUczfGYPMvAItR0hE9GKxsCIijTKU6mGmnzt2vtsBnk6WAAAhiua98vsuEmGXHmg5QiKiF4eFFRG9EM0dLbFjSnt80rspjAyKftUkpuViQvBJTF1/Gg8z8rQcIRGR5rGwIqIXRqqvh4mdG2D/jC7o1MhO2b77fCJ6fBeJzdF3IYTQYoRERJrFwoqIXrh6tib4Y3xbfPd6S1ibGAAA0nLkmLPtPIb/GoVrDzK0HCERkWawsCKil0IikWBw67oIndUFA70cle3Hb6WgV+AhLNl7Gdn5HNxORFUbCysieqlszWT4fngrBI1rA2cbYwBAgULg58gb6PFtJPbF3OflQSKqslhYEZFWdG1sj5CZXfBe90Yw1C/6VZSQlot31p7C+KBo3EnO1nKEREQVx8KKiLTGyEAfs/zc8c/MzujsXkvZHn7lIXr8XyQCQ68hV16oxQiJiCqGhRURaZ2rnSmCx7XBijdbo7aFEQAgv0CB/wu9Cv/vD+LA5Qe8PEhEVQILKyLSCRKJBL096yD0/S54u3MD5cztt5OzMT7oJMb+Ho3rSbx7kIh0GwsrItIpZjIpPu7dFHumd4K3q42yPfLqQ/h/fwj/23URadlyLUZIRFQ6FlZEpJPcHcyx8e12WP5GazhZ/Xf34Oojt+D7bQTWHY9DoYKXB4lIt7CwIiKdJZFI0KdFHYTO6oKZPdyVj8ZJycrHJzti0OeHQzh2I1nLURIR/YeFFRHpPGNDfUzv0QgH3u+K/i3/m1z08v0MjFgZhXfWnMKtR1lajJCIqAgLKyKqMhytjPHDiFbY8o4PPJwslO37Yu/D77tILPgrFsmZfLgzEWkPCysiqnLauNhg59SO+GpIC9iZGQIoGn8VdPQ2un4dgeXh1zn/FRFpBQsrIqqS9PUkeL2NMyJm++K97o1gbKAPAMjIK8DX/1yB7zcR2HLyLge4E9FLxcKKiKo0M5kUs/zcETG7K0a0dca/018hMS0Xs7eeR58fDiHy6kPtBklENQYLKyKqFhwsjLB4cAvsm9EZ3ZvYK9sv38/AmNUnMPK34zh3N1V7ARJRjcDCioiqFXcHc6wa2wYbJraDp5Olsv3w9UcYsPwI3v7jJK7c5wzuRPRisLAiomrJx80WO6d2wA8jWsHZxljZvv/iA/gHHsSMjWdwm1M0EJGGSbUdABHRi6KnJ0H/lo7wb14bm0/exbID1/AgPQ9CAH+eTcDf5xMR8KozJnd20XaoRFRN8IwVEVV7hlI9jGxXH5GzffFJ76awNjEAUDRFw4YTd9Dj+8PYcVuPc2AR0XNjYUVENYaRgT4mdm6Ag3N8MbOHO8xkRSft8wsUiEjUQ7f/O4zFey7hEQssIqokFlZEVOOYGxlgeo9GODTHF5O6NFA+gzA7vxC/HLyJjksPYNHfF5GUkavlSImoqmFhRUQ1lrWpIeb2aoqwmZ3QqbYChtKiX4m5cgV+O3wLnZaGY+GuWDxIZ4FFROXDwoqIajx7cxmGuipwYGZHjOvgAtm/BVZegQK/H7mNTl+FY/7OGCSm5Wg5UiLSdSysiIj+5WBhhPn9muPQHF+81dFVeYkwv0CB4GNx6PJVBOb9eQF3U7K1HCkR6SoWVkRET7G3MMK8vs1waE43TOrcQPkcwvxCBdZG3UHXbyIwY+MZXL6fruVIiUjXsLAiIipFLXMZ5vZuisMf+mJyVzeYGhYVWIUKgT/PJsD/+0MYHxSN6NspWo6UiHQFCysiomewNZPhQ/8mOPxhN8zs4a6cBwsADlxOQsDPxzDkp6MIvfgACoXQYqREpG0srIiIysna1BDTezTCkY+6YX6/ZnCy+u9ROafiHuOtP07CP/Agtp++B3mhQouREpG2sLAiIqogE0MpxnVwRcTsrvju9ZZwdzBTLrv6IBOzNp9D56/C8XPkDaRly7UYKRG9bCysiIgqyUBfD4Nb18W+6Z3x2+hX8Up9a+WyxLRcLNl7GT5LwjB/Zwwf+ExUQ/AhzEREz0lPT4IezRzQo5kDom+n4JfIGwi7nAQhimZzDz4Whz+i4tCjqQMmdHSFt6sNJBKJtsMmoheAhRURkQa1cbFBGxcb3HqUhd+P3MKWk/eQIy+EEEDIxQcIufgAzR0t8FYnV/TxdFTO9k5E1QM/0UREL4CrnSn+N8ADx+Z2w4f+TVDbwki5LDYhHTM3nUPHpQcQGHqNzyQkqkZYWBERvUBWJoaY3NUNhz70ReBwL7Soa6lclpSRh/8LvYr2iw9g2oYziL6dAiE4XQNRVcZLgUREL4GBvh4GeDmhf0tHnIx7jN8O3UTIxQdQCKBAIbDrXAJ2nUtAk9rmGO3jgoGtHGFiyF/RRFWNTp6xyszMxIwZM+Do6AgjIyN4eXlh48aN5Vo3KSkJY8eOhZ2dHUxMTODj44OwsDC1fUNDQ+Hj4wMTExPY2dlh7NixSEpKUulz6tQpTJ06FZ6enjA3N4eDgwN69OiBAwcOPHeeRFTzSCQStHGxwS+jXsXBOb6Y0tUNNqaGyuWX72fg4x0X4P1lGBbuisXNh5lajJaIKkonC6vBgwcjODgY8+fPx969e9GmTRuMGDEC69evL3O9vLw8dO/eHWFhYQgMDMTOnTvh4OAAf39/REZGqvSNjIxEr1694ODggJ07dyIwMBChoaHo3r078vLylP02bNiAEydOYPz48di5cyd+++03yGQydO/eHX/88ccLyZ+Iaoa61iaY498Ex+Z2w/8Na4lW9ayUyzJyC/D7kdvo9m0kRq06jr0XEjnpKFEVoHPnmffs2YOQkBCsX78eI0aMAAD4+voiLi4Os2fPxrBhw6Cvr6923VWrViEmJgZHjx6Fj4+Pct2WLVtizpw5OH78uLLv7Nmz4e7ujq1bt0IqLXobXF1d0aFDB6xevRqTJ08GAMyZMwfffPONyn569+6N1q1b43//+x9Gjx6t8feAiGoWmVQfg1rVxaBWdXHhXhr+OHYbf51LQF5BUSF16NojHLr2CHZmhhjySl0Mb1MPrnamWo6aiNTRuTNWO3bsgJmZGQICAlTax40bh4SEBJXiSN26jRs3VhZVACCVSjFy5EicOHEC8fHxAID4+HhER0dj1KhRyqIKANq3bw93d3fs2LFD2WZvb19iP/r6+njllVdw9+7dSudJRKSOZ11LfB3QElFzu+Pj3k1Qz8ZEuexRZj5+ibwJ328iMPzXY9h5Nh658kItRktET9O5wiomJgZNmzZVKXgAoEWLFsrlZa1b3E/durGxsSrbKK1vWfsAgIKCAhw6dAjNmzcvsx8RUWVZmxri7c5uiPigK9ZMaIvenrVhoP/fpKJRN1MwfeNZtFtcNBbr6oMMLUZLRMV07lJgcnIyGjRoUKLdxsZGubysdYv7lbVu8ffS+pa1DwBYsGABrl+/jj///LPMfnl5eSrjtdLT0wEAcrkccnn1fX5YcW7MsepjnrqhnYsV2rlYITkzD9vPJmDLyXjcSs4GAKRmy/H7kdv4/chttHK2xNDWTujl4QBzI4MS29H1PDWhJuQIME9txVEeOldYASjzUQ/PegxERdYtrW9Z2/jtt9/wxRdf4P3338eAAQPKjGXx4sVYuHBhifbw8HCYmJioWaN6CQkJ0XYIL1xNyBFgnrrECcD0RsANB+Bokh7OJUtQIIp+Z525m4Yzd9Ow4K9YeNoIeNsLuFsK6D31K60q5Pm8akKOAPN8WbKzs8vdV+cKK1tbW7VnjFJSUgCoP8tU0XVtbW0BqD/7lZKSUuo+fv/9d0yaNAlvv/02vv7662dkAsydOxezZs1Svk5PT4ezszN8fX2VMVRHcrkcISEh8PPzg4FByf81Vwc1IUeAeeq691B0xmrnuQRsPhmPq0lFUzPIhQSnkyU4nQw4WMgwoGUdDPJyRH1rWZXMsyKq6rGsKOb5chVfcSoPnSusPD09sWHDBhQUFKiMs7pw4QIAwMPDo8x1i/s96el1i79fuHABvXv3LtFX3T5+//13vPXWWxgzZgx+/vnncj1AVSaTQSaTlWg3MDCo1h+EYjUhz5qQI8A8dVktSwO81bkhJnRyw/l7adh2+h7+OpeA1OyiSxcP0vPw66Hb+PXQbbRwsoC7oQQ+cgF7k6qVZ0VVxWNZGczz5e2/vHRu8PqgQYOQmZmJbdu2qbQHBwfD0dER3t7eZa57+fJllTsHCwoKsHbtWnh7e8PR0REA4OTkhLZt22Lt2rUoLPzvjpqoqChcuXIFgwcPVtluUFAQ3nrrLYwcORK//fYbn0pPRDpHIpGgpbMV/jfAA8c/7o6fR7ZGj6YOkD5xHfB8fDq23tJHh68i8c6aU9h7IZF3FRJpmM6dserVqxf8/PwwefJkpKeno2HDhtiwYQP27duHtWvXKuewmjBhAoKDg3Hjxg3Ur18fADB+/HgsX74cAQEBWLJkCezt7bFixQpcuXIFoaGhKvtZunQp/Pz8EBAQgClTpiApKQkfffQRPDw8MG7cOGW/LVu2YMKECfDy8sKkSZNw4sQJle20atVK7VkpIiJtkUn14e9RB/4edfAoMw9/nU3A1lP3cDHx3xtoCgX2xd7Hvtj7MJNJ0bN5bfT3ckQHN1tI9XXu/9tEVYrOFVYAsH37dnzyySf47LPPkJKSgiZNmmDDhg0YPny4sk9hYSEKCwtVHlgqk8kQFhaGOXPmYNq0acjOzoaXlxf27t2LLl26qOyja9eu2LNnDz777DP069cPJiYm6Nu3L77++muVQmn37t1QKBQ4ffo0OnToUCLWW7duwcXFRfNvAhGRBtiZyTC+oyvGd3TFhbsp+Hb7EcRkGOFRZj4AIDOvANtO38O20/dga2qIPi3qoH9LR7SuZw29p0e9E9Ez6WRhZWZmhsDAQAQGBpbaJygoCEFBQSXaHRwcEBwcXK79+Pn5wc/Pr8w+pe2HiKiqaVLbHINcFPipZ2ecvJuOnWcT8E/MfWTkFQAAkrPy8cexOPxxLA5OVsbo19IRA7wc0aS2OYdAEJWTThZWRET04kj19dCpUS10alQLiwZ6IOJKEv46l4DQS0nI//cxOvGpOfg58gZ+jrwBt1qm6O1ZB7086qBpHRZZRGVhYUVEVIMZGfw3HisjV479sQ+w81wCjlx/hEJF0VCLGw+zsOzAdSw7cB2udqbo5VEbvT3roLmjBYssoqewsCIiIgCAuZEBhrxSF0NeqYtHmXnYeyERf51LwMm4xygeznrrURZWRNzAiogbcLYxRm+POujlWQct61qyyCICCysiIlLDzkyGUT4uGOXjgqT0XPwTex97LtzH8VvJ+PdEFu6m5OCXgzfxy8GbcLQ0+vfMV228Ut8a+hz4TjUUCysiIiqTvYWRssh6lJmH/bEPsDcmEUdvJCsvFyak5WL1kVtYfeQWbEwN0a2JPXo0dUBndzuYGPJPDdUc/GknIqJyszOT4Q3venjDux4eZ+Uj5OID7IlJxJHrjyAvLCqyUrLysfXUPWw9dQ8yqR46NrRDj2YO6N7UHvbmRlrOgOjFYmFFRESVYm1qiNfbOOP1Ns5Iy5Yj7PIDhFx8gMirD5GdXzSje16BAmGXkxB2OQkA4OVsBb9mDnitmQMa2ptxXBZVOyysiIjouVmaGGBw67oY3LoucuWFOHYzGSEXHyD04gMkZeQp+529m4qzd1Px9T9XUN/WBL6N7dG1cS20a2ALIwN9LWZApBksrIiISKOMDPTh29gevo3tsWiABy7EpyHkYtHZrCsPMpT94pKzEXT0NoKO3oaRgR58GtjCt4k9urrbo56tiRYzIKo8FlZERPTC6OkVPRy6pbMVPujZGHeSsxFy6QFCLt7HyduPUfDv4PdcuQLhVx4i/MpDALFoUMtUeTarrasNZFKezaKqgYUVERG9NPVsTTChoysmdHRFeq4cR649QsSVhwi/kqRyyfDmwyzcfHgLqw7fgomhPtq72aFL41ro2NAOLrYmHJtFOouFFRERaYWFkQF6eRZNMCqEwKXEDIRfSULElSScvpOqnMohO78QoZceIPTSAwCAk5UxOjWyQ4eGRV82pobaTINIBQsrIiLSOolEgmaOFmjmaIGpvg2Rli3HoesPEXGl6OtR5n9ns+JTc7Ax+i42Rt+FRAI0d7RAh4Z26NSwFryczLSYBRELKyIi0kGWJgbo28IRfVs4QqEQiE1Ix+Hrj3D4+kNE336sfFi0EEBMfDpi4tPxS+RNyKR6qG+qh3vmt9ClsQOa1rHgLPD0UrGwIiIinaanJ4FnXUt41rXE5K5uyJUXIvp2Cg5fe4TD1x8hNiFd2TevQIGraXr4ev81fL3/GsyNpPB2tUG7BrZo18CWhRa9cCysiIioSjEy0EenRrXQqVEtAEByZh6O3EjG4WsPcejaIySm5Sr7ZuQWIPRSEkIvFU1QWlxoebsWFVrNHFlokWaxsCIioirN1kyG/i0d0b+lI/Lz8xG8fS+kdT0QHZeKqJspSMnKV/ZVV2i1dXnyjJY5pPp62kqFqgEWVkREVG1IJBLYGwO9vethXEc3CCFwLSkTUTeT//0qWWg9+cgdU0N9tKpnjVfqW+NVF2u0qmcNMxn/VFL58aeFiIiqLYlEAncHc7g7mGO0j8szC62s/MJ/B8k/AgDoSYCmdSzQxsVGWWzVsTTWVjpUBbCwIiKiGkNdoXW9uNC6lYKTt1PwIP2/qR0UAohNSEdsQjqCjt4GUDSP1qsu1njVxQav1reGu4M5x2mREgsrIiKqsSQSCRo5mKORgzlG/Vto3Xucg1NxjxF9OwWn4h7jyoMMCPHfOvGpOYg/m4OdZxMAFF0+9KxrCS9na3g5W6FVPSs4WBhpKSPSNhZWRERE/5JIJHC2MYGzjQkGtnICAKTlyHH6zmOcuv0YJ+NScPZuKnLlCuU6WfmFiLqZgqibKcq2OpZG8HK2Un551rWEiSH/5NYEPMpERERlsDQ2gG9je/g2tgcAyAsViE1Ix8nbKTh95zHO3klFwhNTPABAYlouEtPuY2/MfQCAvl7RJUgvZ0t4/ftQ6oa1zHgHYjXEwoqIiKgCDPT1lGeiiiWl5+LM3VScvZuKs3dScf5eKrLyC5XLCxUClxLTcSkxHRtO3AUAGBnooWkdC3g6WcLD0RIeTpZo5GAGAxZbVRoLKyIioudkb2GEns1ro2fz2gCKCqnrSZk4e/cxzt5NxZk7qbj6IAOKJ8Zq5coVOHOnaFkxmVQPTepYwNPp34LLyRLuDuYstqoQFlZEREQapq8nQePa5mhc2xzD2tQDAGTlFeBCfBrO3k3Fhfg0xMSnIS45W2W9vAIFzt1Nxbm7qco2Q309NKljDg8nSzR3tEDTOhZws+XgeF3FwoqIiOglMJVJlTO8F0vLkSM2Pg0xCWm4EJ+OmPg03HqUpbJefqEC5++l4fy9NGWbRALYyvSxJ+0smjtZoWkdCzSpbY661saQSDj1gzaxsCIiItISS2MDtG9oh/YN7ZRt6blyxManIzYhDRfii75uPcpSmfJBCOBRrgT/XEzCPxeTlO3mRlI0rW2BpnXM0aRO0dmtxg7mMDbUf5lp1WgsrIiIiHSIhZEBfNxs4eP235mtzLwCXExIVw6Av5iQhkuJaZArVM9OZeQW4MTtFJy4/d/UD3oSwMXOFO725nB3MEOjfydIdbUzhaGUY7c0jYUVERGRjjOTSdHW1QZtXW0AAHK5HH/v3oOmbbvg2sNsXL6fjkuJGbiUmI7Ep6Z+UAjg5sMs3HyYhX2x/7Xr60ngYmsC938nSHV3MFMWXBwsX3ksrIiIiKogPQngVssUTRyt0K+lo7L9cVY+Lt1Px+V/C61L99Nx9UEm8gsUKusXKgRuPMzCjYdZyvm2AECqJ4Grnem/BVdRseVWywz1bU1gZMBLis/CwoqIiKgasTY1RHs3O7R3+2/cVqFC4E5KNq4+yMC1Bxm4+iATVx9k4ObDLOQXqhZcBYqiB1VfS8oELvzXLpEAda2N4VbLDA3szNCglika1DJFw1pmqGUu46D5f7GwIiIiqub0/z0L5WpnqpxrCwAKChWIS8nGtQcZuPYgE1eTMnGtlIJLCOBuSg7upuQg4spDlWVmMmlRoWVnWlR41SoqvFztTGvcWS4WVkRERDWUVF8PbrXM4FbLDP4e/7UXFCpwO/nfgispEzcfZuLmo6JxWpl5BSW2k5lXUGJKCKDoLJejpTFc7ExQ39YULrZF3+vbmqC+jWm1vFuRhRURERGpkOrroaG9GRram6HXE+1CCCRl5OHGw0zcfJil/H7zUSbuPc5RmRKiqD8Qn5qD+NQcHLmeXGI/DhayokLLxgQudkUFl4utKerZmsDCyODFJvmCsLAiIiKicpFIJHCwMIKDhZHKGC4AyJUX4nZy1r93IGbixr/fbz7KQkZuybNcAPAgPQ8P0vNw4lZKiWU2poaoZ2MMaY4eroZdR307M9S1NoaztQnqWBrp7AOsWVgRERHRczMy0EeT2hZoUttCpV0IgdRsOW4nZyEuOfvfryzcTs7CnZRsPMrMV7u9lKx8pGTlA9DDyYibKsv09SSobWEEZxtj1LU2gbO1CepaGxcVXjYmcLAwgr6edgbTs7AiIiKiF0YikcDa1BDWpoZoVc+6xPKMXPl/BVdKFuIeZSuLsPvpuWq2WHSXY/ElRqDk2S4DfQkcrYoKrbpWJnC2MYaTtTEcLY3haGUMBwujFzY5KgsrIiIi0hpzIwN4OFnCw8myxLKM7Fys2/kPGni2QWJ6Pu49zsbdlBzcSy36npYjV7tNeaFQFmtAybFdEglQy0yGOlbGcLIyQp1/Cy5HSyPUsTKGo5UR7Exl0KvEWS8WVkRERKSTjAz0UccE8G1cCwYGJQezp+fKEf84B3dTsnHvcQ7uPi76fu9xDu6lZCNDzR2MQNGg+qSMPCRl5OHcXfX7NtTXQ21LI9SxNIKdYWG5Y2ZhRURERFWShZEBLOoYoGkdixLLhBBIzynA3cfZuJuSjfjUHCSm5SIxLQfxqblITM3Bw8y8EncyFssvVOBOSjbupGRDkZdd7phYWBEREVG1I5FIYGliAEsT9ZcZASC/QIEH6blISM1BQloOElKLCq+E1KK2xLTcUi83loaFFREREdVIhlI9ONuYwNnGpNQ+WXkFuHrvAVp/X75t6uYkEEREREQ6wFQmhVst83L3Z2FFREREpCEsrIiIiIg0hIUVERERkYawsCIiIiLSEBZWRERERBrCwoqIiIhIQ1hYEREREWkICysiIiIiDWFhRURERKQhLKyIiIiINEQnC6vMzEzMmDEDjo6OMDIygpeXFzZu3FiudZOSkjB27FjY2dnBxMQEPj4+CAsLU9s3NDQUPj4+MDExgZ2dHcaOHYukpKQS/eRyORYuXAgXFxfIZDI0adIEy5Yte64ciYiIqPrRycJq8ODBCA4Oxvz587F37160adMGI0aMwPr168tcLy8vD927d0dYWBgCAwOxc+dOODg4wN/fH5GRkSp9IyMj0atXLzg4OGDnzp0IDAxEaGgounfvjry8PJW+U6ZMweLFizF16lT8888/GDRoEKZPn44vv/xS47kTERFR1SXVdgBP27NnD0JCQrB+/XqMGDECAODr64u4uDjMnj0bw4YNg76+vtp1V61ahZiYGBw9ehQ+Pj7KdVu2bIk5c+bg+PHjyr6zZ8+Gu7s7tm7dCqm06G1wdXVFhw4dsHr1akyePBkAEBsbi1WrVuGLL77A7NmzAQBdu3ZFcnIyFi1ahHfeeQc2NjYv7P0gIiKiqkPnzljt2LEDZmZmCAgIUGkfN24cEhISVIojdes2btxYWVQBgFQqxciRI3HixAnEx8cDAOLj4xEdHY1Ro0YpiyoAaN++Pdzd3bFjxw5l259//gkhBMaNG1cinpycHOzbt++58iUiIqLqQ+cKq5iYGDRt2lSl4AGAFi1aKJeXtW5xP3XrxsbGqmyjtL5P7iMmJga1atVC7dq1KxwPERER1Sw6dykwOTkZDRo0KNFefLktOTm5zHXVXZZ7et3i76X1fXIfpW3T1NQUhoaGZcaTl5enMl4rLS0NAJCSklLqOtWBXC5HdnY2kpOTYWBgoO1wXoiakCPAPKubmpBnTcgRYJ4vW0ZGBgBACPHMvjpXWAGARCKp1LKKrlta3/L2e9ayxYsXY+HChSXa3d3dS12HiIiIdFNGRgYsLS3L7KNzhZWtra3as0DFZ3nKGihe3nVtbW0BqD/7lZKSorIPW1tbnD17tkS/rKws5OfnlxnP3LlzMWvWLOXr1NRU1K9fH3fu3HnmganK0tPT4ezsjLt378LCwkLb4bwQNSFHgHlWNzUhz5qQI8A8XzYhBDIyMuDo6PjMvjpXWHl6emLDhg0oKChQGWd14cIFAICHh0eZ6xb3e9LT6xZ/v3DhAnr37l2i75P78PT0xMaNG3H//n2VcVbliUcmk0Emk5Vot7S0rNYfhGIWFhbVPs+akCPAPKubmpBnTcgRYJ4vU3lPiOjc4PVBgwYhMzMT27ZtU2kPDg6Go6MjvL29y1z38uXLKncOFhQUYO3atfD29lZWmk5OTmjbti3Wrl2LwsJCZd+oqChcuXIFgwcPVrYNGDAAEokEwcHBKvsKCgqCsbEx/P39nytfIiIiqj507oxVr1694Ofnh8mTJyM9PR0NGzbEhg0bsG/fPqxdu1Y5h9WECRMQHByMGzduoH79+gCA8ePHY/ny5QgICMCSJUtgb2+PFStW4MqVKwgNDVXZz9KlS+Hn54eAgABMmTIFSUlJ+Oijj+Dh4aEytULz5s0xYcIEzJ8/H/r6+mjTpg3279+PX3/9FYsWLeIcVkRERPQfoYMyMjLEe++9J2rXri0MDQ1FixYtxIYNG1T6jBkzRgAQt27dUmm/f/++GD16tLCxsRFGRkaiXbt2IiQkRO1+9u/fL9q1ayeMjIyEjY2NGD16tHjw4EGJfvn5+WL+/PmiXr16wtDQULi7u4sffvihwnnl5uaK+fPni9zc3AqvW5XUhDxrQo5CMM/qpibkWRNyFIJ56jKJEOW4d5CIiIiInknnxlgRERERVVUsrIiIiIg0hIUVERERkYawsHoJMjMzMWPGDDg6OsLIyAheXl7YuHGjtsNSERERAYlEovYrKipKpe/p06fRo0cPmJmZwcrKCoMHD8bNmzfVbnfZsmVo0qQJZDIZXF1dsXDhQsjl8hL9kpKSMHbsWNjZ2cHExAQ+Pj4ICwt7rpwyMjIwZ84cvPbaa6hVqxYkEgkWLFigtq+2cwoNDYWPjw9MTExgZ2eHsWPHIikpSWM5jh07Vu2xbdKkic7nCAAHDhzA+PHj0aRJE5iamsLJyQkDBgzAqVOnSvStqseyvDlW9WN59uxZ9OnTB/Xq1YOxsTFsbGzg4+ODtWvXluhbVY9lRfKs6sfzab/99hskEgnMzMxKLKvKx7NCtD16vibw8/MTVlZW4ueffxYHDhwQb731lgAg1q1bp+3QlMLDwwUA8eWXX4pjx46pfGVkZCj7Xbp0SZibm4tOnTqJ3bt3i23btonmzZsLR0dHkZSUpLLNRYsWCYlEIubOnSvCw8PFV199JQwNDcXEiRNV+uXm5goPDw9Rt25dsXbtWrF//34xYMAAIZVKRURERKVzunXrlrC0tBSdO3dWvufz588v0U/bOUVERAipVCoGDBgg9u/fL9auXSucnJyEh4fHM++EKW+OY8aMEcbGxiWO7dmzZ0v01bUchRBi6NChwtfXV6xYsUJERESILVu2iHbt2gmpVCrCwsKU/arysSxvjlX9WIaHh4tJkyaJNWvWiAMHDohdu3aJ4cOHCwDi888/V/aryseyInlW9eP5pHv37glLS0vh6OgoTE1NVZZV9eNZESysXrDdu3cLAGL9+vUq7X5+fsLR0VEUFBRoKTJVxYXVli1byuwXEBAg7OzsRFpamrLt9u3bwsDAQMyZM0fZ9ujRI2FkZCTefvttlfW/+OILIZFIRGxsrLJt+fLlAoA4evSosk0ul4tmzZqJtm3bVjonhUIhFAqFEEKIhw8fllp0aDunNm3aiGbNmgm5XK5sO3LkiAAgVqxYoZEcx4wZU+IXnTq6mKMQQu00KBkZGcLBwUF0795d2VaVj2V5c6zqx7I03t7ewtnZWfm6Kh/LiuRZnY5n3759Rb9+/dTmVF2PpzosrF6wt956S5iZmakcTCGEWL9+vQAgjhw5oqXIVJWnsJLL5cLY2FhMmjSpxLLXXntNNGrUSPl67dq1AoA4duyYSr+EhAQBQHzxxRfKth49eojGjRuX2OaXX34pAIh79+5VJiUVpRUd2s7p3r17AoBYvHhxib7u7u7Cz8/vuXMUovy/vHU9x6f5+voKd3d3IUT1Opal5ShE9T2Wffr0Ea6urkKI6nsshVDNU4jqczzXrFkjzM3Nxd27d0vkVJ2PpzocY/WCxcTEoGnTpirPPQSAFi1aKJfrkqlTp0IqlcLCwgI9e/bE4cOHlctu3LiBnJwcZexPatGiBa5fv47c3FwA/+Xl6emp0q9OnTqws7NTyTsmJqbUbQJAbGzs8ydWCm3nVLxOaX01+fORk5OD2rVrQ19fH3Xr1sW7776rfED5k3EDVSPHtLQ0nD59Gs2bNwdQPY/l0zkWqw7HUqFQoKCgAA8fPsSKFSvwzz//4MMPPwRQvY5lWXkWq+rHMykpCTNmzMCSJUtQt27dEsur0/EsD517pE11k5ycjAYNGpRoL34UTnJy8ssOSS1LS0tMnz4dXbt2ha2tLa5fv46vv/4aXbt2xe7du9GzZ09lrOoe42NjYwMhBB4/fow6deogOTkZMpkMpqamavs+mXdycnKp2yxe/qJoO6dn7V9Tubds2RItW7ZUPjQ8MjIS//d//4ewsDBER0crB5pWpRynTp2KrKwsfPLJJ+XaT1U8lk/nCFSfYzllyhT88ssvAABDQ0P88MMPmDRpUrn2U5WOZVl5AtXjeE6ZMgWNGzfG5MmT1S6vTsezPFhYvQQSiaRSy16mVq1aoVWrVsrXnTp1wqBBg+Dp6Yk5c+agZ8+eymXlzacieWv7PdJ2TqX11VTuM2fOVHnt5+eHVq1aYejQoVi5cqXK8qqQ46effop169Zh2bJleOWVVyoVk67nWVqO1eVYfvzxx3jrrbeQlJSEXbt24d1330VWVhY++OCDCsdUlfOs6sdz27Zt2LVrF86cOfPM/tXheJYHLwW+YLa2tmqr4eLTvLr8EGcrKyv07dsX58+fR05ODmxtbQGoP4OUkpICiUQCKysrAEV55+bmIjs7W23fJ/PW5nuk7Zyetf8XmfugQYNgamqqMp1GVchx4cKFWLRoEb744gu8++67KvGUtZ+qdCxLy7E0VfFY1qtXD6+++ip69+6Nn376CW+//Tbmzp2Lhw8fVqtjWVaepakqxzMzMxNTp07FtGnT4OjoiNTUVKSmpiI/Px8AkJqaiqysrGp1PMuDhdUL5unpiUuXLqGgoECl/cKFCwCgPP2rq8S/j5KUSCRwc3ODsbGxMvYnXbhwAQ0bNoSRkRGA/66PP933/v37ePTokUrenp6epW4TeLHvkbZzKv5eWt8X/fMhhICe3n+/BnQ9x4ULF2LBggVYsGABPv74Y5Vl1eVYlpVjWarasXxa27ZtUVBQgJs3b1abY6nOk3mWpSocz0ePHuHBgwf49ttvYW1trfzasGEDsrKyYG1tjTfffLNaH0+1NDoUnkrYs2ePACA2btyo0u7v769T0y2ok5KSIpycnISXl5ey7fXXXxf29vYiPT1d2RYXFycMDQ3Fhx9+qGxLTk4WRkZG4p133lHZ5uLFi0vcMrtixQoBQERFRSnb5HK5aN68ufD29tZILmXdMaftnNq2bSs8PDxUfhaOHTsmAIiffvpJIzmqs2nTJgFAfP/991Uix//9738CgJg3b16pfar6sSxPjupUtWOpzqhRo4Senp5yTqOqfizLm6c6VeV45uTkiPDw8BJfPXv2FEZGRiI8PFxcuHBBCFF9j6c6LKxeAj8/P2FtbS1+/fVXceDAATFx4kQBQKxdu1bboSmNGDFCfPjhh2LLli0iPDxc/Prrr6Jx48ZCKpWKkJAQZb9Lly4JMzMz0blzZ7Fnzx6xfft24eHhUeYkbx9//LGIiIgQX3/9tZDJZGoneWvevLlwdnYW69atEyEhIWLQoEHPPUGoEEWF7ZYtW8Tq1asFABEQECC2bNkitmzZIrKysnQip/DwcCGVSsWgQYNESEiIWLdunXB2di73xHXPyvH27duiffv24ocffhB79uwRe/fuFR999JEwMjISzZs3F5mZmTqf4zfffCMACH9//xITKT55W3ZVPpblybE6HMuJEyeK999/X2zatElERESIrVu3imHDhgkAYvbs2cp+VflYljfP6nA81VE3hURVP54VwcLqJcjIyBDvvfeeqF27tjA0NBQtWrQQGzZs0HZYKhYvXiy8vLyEpaWl0NfXF7Vq1RKDBg0SJ06cKNH35MmTonv37sLExERYWFiIgQMHiuvXr6vdbmBgoHB3dxeGhoaiXr16Yv78+SI/P79Ev/v374vRo0cLGxsbYWRkJNq1a6dS0FVW/fr1BQC1X7du3dKZnPbv3y/atWsnjIyMhI2NjRg9erTaCSMrk2NKSooYNGiQcHFxEcbGxsLQ0FA0atRIzJkzR6SmplaJHLt06VJqjk+feK+qx7I8OVaHY7l69WrRqVMnYWdnJ6RSqbCyshJdunQRa9asKdG3qh7L8uZZHY6nOqXNzVWVj2dFSIT4dxANERERET0XDl4nIiIi0hAWVkREREQawsKKiIiISENYWBERERFpCAsrIiIiIg1hYUVERESkISysiIiIiDSEhRURkQ7p2rUrJBKJtsMgokpiYUVE1d7t27chkUhKfJmamqJFixZYuHAhMjMzn3v7Y8eO1VzQRFQlSbUdABHRy+Lm5oaRI0cCAIQQePjwIfbu3YsFCxbgn3/+waFDh6Cvr6/lKImoKmNhRUQ1RsOGDbFgwQKVtry8PPj4+ODYsWM4ePAgfH19tRMcEVULvBRIRDWaTCZTFlMPHz5Utu/YsQMjRoxAw4YNYWJiAktLS3Tq1Anbtm1TWT8oKAiurq4AgODgYJVLjREREcp+QggEBwejc+fOsLKygomJCRo1aoR33nkHd+7cKRFXQUEBPv/8c7i6ukImk8Hd3R0rVqx4Ae8AEWkSz1gRUY2Wn5+PiIgISCQSeHl5Kdvnzp0LQ0NDdOzYEXXq1MHDhw/x119/YejQofjhhx8wbdo0AICXlxemT5+OwMBAtGzZEgMHDlRuw8XFBUBRUTVixAhs2rQJTk5OGDFiBCwsLHD79m1s2rQJ/v7+qFevnkpcI0aMwPHjx9GrVy/o6+tj8+bNmDp1KgwMDDBx4sQX/bYQUSVJhBBC20EQEb1It2/fhqura4kxVo8ePcI///yD+Ph4fP755/jggw+U69y8eRMNGjRQ2U5mZibat2+PO3fuICEhASYmJirbHzNmDIKCgkrsf8WKFZg6dSq6d++OXbt2wdjYWLksJycHOTk5sLGxAVB0V2BkZCS8vb2xf/9+WFhYAACuXLkCDw8PuLm54fLlyxp9f4hIc3jGiohqjBs3bmDhwoUl2vv3748+ffqotD1dVAGAmZkZxo4di/fffx/R0dHo0qVLufa7fPly6Ovr46efflIpqgDA2Ni4RBsALF68WFlUAUDjxo3RoUMHREZGIiMjA+bm5uXaNxG9XBxjRUQ1Rs+ePSGEUH49ePAA69evx9GjR9G+fXtcvXpV2TcpKQmzZs1C06ZNYWJiohw39f777wMAEhISyrXPrKwsXLx4Ea6urmjUqFG5Y23dunWJtrp16wIAUlNTy70dInq5eMaKiGose3t7jBgxAjk5OZgwYQKWLFmC1atXIyUlBW3atMGdO3fQoUMH9OjRA1ZWVtDX18fZs2exc+dO5OXllWsfxUWQk5NThWKztLQs0SaVFv3KLiwsrNC2iOjlYWFFRDVe27ZtAQCnT58GAKxatQp37tzBokWL8Mknn6j0XbJkCXbu3FnubRcXSPHx8RqKloh0GS8FElGNl5KSAgBQKBQAisZiAUVjr5526NChEm3Fk4qqO5NkZmaGZs2a4datW7h27ZrGYiYi3cTCiohqNIVCgWXLlgEAOnXqBACoX78+AODw4cMqfdevX489e/aU2Ia1tTUkEgnu3bundh9Tp05FYWEhpkyZgpycHJVlubm5ysKOiKo+Xgokohrj+vXrKjOvP3z4EOHh4bh06RKcnZ0xb948AMCoUaOwdOlSTJs2DeHh4ahfvz7Onz+P0NBQDB48GNu3b1fZrpmZGdq0aYODBw9i3LhxaNSoEfT09PDGG2+gXr16mDx5MiIjI7F582Y0atQI/fv3h4WFBe7cuYN//vkHq1atUpn/ioiqLhZWRFRjPD3dgkwmg4uLC2bNmoW5c+fCzs4OQNHdd5GRkZgzZw5CQ0NRUFCA1q1bY//+/bh7926JwgoA1qxZg5kzZ+LPP/9EWloahBBo164d6tWrB4lEgo0bN+K1117Db7/9hj/++ANCCDg5OeH111/HK6+88tLeAyJ6sThBKBEREZGGcIwVERERkYawsCIiIiLSEBZWRERERBrCwoqIiIhIQ1hYEREREWkICysiIiIiDWFhRURERKQhLKyIiIiINISFFREREZGGsLAiIiIi0hAWVkREREQawsKKiIiISENYWBERERFpyP8DbzLAF8weZp4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте скорость обучения постоянной в течение ряда эпох (например, $n_0$ = 0,1 в течение 5 эпох), затем меньшая скорость обучения для другого ряда эпох (например, $n_1$ = 0,001 в течение 50 эпох), и так далее. Хотя это решение может работать очень хорошо, оно требует возиться, чтобы выяснить правильную последовательность скоростей обучения и как долго использовать каждый из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 0.7426 - accuracy: 0.7784 - val_loss: 0.7837 - val_accuracy: 0.7962 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6852 - accuracy: 0.7963 - val_loss: 0.7057 - val_accuracy: 0.7968 - lr: 0.0100\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7628 - accuracy: 0.7825 - val_loss: 0.8433 - val_accuracy: 0.7630 - lr: 0.0100\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.8662 - accuracy: 0.7623 - val_loss: 0.9061 - val_accuracy: 0.7308 - lr: 0.0100\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.9395 - accuracy: 0.7242 - val_loss: 0.8189 - val_accuracy: 0.7224 - lr: 0.0100\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5578 - accuracy: 0.8319 - val_loss: 0.6553 - val_accuracy: 0.8366 - lr: 0.0050\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5017 - accuracy: 0.8489 - val_loss: 0.5518 - val_accuracy: 0.8444 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4850 - accuracy: 0.8548 - val_loss: 0.6194 - val_accuracy: 0.8156 - lr: 0.0050\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4630 - accuracy: 0.8615 - val_loss: 0.5634 - val_accuracy: 0.8502 - lr: 0.0050\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4706 - accuracy: 0.8609 - val_loss: 0.5633 - val_accuracy: 0.8682 - lr: 0.0050\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4454 - accuracy: 0.8666 - val_loss: 0.6748 - val_accuracy: 0.8600 - lr: 0.0050\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4332 - accuracy: 0.8705 - val_loss: 0.6284 - val_accuracy: 0.8528 - lr: 0.0050\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4240 - accuracy: 0.8740 - val_loss: 0.6086 - val_accuracy: 0.8594 - lr: 0.0050\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4193 - accuracy: 0.8738 - val_loss: 0.6264 - val_accuracy: 0.8516 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4316 - accuracy: 0.8757 - val_loss: 0.6692 - val_accuracy: 0.8462 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2883 - accuracy: 0.9065 - val_loss: 0.5031 - val_accuracy: 0.8830 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2599 - accuracy: 0.9144 - val_loss: 0.5030 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 18/25\n",
      " 995/1719 [================>.............] - ETA: 2s - loss: 0.2445 - accuracy: 0.9198"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измеряйте ошибку проверки каждые N шагов (как при ранней остановке) и уменьшайте скорость обучения с коэффициентом λ, когда ошибка перестает падать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, tf.keras предлагает альтернативный способ реализации планирования скорости обучения: определите скорость обучения с помощью одного из расписаний, доступных в keras.optimizers.schedules , а затем передайте эту скорость обучения любому оптимизатору. Этот подход обновляет скорость обучения на каждом этапе, а не в каждой эпохе. Например, здесь показано, как реализовать тот же экспоненциальный график, что и функцию exponential_decay_fn (), которую мы определили ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For piecewise constant scheduling, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от других подходов, 1 цикл (введенный Лесли Смитом в 2018 paper21) начинается с увеличения начальной скорости обучения η 0 , линейно растущей до η 1 в середине обучения. Затем он уменьшает линейную скорость обучения до η 0 снова во второй половине обучения, завершая последние несколько эпох, снижая скорость на несколько порядков (все еще линейно). Максимальная скорость обучения η 1 выбирается с использованием того же подхода, который мы использовали для нахождения оптимальной скорости обучения, а начальная скорость обучения η 0 выбирается примерно в 10 раз ниже. При использовании импульса мы сначала начинаем с высокого импульса (например, 0,95), затем снижаем его до более низкого импульса в течение первой половины тренировки (например, до 0,85, линейно), а затем возвращаем его к максимальное значение (например, 0,95) во второй половине обучения, заканчивая последние несколько эпох этим максимальным значением. Смит провел много экспериментов, показавших, что этот подход часто позволяет значительно ускорить обучение и достичь лучших результатов. Например, в популярном наборе данных изображений CIFAR10 этот подход достиг точности проверки 91,9% всего за 100 эпох, вместо точности 90,3% в 800 эпохах с помощью стандартного подхода (с той же архитектурой нейронной сети)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как избежать переобучения через регуляризацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубокие нейронные сети обычно имеют десятки тысяч параметров, иногда даже миллионы. Это дает им невероятную свободу и означает, что они могут вместить огромное количество сложных наборов данных. Но эта большая гибкость также делает сеть склонной к переобучению тренировочного набора. Нам нужна регуляризация.\n",
    "Мы уже реализовали один из лучших методов регуляризации: ранняя остановка. Более того, хотя пакетная нормализация была разработана для решения проблем с нестабильными градиентами, она также действует как довольно хороший регуляризатор. Далее мы рассмотрим другие популярные методы регуляризации для нейронных сетей: регуляризация ℓ 1 и out 2 , dropout и регуляризация с максимальной нормой.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ и $\\ell_2$ регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее для простых линейных моделей, вы можете использовать регуляризацию ℓ 2 для ограничения весов соединений нейронной сети и / или регуляризацию ℓ 1, если вы хотите разреженную модель (со многими весами, равными 0). Вот как применить регуляризацию ℓ 2 к весам соединений слоя Keras, используя коэффициент регуляризации 0,01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция l2() возвращает регуляризатор, который будет вызываться на каждом шаге во время обучения для вычисления потери регуляризации. Это затем добавляется к окончательной потере. Как и следовало ожидать, вы можете просто использовать keras.regularizers.l1 (), если вы хотите regular 1 регуляризацию; если вы хотите регуляризацию ℓ 1 и ℓ 2 , используйте keras.regularizers.l1_l2 () (указав оба фактора регуляризации).\n",
    "Поскольку вы обычно хотите применить один и тот же регуляризатор ко всем слоям в вашей сети, а также использовать одну и ту же функцию активации и одну и ту же стратегию инициализации во всех скрытых слоях, вы можете обнаружить, что повторяете одни и те же аргументы. Это делает код уродливым и подверженным ошибкам. Чтобы избежать этого, вы можете попробовать рефакторинг вашего кода для использования циклов. Другой вариант - использовать функцию Python functools.partial () , которая позволяет создать тонкую оболочку для любого вызываемого объекта с некоторыми значениями аргументов по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout является одним из самых популярных методов регуляризации для глубоких нейронных сетей. Он был proposed in a paper Джеффри Хинтоном в 2012 году и более подробно описан в 2014 paper Нитиша Шриваставы и др., И он оказался весьма успешным: даже современные нейронные сети получают  повышение точности на 2%, просто добавив Dropout. Это может показаться не так много, но когда модель уже имеет точность 95%, повышение точности на 2% означает снижение частоты ошибок почти на 40% (с 5% ошибки до примерно 3%). \n",
    "Это довольно простой алгоритм: на каждом этапе обучения, каждый нейрон ( в том числе входных нейронов, но всегда за исключением выходных нейронов) имеет вероятность р быть временно «обнуление» означает , что он будет полностью игнорироваться при этом шаге обучения, но он может быть активен на следующем шаге (см. Рисунок 11-9  ). Гиперпараметр p называется частотой выпадения , и он обычно устанавливается между 10% и 50%: ближе к 20–30% в повторяющихся нейронных сетях и ближе к 40–50% в сверточных нейронных сетях. После тренировки нейроны больше обнуляются. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"dropout.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала удивительно, что эта разрушительная техника работает вообще. Будет ли компания работать лучше, если ее сотрудникам будет приказывать бросать монеты каждое утро, чтобы решить, идти на работу или нет? Ну кто знает; возможно это будет! Компания будет вынуждена адаптировать свою организацию; он не мог рассчитывать на то, что какой-либо человек будет работать с кофемашиной или выполнять какие-либо другие важные задачи, поэтому этот опыт придется распространить на несколько человек. Сотрудникам придется учиться сотрудничать со многими из своих сотрудников, а не только с несколькими из них. Компания станет намного более устойчивой. Если один человек уйдет, это не будет иметь большого значения. Неясно, будет ли эта идея работать на самом деле для компаний, но это, безусловно, работает для нейронных сетей. Нейроны, обученные с отсева, не могут совместно адаптироваться с соседними нейронами; они должны быть максимально полезными сами по себе. Они также не могут чрезмерно полагаться только на несколько входных нейронов; они должны обратить внимание на каждый из своих входных нейронов. Они оказываются менее чувствительными к небольшим изменениям во входных данных. В итоге вы получаете более надежную сеть, которая лучше обобщается.\n",
    "Другой способ понять силу отсева - понять, что на каждом этапе обучения создается уникальная нейронная сеть. Поскольку каждый нейрон может присутствовать или отсутствовать, существует в общей сложности 2 N возможных сетей (где N - общее количество сбрасываемых нейронов). Это настолько большое число, что для одной и той же нейронной сети практически невозможно сделать выборку дважды. После того, как вы выполнили 10 000 этапов обучения, вы, по сути, обучили 10 000 различных нейронных сетей (каждая из которых имеет только один экземпляр обучения). Эти нейронные сети, очевидно, не являются независимыми, потому что они разделяют многие из своих весов, но, тем не менее, все они разные. Результирующая нейронная сеть может рассматриваться как ансамбль усреднения всех этих меньших нейронных сетей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике вы можете обычно применять Dropout только к нейронам в верхнем 1-3 слоях (исключая выходной слой).\n",
    "Есть одна маленькая, но важная техническая деталь. Предположим, что p = 50%, и в этом случае во время тестирования нейрон будет подключен к вдвое большему количеству входных нейронов, чем было бы (в среднем) во время обучения. Чтобы компенсировать этот факт, нам нужно умножить веса входных соединений каждого нейрона на 0,5 после тренировки. Если мы этого не сделаем, каждый нейрон получит общий входной сигнал примерно в два раза больше, чем то, на котором обучалась сеть, и вряд ли будет работать хорошо. В более общем случае нам нужно умножить вес каждого входного соединения на вероятность удержания (1 - p ) после тренировки. В качестве альтернативы, мы можем разделить выход каждого нейрона на вероятность удержания во время тренировки (эти альтернативы не совсем эквивалентны, но они работают одинаково хорошо). \n",
    "Чтобы реализовать Dropout с использованием Keras , вы можете использовать слой `keras.layers.Dropout`. Во время обучения он случайным образом сбрасывает некоторые входные данные (устанавливая их в 0) и делит оставшиеся входные данные на вероятность удержания. После тренировки он вообще ничего не делает; он просто передает входные данные следующему слою. Следующий код применяет регуляризацию отсева перед каждым плотным слоем, используя коэффициент отсева 0,2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку dropout активен только во время обучения, сравнение потери при обучении и потери при проверке может вводить в заблуждение. В частности, модель может соответствовать учебному набору и при этом иметь аналогичные потери при обучении и проверке. Поэтому обязательно оцените потерю тренировки без отсева (например, после тренировки).\n",
    "Если вы заметили, что модель переобучена, вы можете увеличить коэффициент dropout. И наоборот, вы должны попытаться уменьшить коэффициент dropout, если модель не соответствует тренировочному набору. Это также может помочь увеличить частоту выпадения для больших слоев и уменьшить ее для маленьких. Более того, многие современные архитектуры используют dropout только после последнего скрытого слоя, поэтому вы можете попробовать это, если полное выпадение слишком сильное.\n",
    "Выпадение имеет тенденцию значительно замедлять конвергенцию, но обычно это приводит к гораздо лучшей модели при правильной настройке. Таким образом, это, как правило, стоит дополнительного времени и усилий.\n",
    "Примечание\n",
    "Если вы хотите упорядочить самонормализующуюся сеть на основе функции активации SELU (как обсуждалось ранее), вы должны использовать альфа-отсев : это вариант отсева, который сохраняет среднее значение и стандартное отклонение ее входов (он был введен в та же бумага, что и SELU, так как регулярный dropout нарушит самонормализацию).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 2016 году в статье Ярина Гала и Зубина Гахрамани добавлено еще несколько веских причин для использования отсева:\n",
    "*\tВо-первых, в документе была установлена глубокая связь между сетями dropout (то есть нейронными сетями, содержащими слой dropout перед каждым весовым слоем) и приблизительным байесовским выводом, что дает dropout солидное математическое обоснование.\n",
    "*\tВо-вторых, авторы представили мощную технику, называемую MC Dropout , которая может повысить производительность любой обученной модели dropout без необходимости ее переподготовки или даже вообще ее изменять, обеспечивает гораздо лучший показатель неопределенности модели, а также удивительно прост для воплощать в жизнь.\n",
    "Если все это звучит как реклама «один странный трюк», взгляните на следующий код. Это полная реализация MC Dropout , улучшающая модель dropout, которую мы обучали ранее, без ее переподготовки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы просто делаем 100 прогнозов по тестовому набору, устанавливая training = True, чтобы гарантировать, что слой Dropout активен, и собираем прогнозы. Поскольку  Dropout активен, все прогнозы будут разными. Напомним, что predict() возвращает матрицу с одной строкой на экземпляр и одним столбцом на класс Поскольку в тестовом наборе 10 000 экземпляров и 10 классов, это матрица формы [10000, 10]. Мы складываем 100 таких матриц, поэтому y_probas - это массив формы [100, 10000, 10]. Как только мы усредним по первому измерению ( axis = 0 ), мы получим y_proba , массив формы [10000, 10], как мы получили бы с одним прогнозом. Вот и все! Усреднение по нескольким прогнозам с включенным отсевом дает нам оценку по методу Монте-Карло, которая, как правило, более надежна, чем результат одного прогноза с отсечкой. Например, давайте посмотрим на прогноз модели для первого экземпляра в наборе тестов Fashion MNIST, с отключением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель кажется почти уверенной, что этот образ относится к 9 классу (лыжный ботинок). Стоит ли доверять этому? Неужели так мало места для сомнений? Сравните это с прогнозами, сделанными при активации отсева:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это рассказывает совсем другую историю: по-видимому, когда мы активируем dropout, модель больше не уверена. Кажется, он все еще предпочитает класс 9, но иногда он колеблется с классами 5 (сандали) и 7 (кроссовки), что имеет смысл, учитывая, что все они - обувь. После усреднения по первому измерению мы получаем следующие прогнозы MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель все еще думает, что это изображение относится к 9 классу, но только с уверенностью 62%, что кажется гораздо более разумным, чем 99%. Кроме того, полезно точно знать, какие другие классы он считает вероятными. И вы также можете взглянуть на standard deviation of the probability estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что в оценках вероятности есть довольно много отклонений: если вы строите систему, чувствительную к риску (например, медицинскую или финансовую систему), вам, вероятно, следует относиться к такому неопределенному прогнозу с особой осторожностью. Вы определенно не относитесь к этому как к 99% уверенному прогнозу. Более того, точность модели немного увеличилась с 86,8 до 86,9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество используемых образцов Монте-Карло (в данном примере 100) - это гиперпараметр, который вы можете настроить. Чем оно выше, тем точнее будут прогнозы и их оценки неопределенности. Однако, если вы удвоите его, время вывода также будет удвоено. Более того, выше определенного количества образцов вы заметите небольшое улучшение. Таким образом, ваша задача - найти правильный компромисс между задержкой и точностью, в зависимости от вашего приложения.\n",
    "Если ваша модель содержит другие слои, которые ведут себя особым образом во время обучения (например, слои BatchNormalization ), вам не следует форсировать режим обучения, как мы только что сделали. Вместо этого вы должны заменить слои Dropout следующим классом MCDropout : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы просто создаем подкласс Dropout- слоя и переопределяем метод call(), чтобы принудительно установить его training аргумент в True. Кроме того , вы можете определить MCAlphaDropout класс по подклассов AlphaDropout вместо этого. Если вы создаете модель с нуля, это просто вопрос использования MCDropout, а не Dropout . Но если у вас есть модель, которая уже была обучена с использованием Dropout , вам нужно создать новую модель, идентичную существующей модели, за исключением того, что она заменяет слои Dropout на MCDropout , а затем скопируйте веса существующей модели в вашу новую модель.\n",
    "Короче говоря, MC Dropout - это фантастическая методика, которая улучшает модели dropout и обеспечивает более точные оценки неопределенности. И, конечно же, поскольку это просто регулярное прекращение обучения во время тренировок, оно также действует как регуляризатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model with MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регуляризация Max-Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой метод регуляризации, который популярен для нейронных сетей, называется регуляризацией по максимальной норме : для каждого нейрона он ограничивает веса w входящих соединений так, что ∥ w ∥ 2 ≤ r , где r - гиперпараметр максимальной нормы, а ∥ · ∥ 2 является нормой ℓ 2 .  \n",
    "Макс-норма регуляризации не добавляет термин потери регуляризации к общей функции потерь. Вместо этого он обычно реализуется путем вычисления ∥ w ∥ 2 после каждого шага обучения и при необходимости масштабирования w ( w ← w r / / w ‖ 2 ). \n",
    "Снижение r увеличивает степень регуляризации и помогает уменьшить переобучение. Регуляризация макс-нормы также может помочь решить проблемы нестабильных градиентов (если вы не используете пакетную нормализацию).\n",
    "Чтобы реализовать регуляризацию max-norm в Keras, установите для аргумента kernel_constraint каждого скрытого слоя ограничение max_norm() с соответствующим значением max, например:\n",
    "```python\n",
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                   kernel_constraint=keras.constraints.max_norm(1.))\n",
    "```\n",
    "После каждой обучающей итерации метод fit() модели будет вызывать объект, возвращаемый max_norm(), передавая ему веса слоя и получая взамен измененные веса, которые затем заменяют веса слоя. Как вы увидите плзднее, вы можете при необходимости определить свою собственную функцию ограничения и использовать ее как `kernel_constraint`. Вы также можете ограничить условия смещения, установив аргумент `bias_constraint`.\n",
    "Функция max_norm() имеет аргумент оси, который по умолчанию равен 0 . Плотный слой обычно имеет вес формы [number of inputs, number of neurons], поэтому использование axis = 0 означает , что максимальное ограничение-норма будет применяться независимо друг от друга , чтобы вектор весовых коэффициентов каждого нейрона. Если вы хотите использовать max-norm со сверточными слоями, убедитесь, что вы правильно установили аргумент оси ограничения max_norm() (обычно axis = [0, 1, 2] )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
